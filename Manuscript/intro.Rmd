
# Introduction

Determining the spatial correspondence between imaging domains is frequently a
critical component in quantitative image analysis workflows.  The evolution of
image registration theoretical and technological development has led to increasingly
high quality transformational mappings that have significantly improved performance in related
processing tasks (e.g., image segmentation via joint label fusion [@Iglesias:2015aa])
and imaging-based statistical analyses (e.g., sparse canonical correlation
analysis [@Avants:2010aa]).  Several reviews
[@Brown:1992;@Maintz:1998aa;@Pluim:2003aa;@Gholipour:2007aa;@Viergever:2016aa;@Keszei:2017aa]
have charted this chronology and provided insight into related issues such as algorithmic
classification, available implementations, evaluation strategies, and speculation
concerning future directions of the field.  While prescient in many respects,
speculation vis-Ã -vis deep learning was somewhat limited due to its sudden explosion
in popularity and research focus.

The foundational concepts that form the basis for contemporary deep learning studies
date back decades (e.g., [@Ivakhnenko:1971aa]).  Since this early seminal work,
major developmental milestones include the *Neocognitron*, an early neural network
for character recognition [@Fukushima:1980aa], and convolutional neural networks
(CNNs or ConvNets) utilized in speech [@Waibel:1987aa] and visual signal processing
[@LeCun:1989aa], largely inspired by the visual cell types of the feline visual cortex
[@Hubel:1962aa].  The major elements of CNNs are localized connectivity, convolutions, and
subsampling (or "pooling") [@LeCun:2015aa].  Furthermore, it is the deep, or hidden,
layering that characterizes modern CNNs and is the reason for the
extreme performance gains seen with modern architectures.  Such architectures are made
computationally tractable with gradient-based optimization using backpropagation
(first performed in [@LeCun:1989aa]) and the advent of GPU-based hardware [@LeCun:2015aa].
An illustration of a bare-bones CNN configuration is provided in Figure \ref{fig:convnet} which illustrates
the core components of convolution and max pooling.  Structural innovations are built upon
novel arrangements of these core (and other) network components and the connectivities between
them.

\begin{figure}[!htb]
\centering
\includegraphics[width=0.95\textwidth]{Figures/ConvNet.pdf}
\caption{The basic elements of the prop  convolutional neural network.
        The convolutional layer comprises several filters which
        are optimized in terms of their responses to various features
        found in the input layer.  Pooling is used to extract salient
        features and reduce computational complexity and passed on to
        subsequent layers.
        }
\label{fig:convnet}
\end{figure}

A key event in the widespread adoption of CNNs was the 2012
ImageNet Large Scale Visual Recognition Challenge for object classification [@Russakovsky:2015aa].
The winning entry, a CNN-based architecture colloquially known as *AlexNet* [@Krizhevsky:2012],
reduced the error rate by almost half over other entries.  The following years' competitions were
dominated by CNN variants such as VGG [@Simonyan:2014], GoogLeNet [@Szegedy:2015], and
ResNet [@He:2015].  Additional competition outlets including conference-based venues
(e.g., NeurIPS) and community-based platforms, such as Kaggle[^1], continue to highlight
the salience of CNNs as paradigmatic solutions to computational problems.  This is in addition
to the vast number of formal research reports discussed in the same conferences and published
in dedicated journals.

[^1]: Following the 2017 ImageNet challenge, in which the vast majority of
teams surpassed the 5\% classification error rate threshold, the ImageNet organizers ceded management
to the Kaggle community which maintains a running performance assessment in ostensible perpetuity
[@imageNetKaggle].


* We need to somehow tie in the reviews [@Lecun:2015aa;Schmidhuber:2015aa]

* Uptake in the medical imaging community.   Used for such things as image segmentation (U-net).
Reviews specific to medical imaging [@Greenspan:2016aa;@Suzuki:2017aa;@Shen:2017aa;@Litjens:2017aa;@Ker:2018aa;@Biswas:2019aa]

* Early work in medical image registration with the GPU focused on interfacing wiht the
hardware directly [@Shams:2010aa].  One of the review papers listed this as well.







<!--




* Brief history of deep learning.  Cite the various review articles.

* Available resources

    * The usual packages (tensorflow, theano, Caffe, Lasagne, Flux (Julia), Keras (python and R))

    * NiftyNet

    * ANTsRNet

    * Countless repositories of individual implementations

* Brief history of image registration

* Structure of the review

    * Discussion --- what are some of the challengs specific to image registration?

-->