%% This BibTeX bibliography file was created using BibDesk.
%% http://bibdesk.sourceforge.net/

%% Created for Nicholas Tustison at 2019-05-21 22:20:16 -0700 


%% Saved with string encoding Unicode (UTF-8) 



@article{deVos:2019aa,
	Abstract = {Image registration, the process of aligning two or more images, is the core technique of many (semi-)automatic medical image analysis tasks. Recent studies have shown that deep learning methods, notably convolutional neural networks (ConvNets), can be used for image registration. Thus far training of ConvNets for registration was supervised using predefined example registrations. However, obtaining example registrations is not trivial. To circumvent the need for predefined examples, and thereby to increase convenience of training ConvNets for image registration, we propose the Deep Learning Image Registration (DLIR) framework for unsupervised affine and deformable image registration. In the DLIR framework ConvNets are trained for image registration by exploiting image similarity analogous to conventional intensity-based image registration. After a ConvNet has been trained with the DLIR framework, it can be used to register pairs of unseen images in one shot. We propose flexible ConvNets designs for affine image registration and for deformable image registration. By stacking multiple of these ConvNets into a larger architecture, we are able to perform coarse-to-fine image registration. We show for registration of cardiac cine MRI and registration of chest CT that performance of the DLIR framework is comparable to conventional image registration while being several orders of magnitude faster.},
	Author = {de Vos, Bob D and Berendsen, Floris F and Viergever, Max A and Sokooti, Hessam and Staring, Marius and I{\v s}gum, Ivana},
	Date-Added = {2019-05-21 15:33:27 -0700},
	Date-Modified = {2019-05-21 15:33:59 -0700},
	Doi = {10.1016/j.media.2018.11.010},
	Journal = {Med Image Anal},
	Journal-Full = {Medical image analysis},
	Keywords = {Affine image registration; Cardiac cine MRI; Chest CT; Deep learning; Deformable image registration; Unsupervised learning},
	Month = {02},
	Pages = {128-143},
	Pmid = {30579222},
	Pst = {ppublish},
	Title = {A deep learning framework for unsupervised affine and deformable image registration},
	Volume = {52},
	Year = {2019},
	Bdsk-Url-1 = {https://doi.org/10.1016/j.media.2018.11.010}}

@inproceedings{Krebs:2018aa,
	Author = {Julian Krebs and Tommaso Mansi and Boris Mailh{\'{e}} and Nicholas Ayache and Herv{\'{e}} Delingette},
	Booktitle = {Proceedings of the 4th {I}nternational {W}orkshop, {DLMIA} and 8th {I}nternational {W}orkshop, {ML-CDS}},
	Date-Added = {2019-05-21 15:03:33 -0700},
	Date-Modified = {2019-05-21 21:49:58 -0700},
	Month = {September},
	Title = {Unsupervised Probabilistic Deformation Modeling for Robust Diffeomorphic Registration},
	Year = {2018}}

@article{Tustison:2013aa,
	Author = {Tustison, Nicholas J and Johnson, Hans J and Rohlfing, Torsten and Klein, Arno and Ghosh, Satrajit S and Ibanez, Luis and Avants, Brian B},
	Date-Added = {2019-05-21 11:26:43 -0700},
	Date-Modified = {2019-05-21 11:26:43 -0700},
	Doi = {10.3389/fnins.2013.00162},
	Journal = {Front Neurosci},
	Journal-Full = {Frontiers in neuroscience},
	Keywords = {best practices; comparative evaluations; confirmation bias; open science; reproducibility},
	Pages = {162},
	Pmc = {PMC3766821},
	Pmid = {24058331},
	Pst = {epublish},
	Title = {Instrumentation bias in the use and evaluation of scientific software: recommendations for reproducible practices in the computational sciences},
	Volume = {7},
	Year = {2013},
	Bdsk-Url-1 = {https://doi.org/10.3389/fnins.2013.00162}}

@inproceedings{Hinton:1993aa,
	Author = {Hinton, Geoffrey E and Richard S. Zemel},
	Booktitle = {Advances in {N}eural {I}nformation {P}rocessing {S}ystems},
	Date-Added = {2019-05-21 10:29:03 -0700},
	Date-Modified = {2019-05-21 22:09:38 -0700},
	Editor = {J. D. Cowan and G. Tesauro and J. Alspector},
	Pages = {3--10},
	Publisher = {Morgan-Kaufmann},
	Title = {Autoencoders, Minimum Description Length and {H}elmholtz Free Energy},
	Year = {1994},
	Bdsk-Url-1 = {http://papers.nips.cc/paper/798-autoencoders-minimum-description-length-and-helmholtz-free-energy.pdf}}

@article{Crum:2006aa,
	Abstract = {Measures of overlap of labelled regions of images, such as the Dice and Tanimoto coefficients, have been extensively used to evaluate image registration and segmentation algorithms. Modern studies can include multiple labels defined on multiple images yet most evaluation schemes report one overlap per labelled region, simply averaged over multiple images. In this paper, common overlap measures are generalized to measure the total overlap of ensembles of labels defined on multiple test images and account for fractional labels using fuzzy set theory. This framework allows a single "figure-of-merit" to be reported which summarises the results of a complex experiment by image pair, by label or overall. A complementary measure of error, the overlap distance, is defined which captures the spatial extent of the nonoverlapping part and is related to the Hausdorff distance computed on grey level images. The generalized overlap measures are validated on synthetic images for which the overlap can be computed analytically and used as similarity measures in nonrigid registration of three-dimensional magnetic resonance imaging (MRI) brain images. Finally, a pragmatic segmentation ground truth is constructed by registering a magnetic resonance atlas brain to 20 individual scans, and used with the overlap measures to evaluate publicly available brain segmentation algorithms.},
	Author = {Crum, William R and Camara, Oscar and Hill, Derek L G},
	Date-Added = {2019-05-21 08:15:59 -0700},
	Date-Modified = {2019-05-21 08:15:59 -0700},
	Doi = {10.1109/TMI.2006.880587},
	Journal = {IEEE Trans Med Imaging},
	Journal-Full = {IEEE transactions on medical imaging},
	Mesh = {Algorithms; Brain; Humans; Image Enhancement; Image Interpretation, Computer-Assisted; Information Storage and Retrieval; Magnetic Resonance Imaging; Pattern Recognition, Automated; Quality Assurance, Health Care; Reproducibility of Results; Sensitivity and Specificity; Subtraction Technique},
	Month = {Nov},
	Number = {11},
	Pages = {1451-61},
	Pmid = {17117774},
	Pst = {ppublish},
	Title = {Generalized overlap measures for evaluation and validation in medical image analysis},
	Volume = {25},
	Year = {2006},
	Bdsk-Url-1 = {https://doi.org/10.1109/TMI.2006.880587}}

@article{Sotiras:2013aa,
	Abstract = {Deformable image registration is a fundamental task in medical image processing. Among its most important applications, one may cite: 1) multi-modality fusion, where information acquired by different imaging devices or protocols is fused to facilitate diagnosis and treatment planning; 2) longitudinal studies, where temporal structural or anatomical changes are investigated; and 3) population modeling and statistical atlases used to study normal anatomical variability. In this paper, we attempt to give an overview of deformable registration methods, putting emphasis on the most recent advances in the domain. Additional emphasis has been given to techniques applied to medical images. In order to study image registration methods in depth, their main components are identified and studied independently. The most recent techniques are presented in a systematic fashion. The contribution of this paper is to provide an extensive account of registration techniques in a systematic manner. },
	Author = {Sotiras, Aristeidis and Davatzikos, Christos and Paragios, Nikos},
	Date-Added = {2019-05-20 14:51:35 -0700},
	Date-Modified = {2019-05-20 14:51:35 -0700},
	Doi = {10.1109/TMI.2013.2265603},
	Journal = {IEEE Trans Med Imaging},
	Journal-Full = {IEEE transactions on medical imaging},
	Mesh = {Algorithms; Diagnostic Imaging; Humans; Image Processing, Computer-Assisted},
	Month = {Jul},
	Number = {7},
	Pages = {1153-90},
	Pmc = {PMC3745275},
	Pmid = {23739795},
	Pst = {ppublish},
	Title = {Deformable medical image registration: a survey},
	Volume = {32},
	Year = {2013},
	Bdsk-Url-1 = {https://doi.org/10.1109/TMI.2013.2265603}}

@article{Vincent:2010aa,
	Acmid = {1953039},
	Author = {Vincent, Pascal and Larochelle, Hugo and Lajoie, Isabelle and Bengio, Yoshua and Manzagol, Pierre-Antoine},
	Date-Added = {2019-05-19 20:57:38 -0700},
	Date-Modified = {2019-05-19 20:57:50 -0700},
	Issn = {1532-4435},
	Issue_Date = {3/1/2010},
	Journal = {J. Mach. Learn. Res.},
	Month = dec,
	Numpages = {38},
	Pages = {3371--3408},
	Publisher = {JMLR.org},
	Title = {Stacked Denoising Autoencoders: Learning Useful Representations in a Deep Network with a Local Denoising Criterion},
	Url = {http://dl.acm.org/citation.cfm?id=1756006.1953039},
	Volume = {11},
	Year = {2010},
	Bdsk-Url-1 = {http://dl.acm.org/citation.cfm?id=1756006.1953039}}

@article{Cao:2018aa,
	Author = {X. {Cao} and J. {Yang} and J. {Zhang} and Q. {Wang} and P. {Yap} and D. {Shen}},
	Date-Added = {2019-04-16 13:38:48 -0400},
	Date-Modified = {2019-04-16 13:38:48 -0400},
	Doi = {10.1109/TBME.2018.2822826},
	Issn = {0018-9294},
	Journal = {IEEE Transactions on Biomedical Engineering},
	Keywords = {Strain;Task analysis;Databases;Machine learning;Image registration;Tuning;Training;Deformable registration;deep learning;nonlinear regression;key-points sampling},
	Month = {Sep.},
	Number = {9},
	Pages = {1900-1911},
	Title = {Deformable Image Registration Using a Cue-Aware Deep Regression Network},
	Volume = {65},
	Year = {2018},
	Bdsk-Url-1 = {https://doi.org/10.1109/TBME.2018.2822826}}

@article{Shen:2019aa,
	Archiveprefix = {arXiv},
	Author = {Zhengyang Shen and Xu Han and Zhenlin Xu and Marc Niethammer},
	Bibsource = {dblp computer science bibliography, https://dblp.org},
	Biburl = {https://dblp.org/rec/bib/journals/corr/abs-1903-08811},
	Date-Added = {2019-04-16 13:33:09 -0400},
	Date-Modified = {2019-04-16 13:33:16 -0400},
	Eprint = {1903.08811},
	Journal = {CoRR},
	Timestamp = {Mon, 01 Apr 2019 14:07:37 +0200},
	Title = {Networks for Joint Affine and Non-parametric Image Registration},
	Url = {http://arxiv.org/abs/1903.08811},
	Volume = {abs/1903.08811},
	Year = {2019},
	Bdsk-Url-1 = {http://arxiv.org/abs/1903.08811}}

@article{Chee:2018aa,
	Archiveprefix = {arXiv},
	Author = {Evelyn Chee and Zhenzhou Wu},
	Bibsource = {dblp computer science bibliography, https://dblp.org},
	Biburl = {https://dblp.org/rec/bib/journals/corr/abs-1810-02583},
	Date-Added = {2019-04-16 13:30:03 -0400},
	Date-Modified = {2019-04-16 13:30:46 -0400},
	Eprint = {1810.02583},
	Journal = {CoRR},
	Timestamp = {Tue, 30 Oct 2018 10:49:09 +0100},
	Title = {AIRNet: Self-Supervised Affine Registration for 3D Medical Images using Neural Networks},
	Url = {http://arxiv.org/abs/1810.02583},
	Volume = {abs/1810.02583},
	Year = {2018},
	Bdsk-Url-1 = {http://arxiv.org/abs/1810.02583}}

@article{Altaf:2019aa,
	Author = {Fouzia Altaf and Syed M. S. Islam and Naveed Akhtar and Naeem K. Janjua},
	Date-Added = {2019-03-11 06:56:39 -0700},
	Date-Modified = {2019-03-11 07:00:12 -0700},
	Journal = {arXiv preprint},
	Title = {Going Deep in Medical Image Analysis: Concepts, Methods, Challenges and Future Directions},
	Year = {2019}}

@article{Lorenzi:2013aa,
	Abstract = {Non-linear registration is a key instrument for computational anatomy to study the morphology of organs and tissues. However, in order to be an effective instrument for the clinical practice, registration algorithms must be computationally efficient, accurate and most importantly robust to the multiple biases affecting medical images. In this work we propose a fast and robust registration framework based on the log-Demons diffeomorphic registration algorithm. The transformation is parameterized by stationary velocity fields (SVFs), and the similarity metric implements a symmetric local correlation coefficient (LCC). Moreover, we show how the SVF setting provides a stable and consistent numerical scheme for the computation of the Jacobian determinant and the flux of the deformation across the boundaries of a given region. Thus, it provides a robust evaluation of spatial changes. We tested the LCC-Demons in the inter-subject registration setting, by comparing with state-of-the-art registration algorithms on public available datasets, and in the intra-subject longitudinal registration problem, for the statistically powered measurements of the longitudinal atrophy in Alzheimer's disease. Experimental results show that LCC-Demons is a generic, flexible, efficient and robust algorithm for the accurate non-linear registration of images, which can find several applications in the field of medical imaging. Without any additional optimization, it solves equally well intra & inter-subject registration problems, and compares favorably to state-of-the-art methods. },
	Author = {Lorenzi, M and Ayache, N and Frisoni, G B and Pennec, X and {Alzheimer's Disease Neuroimaging Initiative (ADNI)}},
	Date-Added = {2019-01-15 21:58:04 -0800},
	Date-Modified = {2019-01-15 21:58:04 -0800},
	Doi = {10.1016/j.neuroimage.2013.04.114},
	Journal = {Neuroimage},
	Journal-Full = {NeuroImage},
	Keywords = {Alzheimer's disease; Demons; Longitudinal atrophy; Non-linear registration; Optimization},
	Mesh = {Algorithms; Alzheimer Disease; Atrophy; Brain; Humans; Image Interpretation, Computer-Assisted; Neuroimaging},
	Month = {Nov},
	Pages = {470-483},
	Pmid = {23685032},
	Pst = {ppublish},
	Title = {LCC-Demons: a robust and accurate symmetric diffeomorphic registration algorithm},
	Volume = {81},
	Year = {2013},
	Bdsk-Url-1 = {https://doi.org/10.1016/j.neuroimage.2013.04.114}}

@inproceedings{Kingma:2014aa,
	Author = {Diederik P. Kingma and Max Welling},
	Booktitle = {Proceedings of the 2nd {I}nternational {C}onference on {L}earning {R}epresentations ({ICLR})},
	Date-Added = {2019-01-15 21:39:27 -0800},
	Date-Modified = {2019-05-21 21:47:54 -0700},
	Title = {Auto-Encoding Variational Bayes},
	Year = {2014}}

@incollection{Sohn:2015aa,
	Author = {Sohn, Kihyuk and Lee, Honglak and Yan, Xinchen},
	Booktitle = {Advances in {N}eural {I}nformation {P}rocessing {S}ystems 28},
	Date-Added = {2019-01-15 21:36:21 -0800},
	Date-Modified = {2019-05-21 21:48:48 -0700},
	Editor = {C. Cortes and N. D. Lawrence and D. D. Lee and M. Sugiyama and R. Garnett},
	Pages = {3483--3491},
	Publisher = {Curran Associates, Inc.},
	Title = {Learning Structured Output Representation using Deep Conditional Generative Models},
	Year = {2015},
	Bdsk-Url-1 = {http://papers.nips.cc/paper/5775-learning-structured-output-representation-using-deep-conditional-generative-models.pdf}}

@article{Krebs:2018ab,
	Archiveprefix = {arXiv},
	Author = {Julian Krebs and Tommaso Mansi and Boris Mailh{\'{e}} and Nicholas Ayache and Herv{\'{e}} Delingette},
	Bibsource = {dblp computer science bibliography, https://dblp.org},
	Biburl = {https://dblp.org/rec/bib/journals/corr/abs-1804-07172},
	Date-Added = {2019-01-15 18:54:14 -0800},
	Date-Modified = {2019-05-21 15:05:37 -0700},
	Eprint = {1804.07172},
	Journal = {CoRR},
	Timestamp = {Mon, 13 Aug 2018 16:47:37 +0200},
	Title = {Learning Structured Deformations using Diffeomorphic Registration},
	Url = {http://arxiv.org/abs/1804.07172},
	Volume = {abs/1804.07172},
	Year = {2018},
	Bdsk-Url-1 = {http://arxiv.org/abs/1804.07172}}

@article{Tustison:2018aa,
	Abstract = {RATIONALE AND OBJECTIVES: We propose an automated segmentation pipeline based on deep learning for proton lung MRI segmentation and ventilation-based quantification which improves on our previously reported methodologies in terms of computational efficiency while demonstrating accuracy and robustness. The large data requirement for the proposed framework is made possible by a novel template-based data augmentation strategy. Supporting this work is the open-source ANTsRNet-a growing repository of well-known deep learning architectures first introduced here.
MATERIALS AND METHODS: Deep convolutional neural network (CNN) models were constructed and trained using a custom multilabel Dice metric loss function and a novel template-based data augmentation strategy. Training (including template generation and data augmentation) employed 205 proton MR images and 73 functional lung MRI. Evaluation was performed using data sets of size 63 and 40 images, respectively.
RESULTS: Accuracy for CNN-based proton lung MRI segmentation (in terms of Dice overlap) was left lung: 0.93 $\pm$ 0.03, right lung: 0.94 $\pm$ 0.02, and whole lung: 0.94 $\pm$ 0.02. Although slightly less accurate than our previously reported joint label fusion approach (left lung: 0.95 $\pm$ 0.02, right lung: 0.96 $\pm$ 0.01, and whole lung: 0.96 $\pm$ 0.01), processing time is <1 second per subject for the proposed approach versus âˆ¼30 minutes per subject using joint label fusion. Accuracy for quantifying ventilation defects was determined based on a consensus labeling where average accuracy (Dice multilabel overlap of ventilation defect regions plus normal region) was 0.94 for the CNN method; 0.92 for our previously reported method; and 0.90, 0.92, and 0.94 for expert readers.
CONCLUSION: The proposed framework yields accurate automated quantification in near real time. CNNs drastically reduce processing time after offline model construction and demonstrate significant future potential for facilitating quantitative analysis of functional lung MRI.},
	Author = {Tustison, Nicholas J and Avants, Brian B and Lin, Zixuan and Feng, Xue and Cullen, Nicholas and Mata, Jaime F and Flors, Lucia and Gee, James C and Altes, Talissa A and Mugler Iii, John P and Qing, Kun},
	Date-Added = {2019-01-04 09:19:08 -0800},
	Date-Modified = {2019-01-04 09:19:08 -0800},
	Doi = {10.1016/j.acra.2018.08.003},
	Journal = {Acad Radiol},
	Journal-Full = {Academic radiology},
	Keywords = {ANTsRNet; Advanced Normalization Tools; Hyperpolarized gas imaging; Neural networks; Proton lung MRI; U-net},
	Month = {Sep},
	Pmid = {30195415},
	Pst = {aheadofprint},
	Title = {Convolutional Neural Networks with Template-Based Data Augmentation for Functional Lung Image Quantification},
	Year = {2018},
	Bdsk-Url-1 = {https://doi.org/10.1016/j.acra.2018.08.003}}

@inproceedings{niftynet18,
	Author = {Eli Gibson and Wenqi Li and Carole Sudre and Lucas Fidon and Dzhoshkun I. Shakir and Guotai Wang and Zach Eaton-Rosen and Robert Gray and Tom Doel and Yipeng Hu and Tom Whyntie and Parashkev Nachev and Marc Modat and Dean C. Barratt and S{\'e}bastien Ourselin and M. Jorge Cardoso and Tom Vercauteren},
	Date-Added = {2019-01-04 09:18:44 -0800},
	Date-Modified = {2019-01-04 09:18:44 -0800},
	Doi = {https://doi.org/10.1016/j.cmpb.2018.01.025},
	Issn = {0169-2607},
	Journal = {Computer Methods and Programs in Biomedicine},
	Title = {NiftyNet: a deep-learning platform for medical imaging},
	Url = {https://www.sciencedirect.com/science/article/pii/S0169260717311823},
	Year = {2018},
	Bdsk-Url-1 = {https://www.sciencedirect.com/science/article/pii/S0169260717311823},
	Bdsk-Url-2 = {https://doi.org/10.1016/j.cmpb.2018.01.025}}

@article{Zhang:2018aa,
	Archiveprefix = {arXiv},
	Author = {Jun Zhang},
	Bibsource = {dblp computer science bibliography, https://dblp.org},
	Biburl = {https://dblp.org/rec/bib/journals/corr/abs-1809-03443},
	Date-Added = {2019-01-04 09:02:52 -0800},
	Date-Modified = {2019-01-04 09:03:08 -0800},
	Eprint = {1809.03443},
	Journal = {CoRR},
	Timestamp = {Fri, 05 Oct 2018 11:34:52 +0200},
	Title = {Inverse-Consistent Deep Networks for Unsupervised Deformable Image Registration},
	Url = {http://arxiv.org/abs/1809.03443},
	Volume = {abs/1809.03443},
	Year = {2018},
	Bdsk-Url-1 = {http://arxiv.org/abs/1809.03443}}

@inproceedings{Arsigny:2006aa,
	Abstract = {In this article, we focus on the computation of statistics of invertible geometrical deformations (i.e., diffeomorphisms), based on the generalization to this type of data of the notion of principal logarithm. Remarkably, this logarithm is a simple 3D vector field, and is well-defined for diffeomorphisms close enough to the identity. This allows to perform vectorial statistics on diffeomorphisms, while preserving the invertibility constraint, contrary to Euclidean statistics on displacement fields. We also present here two efficient algorithms to compute logarithms of diffeomorphisms and exponentials of vector fields, whose accuracy is studied on synthetic data. Finally, we apply these tools to compute the mean of a set of diffeomorphisms, in the context of a registration experiment between an atlas an a database of 9 T1 MR images of the human brain.},
	Author = {Arsigny, Vincent and Commowick, Olivier and Pennec, Xavier and Ayache, Nicholas},
	Booktitle = {Proceedings of the {I}nternational {C}onference on {M}edical {I}mage {C}omputing and {C}omputer-{A}ssisted {I}ntervention},
	Date-Added = {2019-01-03 21:11:08 -0800},
	Date-Modified = {2019-05-21 21:55:06 -0700},
	Journal-Full = {Medical image computing and computer-assisted intervention : MICCAI ... International Conference on Medical Image Computing and Computer-Assisted Intervention},
	Mesh = {Algorithms; Artificial Intelligence; Brain; Computer Simulation; Data Interpretation, Statistical; Humans; Image Enhancement; Image Interpretation, Computer-Assisted; Imaging, Three-Dimensional; Magnetic Resonance Imaging; Models, Neurological; Models, Statistical; Pattern Recognition, Automated; Reproducibility of Results; Sensitivity and Specificity; Subtraction Technique},
	Number = {Pt 1},
	Pages = {924-31},
	Pmid = {17354979},
	Pst = {ppublish},
	Title = {A log-Euclidean framework for statistics on diffeomorphisms},
	Volume = {9},
	Year = {2006}}

@article{Yoo:2005aa,
	Author = {Yoo, Terry S and Metaxas, Dimitris N},
	Date-Added = {2019-01-03 20:31:38 -0800},
	Date-Modified = {2019-01-03 20:31:38 -0800},
	Doi = {10.1016/j.media.2005.04.008},
	Journal = {Med Image Anal},
	Journal-Full = {Medical image analysis},
	Mesh = {Databases, Factual; Diagnostic Imaging; Image Interpretation, Computer-Assisted; Information Dissemination; Medical Informatics Applications; National Library of Medicine (U.S.); Science; Software; United States},
	Month = {Dec},
	Number = {6},
	Pages = {503-6},
	Pmid = {16169766},
	Pst = {ppublish},
	Title = {Open science--combining open data and open source software: medical image analysis with the Insight Toolkit},
	Volume = {9},
	Year = {2005},
	Bdsk-Url-1 = {https://doi.org/10.1016/j.media.2005.04.008}}

@incollection{Valpola:2015aa,
	Abstract = {A network supporting deep unsupervised learning is presented. The network is an autoencoder with lateral shortcut connections from the encoder to the decoder at each level of the hierarchy. The lateral shortcut connections allow the higher levels of the hierarchy to focus on abstract invariant features. Whereas autoencoders are analogous to latent variable models with a single layer of stochastic variables, the proposed network is analogous to hierarchical latent variable models. Learning combines denoising autoencoder and denoising sources separation frameworks. Each layer of the network contributes to the cost function a term which measures the distance of the representations produced by the encoder and the decoder. Since training signals originate from all levels of the network, all layers can learn efficiently even in deep networks. The speedup offered by cost terms from higher levels of the hierarchy and the ability to learn invariant features are demonstrated in experiments.},
	Author = {Harri Valpola},
	Booktitle = {Advances in Independent Component Analysis and Learning Machines},
	Date-Added = {2019-01-03 19:34:46 -0800},
	Date-Modified = {2019-05-21 22:00:55 -0700},
	Doi = {https://doi.org/10.1016/B978-0-12-802806-3.00008-7},
	Editor = {Ella Bingham and Samuel Kaski and Jorma Laaksonen and Jouko Lampinen},
	Isbn = {978-0-12-802806-3},
	Keywords = {unsupervised learning, deep learning, ladder network, denoising source separation, denoising autoencoder, invariant features},
	Pages = {143 - 171},
	Publisher = {Academic Press},
	Title = {Chapter 8 - From neural {PCA} to deep unsupervised learning},
	Year = {2015},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/B9780128028063000087},
	Bdsk-Url-2 = {https://doi.org/10.1016/B978-0-12-802806-3.00008-7}}

@inproceedings{Long:2015aa,
	Author = {J. Long and E. Shelhamer and T. Darrell},
	Booktitle = {Proceedings of the {IEEE} {C}onference on {C}omputer {V}ision and {P}attern {R}ecognition},
	Date-Added = {2019-01-03 18:18:37 -0800},
	Date-Modified = {2019-05-21 22:02:37 -0700},
	Doi = {10.1109/CVPR.2015.7298965},
	Issn = {1063-6919},
	Keywords = {image classification;image segmentation;inference mechanisms;learning (artificial intelligence);fully convolutional networks;semantic segmentation;visual models;pixels-to-pixels;inference;learning;contemporary classification networks;PASCAL VOC;NYUDv2;SIFT flow;Semantics;Training;Convolution;Image segmentation;Computer architecture;Deconvolution;Adaptation models},
	Month = {June},
	Pages = {3431-3440},
	Title = {Fully convolutional networks for semantic segmentation},
	Year = {2015},
	Bdsk-Url-1 = {https://doi.org/10.1109/CVPR.2015.7298965}}

@article{Lathuiliere:2018aa,
	Archiveprefix = {arXiv},
	Author = {St{\'{e}}phane Lathuili{\`{e}}re and Pablo Mesejo and Xavier Alameda{-}Pineda and Radu Horaud},
	Bibsource = {dblp computer science bibliography, https://dblp.org},
	Biburl = {https://dblp.org/rec/bib/journals/corr/abs-1803-08450},
	Date-Added = {2019-01-03 08:56:44 -0800},
	Date-Modified = {2019-01-03 08:57:05 -0800},
	Eprint = {1803.08450},
	Journal = {CoRR},
	Timestamp = {Mon, 13 Aug 2018 16:48:48 +0200},
	Title = {A Comprehensive Analysis of Deep Regression},
	Url = {http://arxiv.org/abs/1803.08450},
	Volume = {abs/1803.08450},
	Year = {2018},
	Bdsk-Url-1 = {http://arxiv.org/abs/1803.08450}}

@article{Christensen:2001aa,
	Abstract = {This paper presents a new method for image registration based on jointly estimating the forward and reverse transformations between two images while constraining these transforms to be inverses of one another. This approach produces a consistent set of transformations that have less pairwise registration error, i.e., better correspondence, than traditional methods that estimate the forward and reverse transformations independently. The transformations are estimated iteratively and are restricted to preserve topology by constraining them to obey the laws of continuum mechanics. The transformations are parameterized by a Fourier series to diagonalize the covariance structure imposed by the continuum mechanics constraints and to provide a computationally efficient numerical implementation. Results using a linear elastic material constraint are presented using both magnetic resonance and X-ray computed tomography image data. The results show that the joint estimation of a consistent set of forward and reverse transformations constrained by linear-elasticity give better registration results than using either constraint alone or none at all.},
	Author = {Christensen, G E and Johnson, H J},
	Date-Added = {2019-01-02 12:03:05 -0800},
	Date-Modified = {2019-01-02 12:03:05 -0800},
	Doi = {10.1109/42.932742},
	Journal = {IEEE Trans Med Imaging},
	Journal-Full = {IEEE transactions on medical imaging},
	Mesh = {Algorithms; Brain; Fourier Analysis; Humans; Image Interpretation, Computer-Assisted; Image Processing, Computer-Assisted; Magnetic Resonance Imaging; Mathematics; Tomography, X-Ray Computed},
	Month = {Jul},
	Number = {7},
	Pages = {568-82},
	Pmid = {11465464},
	Pst = {ppublish},
	Title = {Consistent image registration},
	Volume = {20},
	Year = {2001},
	Bdsk-Url-1 = {https://doi.org/10.1109/42.932742}}

@article{Johnson:2002aa,
	Abstract = {Two new consistent image registration algorithms are presented: one is based on matching corresponding landmarks and the other is based on matching both landmark and intensity information. The consistent landmark and intensity registration algorithm produces good correspondences between images near landmark locations by matching corresponding landmarks and away from landmark locations by matching the image intensities. In contrast to similar unidirectional algorithms, these new consistent algorithms jointly estimate the forward and reverse transformation between two images while minimizing the inverse consistency error-the error between the forward (reverse) transformation and the inverse of the the reverse (forward) transformation. This reduces the ambiguous correspondence between the forward and reverse transformations associated with large inverse consistency errors. In both algorithms a thin-plate spline (TPS) model is used to regularize the estimated transformations. Two-dimensional (2-D) examples are presented that show the inverse consistency error produced by the traditional unidirectional landmark TPS algorithm can be relatively large and that this error is minimized using the consistent landmark algorithm. Results using 2-D magnetic resonance imaging data are presented that demonstrate that using landmark and intensity information together produce better correspondence between medical images than using either landmarks or intensity information alone.},
	Author = {Johnson, H J and Christensen, G E},
	Date-Added = {2019-01-02 12:03:04 -0800},
	Date-Modified = {2019-01-02 12:03:04 -0800},
	Doi = {10.1109/TMI.2002.1009381},
	Journal = {IEEE Trans Med Imaging},
	Journal-Full = {IEEE transactions on medical imaging},
	Mesh = {Algorithms; Brain; Computer Simulation; Humans; Image Enhancement; Image Interpretation, Computer-Assisted; Magnetic Resonance Imaging; Reproducibility of Results; Sensitivity and Specificity; Subtraction Technique},
	Month = {May},
	Number = {5},
	Pages = {450-61},
	Pmid = {12071616},
	Pst = {ppublish},
	Title = {Consistent landmark and intensity-based image registration},
	Volume = {21},
	Year = {2002},
	Bdsk-Url-1 = {https://doi.org/10.1109/TMI.2002.1009381}}

@article{Rueckert:1999aa,
	Abstract = {In this paper we present a new approach for the nonrigid registration of contrast-enhanced breast MRI. A hierarchical transformation model of the motion of the breast has been developed. The global motion of the breast is modeled by an affine transformation while the local breast motion is described by a free-form deformation (FFD) based on B-splines. Normalized mutual information is used as a voxel-based similarity measure which is insensitive to intensity changes as a result of the contrast enhancement. Registration is achieved by minimizing a cost function, which represents a combination of the cost associated with the smoothness of the transformation and the cost associated with the image similarity. The algorithm has been applied to the fully automated registration of three-dimensional (3-D) breast MRI in volunteers and patients. In particular, we have compared the results of the proposed nonrigid registration algorithm to those obtained using rigid and affine registration techniques. The results clearly indicate that the nonrigid registration algorithm is much better able to recover the motion and deformation of the breast than rigid or affine registration algorithms.},
	Author = {Rueckert, D and Sonoda, L I and Hayes, C and Hill, D L and Leach, M O and Hawkes, D J},
	Date-Added = {2019-01-01 19:53:49 -0800},
	Date-Modified = {2019-05-21 22:10:38 -0700},
	Doi = {10.1109/42.796284},
	Journal = {IEEE Trans Med Imaging},
	Journal-Full = {IEEE transactions on medical imaging},
	Mesh = {Breast; Female; Humans; Image Processing, Computer-Assisted; Magnetic Resonance Imaging},
	Month = {Aug},
	Number = {8},
	Pages = {712-21},
	Pmid = {10534053},
	Pst = {ppublish},
	Title = {Nonrigid registration using free-form deformations: application to breast {MR} images},
	Volume = {18},
	Year = {1999},
	Bdsk-Url-1 = {https://doi.org/10.1109/42.796284}}

@article{Klein:2010aa,
	Abstract = {Medical image registration is an important task in medical image processing. It refers to the process of aligning data sets, possibly from different modalities (e.g., magnetic resonance and computed tomography), different time points (e.g., follow-up scans), and/or different subjects (in case of population studies). A large number of methods for image registration are described in the literature. Unfortunately, there is not one method that works for all applications. We have therefore developed elastix, a publicly available computer program for intensity-based medical image registration. The software consists of a collection of algorithms that are commonly used to solve medical image registration problems. The modular design of elastix allows the user to quickly configure, test, and compare different registration methods for a specific application. The command-line interface enables automated processing of large numbers of data sets, by means of scripting. The usage of elastix for comparing different registration methods is illustrated with three example experiments, in which individual components of the registration method are varied.},
	Author = {Klein, Stefan and Staring, Marius and Murphy, Keelin and Viergever, Max A and Pluim, Josien P W},
	Date-Added = {2019-01-01 19:53:07 -0800},
	Date-Modified = {2019-01-01 19:53:07 -0800},
	Doi = {10.1109/TMI.2009.2035616},
	Journal = {IEEE Trans Med Imaging},
	Journal-Full = {IEEE transactions on medical imaging},
	Mesh = {Diagnostic Imaging; Humans; Image Processing, Computer-Assisted; Models, Biological; Normal Distribution; Software},
	Month = {Jan},
	Number = {1},
	Pages = {196-205},
	Pmid = {19923044},
	Pst = {ppublish},
	Title = {elastix: a toolbox for intensity-based medical image registration},
	Volume = {29},
	Year = {2010},
	Bdsk-Url-1 = {https://doi.org/10.1109/TMI.2009.2035616}}

@article{Woods:1993aa,
	Abstract = {OBJECTIVE: We have previously reported an automated method for within-modality (e.g., PET-to-PET) image alignment. We now describe modifications to this method that allow for cross-modality registration of MRI and PET brain images obtained from a single subject.
METHODS: This method does not require fiducial markers and the user is not required to identify common structures on the two image sets. To align the images, the algorithm seeks to minimize the standard deviation of the PET pixel values that correspond to each MRI pixel value. The MR images must be edited to exclude nonbrain regions prior to using the algorithm.
RESULTS AND CONCLUSION: The method has been validated quantitatively using data from patients with stereotaxic fiducial markers rigidly fixed in the skull. Maximal three-dimensional errors of < 3 mm and mean three-dimensional errors of < 2 mm were measured. Computation time on a SPARCstation IPX varies from 3 to 9 min to align MR image sets with [18F]fluorodeoxyglucose PET images. The MR alignment with noisy H2(15)O PET images typically requires 20-30 min.},
	Author = {Woods, R P and Mazziotta, J C and Cherry, S R},
	Date = {1993 Jul-Aug},
	Date-Added = {2019-01-01 19:51:23 -0800},
	Date-Modified = {2019-01-01 19:51:23 -0800},
	Journal = {J Comput Assist Tomogr},
	Journal-Full = {Journal of computer assisted tomography},
	Mesh = {Adult; Algorithms; Brain; Deoxyglucose; Epilepsy; Female; Fluorine Radioisotopes; Fluorodeoxyglucose F18; Humans; Image Processing, Computer-Assisted; Magnetic Resonance Imaging; Male; Time Factors; Tomography, Emission-Computed},
	Number = {4},
	Pages = {536-46},
	Pmid = {8331222},
	Pst = {ppublish},
	Title = {MRI-PET registration with automated algorithm},
	Volume = {17},
	Year = {1993}}

@article{Avants:2011aa,
	Abstract = {The United States National Institutes of Health (NIH) commit significant support to open-source data and software resources in order to foment reproducibility in the biomedical imaging sciences. Here, we report and evaluate a recent product of this commitment: Advanced Neuroimaging Tools (ANTs), which is approaching its 2.0 release. The ANTs open source software library consists of a suite of state-of-the-art image registration, segmentation and template building tools for quantitative morphometric analysis. In this work, we use ANTs to quantify, for the first time, the impact of similarity metrics on the affine and deformable components of a template-based normalization study. We detail the ANTs implementation of three similarity metrics: squared intensity difference, a new and faster cross-correlation, and voxel-wise mutual information. We then use two-fold cross-validation to compare their performance on openly available, manually labeled, T1-weighted MRI brain image data of 40 subjects (UCLA's LPBA40 dataset). We report evaluation results on cortical and whole brain labels for both the affine and deformable components of the registration. Results indicate that the best ANTs methods are competitive with existing brain extraction results (Jaccard=0.958) and cortical labeling approaches. Mutual information affine mapping combined with cross-correlation diffeomorphic mapping gave the best cortical labeling results (Jaccard=0.669$\pm$0.022). Furthermore, our two-fold cross-validation allows us to quantify the similarity of templates derived from different subgroups. Our open code, data and evaluation scripts set performance benchmark parameters for this state-of-the-art toolkit. This is the first study to use a consistent transformation framework to provide a reproducible evaluation of the isolated effect of the similarity metric on optimal template construction and brain labeling.},
	Author = {Avants, Brian B and Tustison, Nicholas J and Song, Gang and Cook, Philip A and Klein, Arno and Gee, James C},
	Date-Added = {2019-01-01 19:50:12 -0800},
	Date-Modified = {2019-05-21 22:10:09 -0700},
	Doi = {10.1016/j.neuroimage.2010.09.025},
	Journal = {Neuroimage},
	Journal-Full = {NeuroImage},
	Mesh = {Algorithms; Brain; Databases, Factual; Diagnostic Imaging; Head; Humans; Image Processing, Computer-Assisted; Linear Models; Models, Anatomic; Models, Neurological; Population; Reproducibility of Results; Software},
	Month = {Feb},
	Number = {3},
	Pages = {2033-44},
	Pmc = {PMC3065962},
	Pmid = {20851191},
	Pst = {ppublish},
	Title = {A reproducible evaluation of {ANTs} similarity metric performance in brain image registration},
	Volume = {54},
	Year = {2011},
	Bdsk-Url-1 = {https://doi.org/10.1016/j.neuroimage.2010.09.025}}

@article{Shen:2002aa,
	Abstract = {A new approach is presented for elastic registration of medical images, and is applied to magnetic resonance images of the brain. Experimental results demonstrate very high accuracy in superposition of images from different subjects. There are two major novelties in the proposed algorithm. First, it uses an attribute vector, i.e., a set of geometric moment invariants (GMIs) that are defined on each voxel in an image and are calculated from the tissue maps, to reflect the underlying anatomy at different scales. The attribute vector, if rich enough, can distinguish between different parts of an image, which helps establish anatomical correspondences in the deformation procedure; it also helps reduce local minima, by reducing ambiguity in potential matches. This is a fundamental deviation of our method, referred to as the hierarchical attribute matching mechanism for elastic registration (HAMMER), from other volumetric deformation methods, which are typically based on maximizing image similarity. Second, in order to avoid being trapped by local minima, i.e., suboptimal poor matches, HAMMER uses a successive approximation of the energy function being optimized by lower dimensional smooth energy functions, which are constructed to have significantly fewer local minima. This is achieved by hierarchically selecting the driving features that have distinct attribute vectors, thus, drastically reducing ambiguity in finding correspondence. A number of experiments demonstrate that the proposed algorithm results in accurate superposition of image data from individuals with significant anatomical differences.},
	Author = {Shen, Dinggang and Davatzikos, Christos},
	Date-Added = {2018-12-31 14:26:47 -0800},
	Date-Modified = {2018-12-31 14:26:47 -0800},
	Doi = {10.1109/TMI.2002.803111},
	Journal = {IEEE Trans Med Imaging},
	Journal-Full = {IEEE transactions on medical imaging},
	Mesh = {Aged; Algorithms; Atrophy; Brain; Elasticity; Humans; Image Enhancement; Magnetic Resonance Imaging; Pattern Recognition, Automated; Quality Control; Reproducibility of Results; Sensitivity and Specificity; Stochastic Processes; Subtraction Technique},
	Month = {Nov},
	Number = {11},
	Pages = {1421-39},
	Pmid = {12575879},
	Pst = {ppublish},
	Title = {HAMMER: hierarchical attribute matching mechanism for elastic registration},
	Volume = {21},
	Year = {2002},
	Bdsk-Url-1 = {https://doi.org/10.1109/TMI.2002.803111}}

@article{Wang:2010aa,
	Abstract = {Groupwise registration has been recently introduced to simultaneously register a group of images by avoiding the selection of a particular template. To achieve this, several methods have been proposed to take advantage of information-theoretic entropy measures based on image intensity. However, simplistic utilization of voxelwise image intensity is not sufficient to establish reliable correspondences, since it lacks important contextual information. Therefore, we explore the notion of attribute vector as the voxel signature, instead of image intensity, to guide the correspondence detection in groupwise registration. In particular, for each voxel, the attribute vector is computed from its multi-scale neighborhoods, in order to capture the geometric information at different scales. The probability density function (PDF) of each element in the attribute vector is then estimated from the local neighborhood, providing a statistical summary of the underlying anatomical structure in that local pattern. Eventually, with the help of Jensen-Shannon (JS) divergence, a group of subjects can be aligned simultaneously by minimizing the sum of JS divergences across the image domain and all attributes. We have employed our groupwise registration algorithm on both real (NIREP NA0 data set) and simulated data (12 pairs of normal control and simulated atrophic data set). The experimental results demonstrate that our method yields better registration accuracy, compared with a popular groupwise registration method.},
	Author = {Wang, Qian and Wu, Guorong and Yap, Pew-Thian and Shen, Dinggang},
	Date-Added = {2018-12-31 14:21:13 -0800},
	Date-Modified = {2018-12-31 14:21:13 -0800},
	Doi = {10.1016/j.neuroimage.2010.01.040},
	Journal = {Neuroimage},
	Journal-Full = {NeuroImage},
	Mesh = {Algorithms; Brain; Brain Diseases; Computer Simulation; Databases, Factual; Humans; Image Processing, Computer-Assisted; Magnetic Resonance Imaging; Probability},
	Month = {May},
	Number = {4},
	Pages = {1485-96},
	Pmc = {PMC2839051},
	Pmid = {20097291},
	Pst = {ppublish},
	Title = {Attribute vector guided groupwise registration},
	Volume = {50},
	Year = {2010},
	Bdsk-Url-1 = {https://doi.org/10.1016/j.neuroimage.2010.01.040}}

@article{Cheng:2016aa,
	Author = {Xi Cheng and Li Zhang and Yefeng Zheng},
	Date-Added = {2018-12-31 13:50:24 -0800},
	Date-Modified = {2018-12-31 13:51:27 -0800},
	Doi = {10.1080/21681163.2015.1135299},
	Eprint = {https://doi.org/10.1080/21681163.2015.1135299},
	Journal = {Computer Methods in Biomechanics and Biomedical Engineering: Imaging \& Visualization},
	Number = {3},
	Pages = {248-252},
	Publisher = {Taylor & Francis},
	Title = {Deep similarity learning for multimodal medical images},
	Url = {https://doi.org/10.1080/21681163.2015.1135299},
	Volume = {6},
	Year = {2016},
	Bdsk-Url-1 = {https://doi.org/10.1080/21681163.2015.1135299}}

@article{Glocker:2011aa,
	Abstract = {This review introduces a novel deformable image registration paradigm that exploits Markov random field formulation and powerful discrete optimization algorithms. We express deformable registration as a minimal cost graph problem, where nodes correspond to the deformation grid, a node's connectivity corresponds to regularization constraints, and labels correspond to 3D deformations. To cope with both iconic and geometric (landmark-based) registration, we introduce two graphical models, one for each subproblem. The two graphs share interconnected variables, leading to a modular, powerful, and flexible formulation that can account for arbitrary image-matching criteria, various local deformation models, and regularization constraints. To cope with the corresponding optimization problem, we adopt two optimization strategies: a computationally efficient one and a tight relaxation alternative. Promising results demonstrate the potential of this approach. Discrete methods are an important new trend in medical image registration, as they provide several improvements over the more traditional continuous methods. This is illustrated with several key examples where the presented framework outperforms existing general-purpose registration methods in terms of both performance and computational complexity. Our methods become of particular interest in applications where computation time is a critical issue, as in intraoperative imaging, or where the huge variation in data demands complex and application-specific matching criteria, as in large-scale multimodal population studies. The proposed registration framework, along with a graphical interface and corresponding publications, is available for download for research purposes (for Windows and Linux platforms) from http://www.mrf-registration.net.},
	Author = {Glocker, Ben and Sotiras, Aristeidis and Komodakis, Nikos and Paragios, Nikos},
	Date-Added = {2018-12-31 13:43:53 -0800},
	Date-Modified = {2018-12-31 13:43:53 -0800},
	Doi = {10.1146/annurev-bioeng-071910-124649},
	Journal = {Annu Rev Biomed Eng},
	Journal-Full = {Annual review of biomedical engineering},
	Mesh = {Algorithms; Four-Dimensional Computed Tomography; Humans; Image Enhancement; Image Processing, Computer-Assisted; Linear Models; Markov Chains; Pattern Recognition, Automated; Reproducibility of Results; Subtraction Technique; Thorax},
	Month = {Aug},
	Pages = {219-44},
	Pmid = {21568711},
	Pst = {ppublish},
	Title = {Deformable medical image registration: setting the state of the art with discrete methods},
	Volume = {13},
	Year = {2011},
	Bdsk-Url-1 = {https://doi.org/10.1146/annurev-bioeng-071910-124649}}

@article{Brox:2011aa,
	Abstract = {Optical flow estimation is classically marked by the requirement of dense sampling in time. While coarse-to-fine warping schemes have somehow relaxed this constraint, there is an inherent dependency between the scale of structures and the velocity that can be estimated. This particularly renders the estimation of detailed human motion problematic, as small body parts can move very fast. In this paper, we present a way to approach this problem by integrating rich descriptors into the variational optical flow setting. This way we can estimate a dense optical flow field with almost the same high accuracy as known from variational optical flow, while reaching out to new domains of motion analysis where the requirement of dense sampling in time is no longer satisfied.},
	Author = {Brox, Thomas and Malik, Jitendra},
	Date-Added = {2018-12-31 13:11:40 -0800},
	Date-Modified = {2018-12-31 13:11:40 -0800},
	Doi = {10.1109/TPAMI.2010.143},
	Journal = {IEEE Trans Pattern Anal Mach Intell},
	Journal-Full = {IEEE transactions on pattern analysis and machine intelligence},
	Mesh = {Algorithms; Artificial Intelligence; Computer Simulation; Humans; Image Enhancement; Image Interpretation, Computer-Assisted; Imaging, Three-Dimensional; Information Storage and Retrieval; Models, Theoretical; Motion; Pattern Recognition, Automated; Phantoms, Imaging; Sensitivity and Specificity; Signal Processing, Computer-Assisted; Subtraction Technique; Video Recording},
	Month = {Mar},
	Number = {3},
	Pages = {500-13},
	Pmid = {20714020},
	Pst = {ppublish},
	Title = {Large displacement optical flow: descriptor matching in variational motion estimation},
	Volume = {33},
	Year = {2011},
	Bdsk-Url-1 = {https://doi.org/10.1109/TPAMI.2010.143}}

@article{Fischler:1981aa,
	Author = {Martin A. Fischler and Robert C. Bolles},
	Date-Added = {2018-12-31 13:00:27 -0800},
	Date-Modified = {2018-12-31 13:01:45 -0800},
	Journal = {Comm. ACM.},
	Number = {6},
	Pages = {381--395},
	Title = {Random Sample Consensus: A Paradigm for Model Fitting with Applications to Image Analysis and Automated Cartography},
	Volume = {24},
	Year = {1981}}

@inproceedings{Hu:2018ac,
	Author = {Yipeng Hu and Eli Gibson and Nooshin Ghavami and Ester Bonmati and Caroline M. Moore and Mark Emberton and Tom Vercauteren and J. Alison Noble and Dean C. Barratt},
	Booktitle = {Proceedings of the {I}nternational {C}onference on {M}edical {I}mage {C}omputing and {C}omputer-{A}ssisted {I}ntervention},
	Date-Added = {2018-12-31 11:11:57 -0800},
	Date-Modified = {2019-05-21 21:33:19 -0700},
	Title = {Adversarial Deformation Regularization for Training Image Registration Neural Networks},
	Year = {2018}}

@article{Wang:2004aa,
	Abstract = {Objective methods for assessing perceptual image quality traditionally attempted to quantify the visibility of errors (differences) between a distorted image and a reference image using a variety of known properties of the human visual system. Under the assumption that human visual perception is highly adapted for extracting structural information from a scene, we introduce an alternative complementary framework for quality assessment based on the degradation of structural information. As a specific example of this concept, we develop a Structural Similarity Index and demonstrate its promise through a set of intuitive examples, as well as comparison to both subjective ratings and state-of-the-art objective methods on a database of images compressed with JPEG and JPEG2000.},
	Author = {Wang, Zhou and Bovik, Alan Conrad and Sheikh, Hamid Rahim and Simoncelli, Eero P},
	Date-Added = {2018-12-31 11:09:31 -0800},
	Date-Modified = {2018-12-31 11:09:31 -0800},
	Journal = {IEEE Trans Image Process},
	Journal-Full = {IEEE transactions on image processing : a publication of the IEEE Signal Processing Society},
	Mesh = {Algorithms; Data Interpretation, Statistical; Hypermedia; Image Enhancement; Image Interpretation, Computer-Assisted; Information Storage and Retrieval; Models, Statistical; Pattern Recognition, Automated; Quality Control; Reproducibility of Results; Sensitivity and Specificity; Signal Processing, Computer-Assisted; Subtraction Technique},
	Month = {Apr},
	Number = {4},
	Pages = {600-12},
	Pmid = {15376593},
	Pst = {ppublish},
	Title = {Image quality assessment: from error visibility to structural similarity},
	Volume = {13},
	Year = {2004}}

@inproceedings{Radford:2016aa,
	Author = {Alec Radford and Luke Metz and Soumith Chintala},
	Booktitle = {Proceedings of the {I}nternational {C}onference on {L}earning {R}epresentations},
	Date-Added = {2018-12-31 10:48:32 -0800},
	Date-Modified = {2019-05-21 21:59:56 -0700},
	Title = {Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks},
	Year = {2016}}

@inproceedings{Zhu:2017aa,
	Author = {Zhu, Jun-Yan and Park, Taesung and Isola, Phillip and Efros, Alexei A},
	Booktitle = {{IEEE} {I}nternational {C}onference on {C}omputer {V}ision},
	Date-Added = {2018-12-31 08:41:13 -0800},
	Date-Modified = {2019-05-21 21:37:19 -0700},
	Title = {Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks},
	Year = {2017}}

@inproceedings{Goodfellow:2014aa,
	Author = {Ian J. Goodfellow and Jean Pouget-Abadie and Mehdi Mirza and Bing Xu and David Warde-Farley and Sherjil Ozair and Aaron Courville and Yoshua Bengio},
	Booktitle = {Advances in neural information processing systems},
	Date-Added = {2018-12-28 12:54:06 -0800},
	Date-Modified = {2019-05-21 22:05:14 -0700},
	Title = {Generative Adversarial Nets},
	Year = {2014}}

@inproceedings{Bromley:1994aa,
	Author = {J. Bromley and I. Guyon and Y. LeCun and E. Sckinger and R. Shah},
	Booktitle = {{N}eural {I}nformation {P}rocessing {S}ystems},
	Date-Added = {2018-12-27 13:08:44 -0800},
	Date-Modified = {2019-05-21 22:08:36 -0700},
	Title = {Signature verification using a ``siamese'' time delay neural network},
	Year = {1994}}

@article{Lowe2004,
	Abstract = {This paper presents a method for extracting distinctive invariant features from images that can be used to perform reliable matching between different views of an object or scene. The features are invariant to image scale and rotation, and are shown to provide robust matching across a substantial range of affine distortion, change in 3D viewpoint, addition of noise, and change in illumination. The features are highly distinctive, in the sense that a single feature can be correctly matched with high probability against a large database of features from many images. This paper also describes an approach to using these features for object recognition. The recognition proceeds by matching individual features to a database of features from known objects using a fast nearest-neighbor algorithm, followed by a Hough transform to identify clusters belonging to a single object, and finally performing verification through least-squares solution for consistent pose parameters. This approach to recognition can robustly identify objects among clutter and occlusion while achieving near real-time performance.},
	Author = {Lowe, David G.},
	Date-Added = {2018-12-27 13:02:52 -0800},
	Date-Modified = {2019-05-21 22:03:24 -0700},
	Day = {01},
	Doi = {10.1023/B:VISI.0000029664.99615.94},
	Issn = {1573-1405},
	Journal = {International Journal of Computer Vision},
	Month = {Nov},
	Number = {2},
	Pages = {91--110},
	Title = {Distinctive Image Features from Scale-Invariant Keypoints},
	Volume = {60},
	Year = {2004},
	Bdsk-Url-1 = {https://doi.org/10.1023/B:VISI.0000029664.99615.94}}

@inproceedings{Zagoruyko:2015aa,
	Author = {Sergey Zagoruyko and Nikos Komodakis},
	Booktitle = {Proceedings of the {IEEE} {C}onference on {C}omputer {V}ision and {P}attern {R}ecognition},
	Date-Added = {2018-12-27 11:22:01 -0800},
	Date-Modified = {2019-05-21 22:03:05 -0700},
	Title = {Learning to Compare Image Patches via Convolutional Neural Networks},
	Year = {2015}}

@article{Pluim:2000aa,
	Abstract = {Mutual information has developed into an accurate measure for rigid and affine monomodality and multimodality image registration. The robustness of the measure is questionable, however. A possible reason for this is the absence of spatial information in the measure. The present paper proposes to include spatial information by combining mutual information with a term based on the image gradient of the images to be registered. The gradient term not only seeks to align locations of high gradient magnitude, but also aims for a similar orientation of the gradients at these locations. Results of combining both standard mutual information as well as a normalized measure are presented for rigid registration of three-dimensional clinical images [magnetic resonance (MR), computed tomography (CT), and positron emission tomography (PET)]. The results indicate that the combined measures yield a better registration function does mutual information or normalized mutual information per se. The registration functions are less sensitive to low sampling resolution, do not contain incorrect global maxima that are sometimes found in the mutual information function, and interpolation-induced local minima can be reduced. These characteristics yield the promise of more robust registration measures. The accuracy of the combined measures is similar to that of mutual information-based methods.},
	Author = {Pluim, J P and Maintz, J B and Viergever, M A},
	Date-Added = {2018-12-27 11:20:05 -0800},
	Date-Modified = {2018-12-27 11:20:05 -0800},
	Doi = {10.1109/42.876307},
	Journal = {IEEE Trans Med Imaging},
	Journal-Full = {IEEE transactions on medical imaging},
	Mesh = {Entropy; Humans; Imaging, Three-Dimensional; Magnetic Resonance Imaging; Probability; Reproducibility of Results; Tomography, Emission-Computed; Tomography, X-Ray Computed},
	Month = {Aug},
	Number = {8},
	Pages = {809-14},
	Pmid = {11055805},
	Pst = {ppublish},
	Title = {Image registration by maximization of combined mutual information and gradient information},
	Volume = {19},
	Year = {2000},
	Bdsk-Url-1 = {https://doi.org/10.1109/42.876307}}

@article{Baker2004,
	Abstract = {Since the Lucas-Kanade algorithm was proposed in 1981 image alignment has become one of the most widely used techniques in computer vision. Applications range from optical flow and tracking to layered motion, mosaic construction, and face coding. Numerous algorithms have been proposed and a wide variety of extensions have been made to the original formulation. We present an overview of image alignment, describing most of the algorithms and their extensions in a consistent framework. We concentrate on the inverse compositional algorithm, an efficient algorithm that we recently proposed. We examine which of the extensions to Lucas-Kanade can be used with the inverse compositional algorithm without any significant loss of efficiency, and which cannot. In this paper, Part 1 in a series of papers, we cover the quantity approximated, the warp update rule, and the gradient descent approximation. In future papers, we will cover the choice of the error function, how to allow linear appearance variation, and how to impose priors on the parameters.},
	Author = {Baker, Simon and Matthews, Iain},
	Date-Added = {2018-12-25 21:53:38 -0800},
	Date-Modified = {2018-12-25 21:53:38 -0800},
	Day = {01},
	Doi = {10.1023/B:VISI.0000011205.11775.fd},
	Issn = {1573-1405},
	Journal = {International Journal of Computer Vision},
	Month = {Feb},
	Number = {3},
	Pages = {221--255},
	Title = {Lucas-Kanade 20 Years On: A Unifying Framework},
	Url = {https://doi.org/10.1023/B:VISI.0000011205.11775.fd},
	Volume = {56},
	Year = {2004},
	Bdsk-Url-1 = {https://doi.org/10.1023/B:VISI.0000011205.11775.fd}}

@article{Liu:2018aa,
	Author = {Rosanne Liu and Joel Lehman and Piero Molino and Felipe Petroski Such and Eric Frank and Alex Sergeev and Jason Yosinski},
	Date-Added = {2018-12-25 11:55:08 -0800},
	Date-Modified = {2018-12-25 11:56:21 -0800},
	Journal = {arXiv preprint},
	Title = {An Intriguing Failing of Convolutional Neural Networks and the CoordConv Solution},
	Year = {2018}}

@book{Goodfellow:2016aa,
	Author = {Ian Goodfellow and Yoshua Bengio and Aaron Courville},
	Date-Added = {2018-12-24 16:55:29 -0800},
	Date-Modified = {2018-12-24 16:56:14 -0800},
	Publisher = {MIT Press},
	Title = {Deep Learning},
	Year = {2016}}

@article{Bernal:2018aa,
	Abstract = {In recent years, deep convolutional neural networks (CNNs) have shown record-shattering performance in a variety of computer vision problems, such as visual object recognition, detection and segmentation. These methods have also been utilised in medical image analysis domain for lesion segmentation, anatomical segmentation and classification. We present an extensive literature review of CNN techniques applied in brain magnetic resonance imaging (MRI) analysis, focusing on the architectures, pre-processing, data-preparation and post-processing strategies available in these works. The aim of this study is three-fold. Our primary goal is to report how different CNN architectures have evolved, discuss state-of-the-art strategies, condense their results obtained using public datasets and examine their pros and cons. Second, this paper is intended to be a detailed reference of the research activity in deep CNN for brain MRI analysis. Finally, we present a perspective on the future of CNNs in which we hint some of the research directions in subsequent years.},
	Author = {Bernal, Jose and Kushibar, Kaisar and Asfaw, Daniel S and Valverde, Sergi and Oliver, Arnau and Mart{\'\i}, Robert and Llad{\'o}, Xavier},
	Date-Added = {2018-12-24 14:03:09 -0800},
	Date-Modified = {2018-12-24 14:03:09 -0800},
	Doi = {10.1016/j.artmed.2018.08.008},
	Journal = {Artif Intell Med},
	Journal-Full = {Artificial intelligence in medicine},
	Keywords = {Brain MRI; Deep convolutional neural network; Review; Segmentation},
	Month = {Sep},
	Pmid = {30195984},
	Pst = {aheadofprint},
	Title = {Deep convolutional neural networks for brain image analysis on magnetic resonance imaging: a review},
	Year = {2018},
	Bdsk-Url-1 = {https://doi.org/10.1016/j.artmed.2018.08.008}}

@inproceedings{paszke:2017aa,
	Author = {Paszke, Adam and Gross, Sam and Chintala, Soumith and Chanan, Gregory and Yang, Edward and DeVito, Zachary and Lin, Zeming and Desmaison, Alban and Antiga, Luca and Lerer, Adam},
	Booktitle = {NIPS-W},
	Date-Added = {2018-12-24 13:59:28 -0800},
	Date-Modified = {2019-05-21 21:37:44 -0700},
	Title = {Automatic differentiation in {PyTorch}},
	Year = {2017}}

@article{Ashburner:2000aa,
	Abstract = {At its simplest, voxel-based morphometry (VBM) involves a voxel-wise comparison of the local concentration of gray matter between two groups of subjects. The procedure is relatively straightforward and involves spatially normalizing high-resolution images from all the subjects in the study into the same stereotactic space. This is followed by segmenting the gray matter from the spatially normalized images and smoothing the gray-matter segments. Voxel-wise parametric statistical tests which compare the smoothed gray-matter images from the two groups are performed. Corrections for multiple comparisons are made using the theory of Gaussian random fields. This paper describes the steps involved in VBM, with particular emphasis on segmenting gray matter from MR images with nonuniformity artifact. We provide evaluations of the assumptions that underpin the method, including the accuracy of the segmentation and the assumptions made about the statistical distribution of the data.},
	Author = {Ashburner, J and Friston, K J},
	Date-Added = {2018-12-24 13:48:09 -0800},
	Date-Modified = {2018-12-24 13:48:09 -0800},
	Doi = {10.1006/nimg.2000.0582},
	Journal = {Neuroimage},
	Journal-Full = {NeuroImage},
	Mesh = {Brain; False Positive Reactions; Humans; Magnetic Resonance Imaging; Models, Neurological; Periaqueductal Gray; Random Allocation},
	Month = {Jun},
	Number = {6 Pt 1},
	Pages = {805-21},
	Pmid = {10860804},
	Pst = {ppublish},
	Title = {Voxel-based morphometry--the methods},
	Volume = {11},
	Year = {2000},
	Bdsk-Url-1 = {https://doi.org/10.1006/nimg.2000.0582}}

@article{Anwar:2018aa,
	Abstract = {The science of solving clinical problems by analyzing images generated in clinical practice is known as medical image analysis. The aim is to extract information in an affective and efficient manner for improved clinical diagnosis. The recent advances in the field of biomedical engineering have made medical image analysis one of the top research and development area. One of the reasons for this advancement is the application of machine learning techniques for the analysis of medical images. Deep learning is successfully used as a tool for machine learning, where a neural network is capable of automatically learning features. This is in contrast to those methods where traditionally hand crafted features are used. The selection and calculation of these features is a challenging task. Among deep learning techniques, deep convolutional networks are actively used for the purpose of medical image analysis. This includes application areas such as segmentation, abnormality detection, disease classification, computer aided diagnosis and retrieval. In this study, a comprehensive review of the current state-of-the-art in medical image analysis using deep convolutional networks is presented. The challenges and potential of these techniques are also highlighted.},
	Author = {Anwar, Syed Muhammad and Majid, Muhammad and Qayyum, Adnan and Awais, Muhammad and Alnowami, Majdi and Khan, Muhammad Khurram},
	Date-Added = {2018-12-23 18:40:53 -0800},
	Date-Modified = {2018-12-23 18:40:53 -0800},
	Doi = {10.1007/s10916-018-1088-1},
	Journal = {J Med Syst},
	Journal-Full = {Journal of medical systems},
	Keywords = {Classification; Computer aided diagnosis; Convolutional neural network; Medical image analysis; Segmentation},
	Month = {Oct},
	Number = {11},
	Pages = {226},
	Pmid = {30298337},
	Pst = {epublish},
	Title = {Medical Image Analysis using Convolutional Neural Networks: A Review},
	Volume = {42},
	Year = {2018},
	Bdsk-Url-1 = {https://doi.org/10.1007/s10916-018-1088-1}}

@article{Sahiner:2018aa,
	Abstract = {The goals of this review paper on deep learning (DL) in medical imaging and radiation therapy are to (a) summarize what has been achieved to date; (b) identify common and unique challenges, and strategies that researchers have taken to address these challenges; and (c) identify some of the promising avenues for the future both in terms of applications as well as technical innovations. We introduce the general principles of DL and convolutional neural networks, survey five major areas of application of DL in medical imaging and radiation therapy, identify common themes, discuss methods for dataset expansion, and conclude by summarizing lessons learned, remaining challenges, and future directions.},
	Author = {Sahiner, Berkman and Pezeshk, Aria and Hadjiiski, Lubomir M and Wang, Xiaosong and Drukker, Karen and Cha, Kenny H and Summers, Ronald M and Giger, Maryellen L},
	Date-Added = {2018-12-23 18:35:29 -0800},
	Date-Modified = {2018-12-23 18:35:29 -0800},
	Doi = {10.1002/mp.13264},
	Journal = {Med Phys},
	Journal-Full = {Medical physics},
	Keywords = {computer-aided detection/characterization; deep learning, machine learning; reconstruction; segmentation; treatment},
	Month = {Oct},
	Pmid = {30367497},
	Pst = {aheadofprint},
	Title = {Deep learning in medical imaging and radiation therapy},
	Year = {2018},
	Bdsk-Url-1 = {https://doi.org/10.1002/mp.13264}}

@article{Falk:2019aa,
	Abstract = {U-Net is a generic deep-learning solution for frequently occurring quantification tasks such as cell detection and shape measurements in biomedical image data. We present an ImageJ plugin that enables non-machine-learning experts to analyze their data with U-Net on either a local computer or a remote server/cloud service. The plugin comes with pretrained models for single-cell segmentation and allows for U-Net to be adapted to new tasks on the basis of a few annotated samples.},
	Author = {Falk, Thorsten and Mai, Dominic and Bensch, Robert and {\c C}i{\c c}ek, {\"O}zg{\"u}n and Abdulkadir, Ahmed and Marrakchi, Yassine and B{\"o}hm, Anton and Deubner, Jan and J{\"a}ckel, Zoe and Seiwald, Katharina and Dovzhenko, Alexander and Tietz, Olaf and Dal Bosco, Cristina and Walsh, Sean and Saltukoglu, Deniz and Tay, Tuan Leng and Prinz, Marco and Palme, Klaus and Simons, Matias and Diester, Ilka and Brox, Thomas and Ronneberger, Olaf},
	Date-Added = {2018-12-23 18:31:19 -0800},
	Date-Modified = {2018-12-23 18:31:19 -0800},
	Doi = {10.1038/s41592-018-0261-2},
	Journal = {Nat Methods},
	Journal-Full = {Nature methods},
	Month = {Jan},
	Number = {1},
	Pages = {67-70},
	Pmid = {30559429},
	Pst = {ppublish},
	Title = {U-Net: deep learning for cell counting, detection, and morphometry},
	Volume = {16},
	Year = {2019},
	Bdsk-Url-1 = {https://doi.org/10.1038/s41592-018-0261-2}}

@misc{tensorflow,
	Author = {Mart\'{\i}n~Abadi and Ashish~Agarwal and Paul~Barham and Eugene~Brevdo and Zhifeng~Chen and Craig~Citro and Greg~S.~Corrado and Andy~Davis and Jeffrey~Dean and Matthieu~Devin and Sanjay~Ghemawat and Ian~Goodfellow and Andrew~Harp and Geoffrey~Irving and Michael~Isard and Yangqing Jia and Rafal~Jozefowicz and Lukasz~Kaiser and Manjunath~Kudlur and Josh~Levenberg and Dan~Man\'{e} and Rajat~Monga and Sherry~Moore and Derek~Murray and Chris~Olah and Mike~Schuster and Jonathon~Shlens and Benoit~Steiner and Ilya~Sutskever and Kunal~Talwar and Paul~Tucker and Vincent~Vanhoucke and Vijay~Vasudevan and Fernanda~Vi\'{e}gas and Oriol~Vinyals and Pete~Warden and Martin~Wattenberg and Martin~Wicke and Yuan~Yu and Xiaoqiang~Zheng},
	Date-Added = {2018-12-23 17:28:11 -0800},
	Date-Modified = {2018-12-23 17:29:39 -0800},
	Title = {{TensorFlow}: Large-Scale Machine Learning on Heterogeneous Systems},
	Year = {2015}}

@misc{keras,
	Author = {Chollet, Fran\c{c}ois and others},
	Date-Added = {2018-12-23 17:23:08 -0800},
	Date-Modified = {2018-12-23 17:25:48 -0800},
	Howpublished = {{\url{https://github.com/fchollet/keras}}},
	Title = {Keras}}

@article{Modat:2010aa,
	Abstract = {A large number of algorithms have been developed to perform non-rigid registration and it is a tool commonly used in medical image analysis. The free-form deformation algorithm is a well-established technique, but is extremely time consuming. In this paper we present a parallel-friendly formulation of the algorithm suitable for graphics processing unit execution. Using our approach we perform registration of T1-weighted MR images in less than 1 min and show the same level of accuracy as a classical serial implementation when performing segmentation propagation. This technology could be of significant utility in time-critical applications such as image-guided interventions, or in the processing of large data sets.},
	Author = {Modat, Marc and Ridgway, Gerard R and Taylor, Zeike A and Lehmann, Manja and Barnes, Josephine and Hawkes, David J and Fox, Nick C and Ourselin, S{\'e}bastien},
	Date-Added = {2018-12-23 15:37:33 -0800},
	Date-Modified = {2018-12-23 15:37:33 -0800},
	Doi = {10.1016/j.cmpb.2009.09.002},
	Journal = {Comput Methods Programs Biomed},
	Journal-Full = {Computer methods and programs in biomedicine},
	Mesh = {Algorithms; Computer Graphics; Diagnostic Imaging; Image Processing, Computer-Assisted; Software},
	Month = {Jun},
	Number = {3},
	Pages = {278-84},
	Pmid = {19818524},
	Pst = {ppublish},
	Title = {Fast free-form deformation using graphics processing units},
	Volume = {98},
	Year = {2010},
	Bdsk-Url-1 = {https://doi.org/10.1016/j.cmpb.2009.09.002}}

@article{Yi:2018aa,
	Author = {Xin Yi and Ekta Walia and Paul Babyn},
	Date-Added = {2018-12-23 15:20:11 -0800},
	Date-Modified = {2018-12-23 15:21:03 -0800},
	Journal = {arXiv preprint},
	Title = {Generative Adversarial Network in Medical Imaging: A Review},
	Year = {2018}}

@proceedings{brats2018,
	Date-Added = {2018-12-23 14:30:38 -0800},
	Date-Modified = {2018-12-23 14:30:59 -0800},
	Title = {Pre-Conference Proceedings of the 7th {MICCAI} {BraTS} Challenge},
	Year = {2018}}

@proceedings{brats2014,
	Date-Added = {2018-12-23 14:27:45 -0800},
	Date-Modified = {2018-12-23 14:31:12 -0800},
	Title = {Conference Proceedings of the 3rd {MICCAI} {BraTS} Challenge},
	Year = {2014},
	Bdsk-File-1 = {YnBsaXN0MDDSAQIDBFxyZWxhdGl2ZVBhdGhZYWxpYXNEYXRhXxAoLi4vLi4vLi4vLi4vLi4vLlRyYXNoL2Ficy0xODEwLTAyNTgzLmJpYk8RAVYAAAAAAVYAAgAADE1hY2ludG9zaCBIRAAAAAAAAAAAAAAAAAAAAAAAAABCRAAB/////xJhYnMtMTgxMC0wMjU4My5iaWIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAD/////AAAAAAAAAAAAAAAAAAUAAgAACiBjdQAAAAAAAAAAAAAAAAAGLlRyYXNoAAIAKy86VXNlcnM6bnR1c3Rpc29uOi5UcmFzaDphYnMtMTgxMC0wMjU4My5iaWIAAA4AJgASAGEAYgBzAC0AMQA4ADEAMAAtADAAMgA1ADgAMwAuAGIAaQBiAA8AGgAMAE0AYQBjAGkAbgB0AG8AcwBoACAASABEABIAKVVzZXJzL250dXN0aXNvbi8uVHJhc2gvYWJzLTE4MTAtMDI1ODMuYmliAAATAAEvAAAVAAIAEP//AAAACAANABoAJABPAAAAAAAAAgEAAAAAAAAABQAAAAAAAAAAAAAAAAAAAak=}}

@article{Menze:2015aa,
	Abstract = {In this paper we report the set-up and results of the Multimodal Brain Tumor Image Segmentation Benchmark (BRATS) organized in conjunction with the MICCAI 2012 and 2013 conferences. Twenty state-of-the-art tumor segmentation algorithms were applied to a set of 65 multi-contrast MR scans of low- and high-grade glioma patients-manually annotated by up to four raters-and to 65 comparable scans generated using tumor image simulation software. Quantitative evaluations revealed considerable disagreement between the human raters in segmenting various tumor sub-regions (Dice scores in the range 74%-85%), illustrating the difficulty of this task. We found that different algorithms worked best for different sub-regions (reaching performance comparable to human inter-rater variability), but that no single algorithm ranked in the top for all sub-regions simultaneously. Fusing several good algorithms using a hierarchical majority vote yielded segmentations that consistently ranked above all individual algorithms, indicating remaining opportunities for further methodological improvements. The BRATS image data and manual annotations continue to be publicly available through an online evaluation system as an ongoing benchmarking resource. },
	Author = {Menze, Bjoern H and Jakab, Andras and Bauer, Stefan and Kalpathy-Cramer, Jayashree and Farahani, Keyvan and Kirby, Justin and Burren, Yuliya and Porz, Nicole and Slotboom, Johannes and Wiest, Roland and Lanczi, Levente and Gerstner, Elizabeth and Weber, Marc-Andr{\'e} and Arbel, Tal and Avants, Brian B and Ayache, Nicholas and Buendia, Patricia and Collins, D Louis and Cordier, Nicolas and Corso, Jason J and Criminisi, Antonio and Das, Tilak and Delingette, Herv{\'e} and Demiralp, {\c C}a{\u g}atay and Durst, Christopher R and Dojat, Michel and Doyle, Senan and Festa, Joana and Forbes, Florence and Geremia, Ezequiel and Glocker, Ben and Golland, Polina and Guo, Xiaotao and Hamamci, Andac and Iftekharuddin, Khan M and Jena, Raj and John, Nigel M and Konukoglu, Ender and Lashkari, Danial and Mariz, Jos{\'e} Antoni{\'o} and Meier, Raphael and Pereira, S{\'e}rgio and Precup, Doina and Price, Stephen J and Raviv, Tammy Riklin and Reza, Syed M S and Ryan, Michael and Sarikaya, Duygu and Schwartz, Lawrence and Shin, Hoo-Chang and Shotton, Jamie and Silva, Carlos A and Sousa, Nuno and Subbanna, Nagesh K and Szekely, Gabor and Taylor, Thomas J and Thomas, Owen M and Tustison, Nicholas J and Unal, Gozde and Vasseur, Flor and Wintermark, Max and Ye, Dong Hye and Zhao, Liang and Zhao, Binsheng and Zikic, Darko and Prastawa, Marcel and Reyes, Mauricio and Van Leemput, Koen},
	Date-Added = {2018-12-23 14:24:45 -0800},
	Date-Modified = {2019-05-21 22:11:24 -0700},
	Doi = {10.1109/TMI.2014.2377694},
	Journal = {IEEE Trans Med Imaging},
	Journal-Full = {IEEE transactions on medical imaging},
	Mesh = {Algorithms; Benchmarking; Glioma; Humans; Magnetic Resonance Imaging; Neuroimaging},
	Month = {Oct},
	Number = {10},
	Pages = {1993-2024},
	Pmc = {PMC4833122},
	Pmid = {25494501},
	Pst = {ppublish},
	Title = {The Multimodal Brain Tumor Image Segmentation Benchmark ({BRATS})},
	Volume = {34},
	Year = {2015},
	Bdsk-Url-1 = {https://doi.org/10.1109/TMI.2014.2377694}}

@article{Chan:1995aa,
	Abstract = {We are developing a computer program for automated detection of clustered microcalcifications on mammograms. In this study, we investigated the effectiveness of a signal classifier based on a convolution neural network (CNN) approach for improvement of the accuracy of the detection program. Fifty-two mammograms with clustered microcalcifications were selected from patient files. The clusters on the mammograms were ranked by experienced mammographers and divided into an obvious group, an average group, and a subtle group. The average and subtle groups were combined and randomly divided into two sets, each of which was used as training or test set alternately. The obvious group served as an additional independent test set. Regions of interest (ROIs) containing potential individual microcalcifications were first located on each mammogram by the automated detection program. The ROIs from one set of the mammograms were used to train CNNs of different configurations with a back-propagation method. The generalization capability of the trained CNNs was then examined by their accuracy of classifying the ROIs from the other set and from the obvious group. The classification accuracy of the CNNs for the ROIs was evaluated by receiver operating characteristic (ROC) analysis. It was found that CNNs of many different configurations can reach approximately the same performance level, with the area under the ROC curve (Az) of 0.9. We incorporated a trained CNN into the detection program and evaluated the improvement of the detection accuracy by the CNN using free response ROC analysis. Our results indicated that, over a wide range of true-positive (TP) cluster detection rate, the CNN classifier could reduce the number of false-positive (FP) clusters per image by more than 70%. For the obvious cases, at a TP rate of 100%, the FP rate reduced from 0.35 cluster per image to 0.1 cluster per image. For the average and subtle cases, the detection accuracy improved from a TP rate of 87% at an FP rate of four clusters per image to a TP rate of 90% at an FP rate of 1.5 clusters per image.},
	Author = {Chan, H P and Lo, S C and Sahiner, B and Lam, K L and Helvie, M A},
	Date-Added = {2018-12-22 19:10:17 -0800},
	Date-Modified = {2018-12-22 19:10:17 -0800},
	Doi = {10.1118/1.597428},
	Journal = {Med Phys},
	Journal-Full = {Medical physics},
	Mesh = {Automation; Breast Diseases; Breast Neoplasms; Calcinosis; False Positive Reactions; Female; Humans; Mammography; Mathematics; Neural Networks (Computer); Patient Selection; Radiographic Image Interpretation, Computer-Assisted; Reproducibility of Results; Risk Factors},
	Month = {Oct},
	Number = {10},
	Pages = {1555-67},
	Pmid = {8551980},
	Pst = {ppublish},
	Title = {Computer-aided detection of mammographic microcalcifications: pattern recognition with an artificial neural network},
	Volume = {22},
	Year = {1995},
	Bdsk-Url-1 = {https://doi.org/10.1118/1.597428}}

@article{Tan:2014aa,
	Abstract = {PURPOSE: Selecting optimal features from a large image feature pool remains a major challenge in developing computer-aided detection (CAD) schemes of medical images. The objective of this study is to investigate a new approach to significantly improve efficacy of image feature selection and classifier optimization in developing a CAD scheme of mammographic masses.
METHODS: An image dataset including 1600 regions of interest (ROIs) in which 800 are positive (depicting malignant masses) and 800 are negative (depicting CAD-generated false positive regions) was used in this study. After segmentation of each suspicious lesion by a multilayer topographic region growth algorithm, 271 features were computed in different feature categories including shape, texture, contrast, isodensity, spiculation, local topological features, as well as the features related to the presence and location of fat and calcifications. Besides computing features from the original images, the authors also computed new texture features from the dilated lesion segments. In order to select optimal features from this initial feature pool and build a highly performing classifier, the authors examined and compared four feature selection methods to optimize an artificial neural network (ANN) based classifier, namely: (1) Phased Searching with NEAT in a Time-Scaled Framework, (2) A sequential floating forward selection (SFFS) method, (3) A genetic algorithm (GA), and (4) A sequential forward selection (SFS) method. Performances of the four approaches were assessed using a tenfold cross validation method.
RESULTS: Among these four methods, SFFS has highest efficacy, which takes 3%-5% of computational time as compared to GA approach, and yields the highest performance level with the area under a receiver operating characteristic curve (AUC) = 0.864 $\pm$ 0.034. The results also demonstrated that except using GA, including the new texture features computed from the dilated mass segments improved the AUC results of the ANNs optimized using other three feature selection methods. In addition, among 271 features, the shape, local morphological features, fat and calcification based features were the most frequently selected features to build ANNs.
CONCLUSIONS: Although conventional GA is a powerful tool in optimizing classifiers used in CAD schemes of medical images, it is very computationally intensive. This study demonstrated that using a new SFFS based approach enabled to significantly improve efficacy of image feature selection for developing CAD schemes.},
	Author = {Tan, Maxine and Pu, Jiantao and Zheng, Bin},
	Date-Added = {2018-12-22 19:09:34 -0800},
	Date-Modified = {2018-12-22 19:09:34 -0800},
	Doi = {10.1118/1.4890080},
	Journal = {Med Phys},
	Journal-Full = {Medical physics},
	Mesh = {Algorithms; Area Under Curve; Breast Neoplasms; Datasets as Topic; Humans; Mammography; Neural Networks (Computer); Pattern Recognition, Automated; ROC Curve; Radiographic Image Interpretation, Computer-Assisted; Time Factors},
	Month = {Aug},
	Number = {8},
	Pages = {081906},
	Pmc = {PMC4105957},
	Pmid = {25086537},
	Pst = {ppublish},
	Title = {A new and fast image feature selection method for developing an optimal mammographic mass detection scheme},
	Volume = {41},
	Year = {2014},
	Bdsk-Url-1 = {https://doi.org/10.1118/1.4890080}}

@inproceedings{Lo:1992aa,
	Author = {Lo, S C and Freedman, M T and Lin, J S and Mun, S K},
	Booktitle = {Proc. SPIE: Medical Imaging: Image Processing},
	Date-Added = {2018-12-22 19:05:14 -0800},
	Date-Modified = {2018-12-22 19:08:09 -0800},
	Pages = {859--869},
	Title = {Computer-aided detection of mammographic calcifications: Pattern recognition with an artificial neural network},
	Volume = {1898},
	Year = {1992}}

@article{Lo:1993aa,
	Abstract = {The potential advantages of using digital techniques instead of film-based radiography have been discussed extensively for the past 10 years. A major future application of digital techniques is computer-assisted diagnosis: the use of computer techniques to assist the radiologist in the diagnostic process. One aspect of this assistance is computer-assisted detection. The detection of small lung nodule has been recognized as a clinically difficult task for many years. Most of the literature has indicated that the rate for finding lung nodules (size range from 3 mm to 15 mm) is only approximately 65%, in those cases in which the undetected nodules could be found retrospectively. In recent published research, image processing techniques, such as thresholding and morphological analysis, have been used to enhance true-positive detection. However, these methods still produce many false-positive detections. We have been investigating the use of neural networks to distinguish true-positives nodule detections among those areas of interest that are generated from a signal enhanced image. The initial results show that the trained neural networks program can increase true-positive detections and moderately reduce the number of false-positive detections. The program reported here can perform three modes of lung nodule detection: thresholding, profile matching analysis, and neural network. This program is fully automatic and has been implemented in a DEC 5000/200 (Digital Equipment Corp, Maynard, MA) workstation. The total processing time for all three methods is less than 35 seconds. In this report, key image processing techniques and neural network for the lung nodule detection are described and the results of this initial study are reported.},
	Author = {Lo, S C and Freedman, M T and Lin, J S and Mun, S K},
	Date-Added = {2018-12-22 18:55:03 -0800},
	Date-Modified = {2018-12-22 18:55:03 -0800},
	Journal = {J Digit Imaging},
	Journal-Full = {Journal of digital imaging},
	Mesh = {Algorithms; Diagnosis, Computer-Assisted; Humans; Image Processing, Computer-Assisted; Lung Neoplasms; Neural Networks (Computer); Predictive Value of Tests; Radiographic Image Enhancement; Solitary Pulmonary Nodule},
	Month = {Feb},
	Number = {1},
	Pages = {48-54},
	Pmid = {8439583},
	Pst = {ppublish},
	Title = {Automatic lung nodule detection using profile matching and back-propagation neural network techniques},
	Volume = {6},
	Year = {1993}}

@article{Sahiner:1996aa,
	Abstract = {The authors investigated the classification of regions of interest (ROI's) on mammograms as either mass or normal tissue using a convolution neural network (CNN). A CNN is a backpropagation neural network with two-dimensional (2-D) weight kernels that operate on images. A generalized, fast and stable implementation of the CNN was developed. The input images to the CNN were obtained from the ROI's using two techniques. The first technique employed averaging and subsampling. The second technique employed texture feature extraction methods applied to small subregions inside the ROI. Features computed over different subregions were arranged as texture images, which were subsequently used as CNN inputs. The effects of CNN architecture and texture feature parameters on classification accuracy were studied. Receiver operating characteristic (ROC) methodology was used to evaluate the classification accuracy. A data set consisting of 168 ROIs containing biopsy-proven masses and 504 ROI's containing normal breast tissue was extracted from 168 mammograms by radiologists experienced in mammography. This data set was used for training and testing the CNN. With the best combination of CNN architecture and texture feature parameters, the area under the test ROC curve reached 0.87, which corresponded to a true-positive fraction of 90% at a false positive fraction of 31%. The authors' results demonstrate the feasibility of using a CNN for classification of masses and normal tissue on mammograms.},
	Author = {Sahiner, B and Chan, H P and Petrick, N and Wei, D and Helvie, M A and Adler, D D and Goodsitt, M M},
	Date-Added = {2018-12-22 18:54:38 -0800},
	Date-Modified = {2018-12-22 18:54:38 -0800},
	Doi = {10.1109/42.538937},
	Journal = {IEEE Trans Med Imaging},
	Journal-Full = {IEEE transactions on medical imaging},
	Number = {5},
	Pages = {598-610},
	Pmid = {18215941},
	Pst = {ppublish},
	Title = {Classification of mass and normal breast tissue: a convolution neural network classifier with spatial domain and texture images},
	Volume = {15},
	Year = {1996},
	Bdsk-Url-1 = {https://doi.org/10.1109/42.538937}}

@article{Mazurowski:2018aa,
	Author = {Maciej A. Mazurowski and Mateusz Buda and Ashirbani Saha and and Mustafa R. Bashir},
	Date-Added = {2018-12-22 18:44:09 -0800},
	Date-Modified = {2019-05-21 22:15:46 -0700},
	Journal = {J Magn Reson Imaging},
	Title = {Deep Learning in Radiology: An Overview of the Concepts and a Survey of the State of the Art With Focus on {MRI}},
	Year = {2018}}

@article{Hochreiter:1997aa,
	Abstract = {Learning to store information over extended time intervals by recurrent backpropagation takes a very long time, mostly because of insufficient, decaying error backflow. We briefly review Hochreiter's (1991) analysis of this problem, then address it by introducing a novel, efficient, gradient-based method called long short-term memory (LSTM). Truncating the gradient where this does not do harm, LSTM can learn to bridge minimal time lags in excess of 1000 discrete-time steps by enforcing constant error flow through constant error carousels within special units. Multiplicative gate units learn to open and close access to the constant error flow. LSTM is local in space and time; its computational complexity per time step and weight is O(1). Our experiments with artificial data involve local, distributed, real-valued, and noisy pattern representations. In comparisons with real-time recurrent learning, back propagation through time, recurrent cascade correlation, Elman nets, and neural sequence chunking, LSTM leads to many more successful runs, and learns much faster. LSTM also solves complex, artificial long-time-lag tasks that have never been solved by previous recurrent network algorithms.},
	Author = {Hochreiter, S and Schmidhuber, J},
	Date-Added = {2018-12-22 18:35:11 -0800},
	Date-Modified = {2018-12-22 18:35:11 -0800},
	Journal = {Neural Comput},
	Journal-Full = {Neural computation},
	Mesh = {Algorithms; Learning; Memory; Memory, Short-Term; Models, Neurological; Models, Psychological; Nerve Net; Neural Networks (Computer); Time Factors},
	Month = {Nov},
	Number = {8},
	Pages = {1735-80},
	Pmid = {9377276},
	Pst = {ppublish},
	Title = {Long short-term memory},
	Volume = {9},
	Year = {1997}}

@inproceedings{He:2015ab,
	Author = {Kaiming He and Xiangyu Zhang and Shaoqing Ren and Jian Sun},
	Booktitle = {Proceedings of the {IEEE} {C}onference on {C}omputer {V}ision and {P}attern {R}ecognition},
	Date-Added = {2018-12-22 14:05:38 -0800},
	Date-Modified = {2018-12-23 20:12:34 -0800},
	Title = {Delving deep into rectifiers: Surpassing human-level performance on imagenet classification},
	Year = {2015}}

@article{Lv:2018aa,
	Abstract = {OBJECTIVE: Free-breathing abdomen imaging requires non-rigid motion registration of unavoidable respiratory motion in three-dimensional undersampled data sets. In this work, we introduce an image registration method based on the convolutional neural network (CNN) to obtain motion-free abdominal images throughout the respiratory cycle.
METHODS: Abdominal data were acquired from 10 volunteers using a 1.5 T MRI system. The respiratory signal was extracted from the central-space spokes, and the acquired data were reordered in three bins according to the corresponding breathing signal. Retrospective image reconstruction of the three near-motion free respiratory phases was performed using non-Cartesian iterative SENSE reconstruction. Then, we trained a CNN to analyse the spatial transform among the different bins. This network could generate the displacement vector field and be applied to perform registration on unseen image pairs. To demonstrate the feasibility of this registration method, we compared the performance of three different registration approaches for accurate image fusion of three bins: non-motion corrected (NMC), local affine registration method (LREG) and CNN.
RESULTS: Visualization of coronal images indicated that LREG had caused broken blood vessels, while the vessels of the CNN were sharper and more consecutive. As shown in the sagittal view, compared to NMC and CNN, distorted and blurred liver contours were caused by LREG. At the same time, zoom-in axial images presented that the vessels were delineated more clearly by CNN than LREG. The statistical results of the signal-to-noise ratio, visual score, vessel sharpness and registration time over all volunteers were compared among the NMC, LREG and CNN approaches. The SNR indicated that the CNN acquired the best image quality (207.42 {\^A}$\pm$ 96.73), which was better than NMC (116.67 {\^A}$\pm$ 44.70) and LREG (187.93 {\^A}$\pm$ 96.68). The image visual score agreed with SNR, marking CNN (3.85 {\^A}$\pm$ 0.12) as the best, followed by LREG (3.43 {\^A}$\pm$ 0.13) and NMC (2.55 {\^A}$\pm$ 0.09). A vessel sharpness assessment yielded similar values between the CNN (0.81 {\^A}$\pm$ 0.03) and LREG (0.80 {\^A}$\pm$ 0.04), differentiating them from the NMC (0.78 {\^A}$\pm$ 0.06). When compared with the LREG-based reconstruction, the CNN-based reconstruction reduces the registration time from 1 h to 1 min.
CONCLUSION: Our preliminary results demonstrate the feasibility of the CNN-based approach, and this scheme outperforms the NMC- and LREG-based methods. Advances in knowledge: This method reduces the registration time from ~1 h to ~1 min, which has promising prospects for clinical use. To the best of our knowledge, this study shows the first convolutional neural network-based registration method to be applied in abdominal images.},
	Author = {Lv, Jun and Yang, Ming and Zhang, Jue and Wang, Xiaoying},
	Date-Added = {2018-12-22 09:15:13 -0800},
	Date-Modified = {2018-12-22 09:15:13 -0800},
	Doi = {10.1259/bjr.20170788},
	Journal = {Br J Radiol},
	Journal-Full = {The British journal of radiology},
	Mesh = {Abdomen; Adult; Feasibility Studies; Female; Healthy Volunteers; Humans; Image Enhancement; Image Interpretation, Computer-Assisted; Imaging, Three-Dimensional; Magnetic Resonance Imaging; Male; Motion; Neural Networks (Computer); Respiratory-Gated Imaging Techniques; Signal-To-Noise Ratio},
	Month = {Feb},
	Number = {1083},
	Pages = {20170788},
	Pmc = {PMC5965487},
	Pmid = {29261334},
	Pst = {ppublish},
	Title = {Respiratory motion correction for free-breathing 3D abdominal MRI using CNN-based image registration: a feasibility study},
	Volume = {91},
	Year = {2018},
	Bdsk-Url-1 = {https://doi.org/10.1259/bjr.20170788}}

@inproceedings{Chopra:2005aa,
	Author = {Sumit Chopra and Raia Hadsell and Yann LeCun},
	Booktitle = {Proceedings of the {IEEE} {I}nternational {C}onference on {C}omputer {V}ision},
	Date-Added = {2018-12-20 11:40:08 -0800},
	Date-Modified = {2019-05-21 22:07:08 -0700},
	Title = {Learning a Similarity Metric Discriminatively, with Application to Face Verification},
	Year = {2005}}

@inproceedings{Simonovsky:2016aa,
	Author = {Martin Simonovsky and BenjamÄ±n Gutierrez-Becker and Diana Mateus and Nassir Navab and Nikos Komodakis},
	Booktitle = {Proceedings of the {I}nternational {C}onference on {M}edical {I}mage {C}omputing and {C}omputer-{A}ssisted {I}ntervention},
	Date-Added = {2018-12-17 10:29:09 -0800},
	Date-Modified = {2019-05-21 21:57:49 -0700},
	Title = {A Deep Metric for Multimodal Registration},
	Year = {2016}}

@inproceedings{Mahapatra:2018aa,
	Author = {Dwarikanath Mahapatra and Bhavna Antony and Suman Sedai and Rahil Garnavi},
	Booktitle = {Proceedings of {IEEE} 15th {I}nternational {S}ymposium on {B}iomedical {I}maging},
	Date-Added = {2018-12-16 19:56:17 -0800},
	Date-Modified = {2019-05-21 21:36:00 -0700},
	Title = {Deformable medical image registration using generative adversarial networks},
	Year = {2018}}

@article{Shan:2018aa,
	Author = {Siyuan Shan and Wen Yan and Xiaoqing Guo and Eric I-Chao Chang and Yubo Fan and Yan Xu},
	Date-Added = {2018-12-16 15:10:19 -0800},
	Date-Modified = {2018-12-16 15:11:41 -0800},
	Journal = {arxiv},
	Title = {Unsupervised End-to-end Learning for Deformable Medical Image Registration},
	Year = {2018}}

@article{Nazib:2018aa,
	Author = {Abdullah Nazib and Clinton Fookes and Dimitri Perrin},
	Date-Added = {2018-12-16 13:47:38 -0800},
	Date-Modified = {2018-12-16 13:48:22 -0800},
	Journal = {arXiv preprint},
	Title = {A Comparative Analysis of Registration Tools: Traditional vs Deep Learning Approach on High Resolution Tissue Cleared Data},
	Year = {2018}}

@inproceedings{Hu:2018ab,
	Author = {Yipeng Hu and Marc Modat and Eli Gibson and Nooshin Ghavami and Ester Bonmati and Caroline M. Moore and Mark Emberton and J. Alison Noble and Dean C. Barratt and Tom Vercauteren},
	Booktitle = {Proceedings of {IEEE} 15th {I}nternational {S}ymposium on {B}iomedical {I}maging},
	Date-Added = {2018-12-16 13:22:06 -0800},
	Date-Modified = {2019-05-21 21:35:19 -0700},
	Title = {Label-driven weakly-supervised learning for multimodal deformable image registration},
	Year = {2018}}

@article{DeTone:2016aa,
	Author = {Daniel DeTone and Tomasz Malisiewicz and Andrew Rabinovich},
	Date-Added = {2018-12-14 16:36:50 -0800},
	Date-Modified = {2018-12-14 16:38:56 -0800},
	Journal = {arXiv:1606.03798},
	Title = {Deep Image Homography Estimation},
	Year = {2016}}

@inproceedings{Nowruzi:2017aa,
	Author = {Farzan Erlik Nowruzi and Robert Laganiere and Nathalie Japkowicz},
	Booktitle = {Proceedings of the International Conference of Computer Vision},
	Date-Added = {2018-12-14 16:35:09 -0800},
	Date-Modified = {2018-12-14 16:36:45 -0800},
	Title = {Homography Estimation from Image Pairs with Hierarchical Convolutional Networks},
	Year = {2017}}

@inproceedings{Nguyen:2018aa,
	Author = {Nguyen, Ty and Chen, Steven W and Shivakumar, Shreyas S and Taylor, Camillo J and Kumar, Vijay},
	Booktitle = {Proceedings of {IEEE} {R}obotics and {A}utomation {L}etters},
	Date-Added = {2018-12-14 16:29:02 -0800},
	Date-Modified = {2019-05-21 21:57:09 -0700},
	Title = {Unsupervised Deep Homography: A Fast and Robust Homography Estimation Model},
	Year = {2018}}

@article{Ghosal:2017aa,
	Author = {Sayan Ghosal and Nilanjan Ray},
	Date-Added = {2018-12-14 16:09:18 -0800},
	Date-Modified = {2018-12-14 16:12:57 -0800},
	Journal = {Pattern Recognition Letters},
	Month = {July},
	Number = {15},
	Pages = {81--86},
	Title = {Deep Deformable Registration: Enhancing Accuracy by Fully Convolutional Neural Net},
	Volume = {94},
	Year = {2017}}

@inproceedings{Fan:2018aa,
	Author = {Jingfan Fan and Xiaohuan Cao and Zhong Xue and Pew-Thian Yap and Dinggang Shen},
	Booktitle = {Proceedings of the {I}nternational {C}onference on {M}edical {I}mage {C}omputing and {C}omputer-{A}ssisted {I}ntervention},
	Date-Added = {2018-12-14 16:06:00 -0800},
	Date-Modified = {2019-05-21 21:33:35 -0700},
	Title = {Adversarial Similarity Network for Evaluating Image Alignment in Deep Learning Based Registration},
	Year = {2018}}

@article{Dupuis:1998,
	Author = {P. Dupuis and U. Grenander and M. I. Miller},
	Date-Added = {2018-12-12 21:02:49 -0800},
	Date-Modified = {2018-12-12 21:04:03 -0800},
	Journal = {Quarterly of Applied Mathematics},
	Pages = {587--600},
	Title = {Variational problems on flows of diffeomorphisms for image matching},
	Volume = {LVI},
	Year = {1998}}

@article{Trouve:1995aa,
	Author = {A. Trouv\'{e}},
	Date-Added = {2018-12-12 20:43:25 -0800},
	Date-Modified = {2018-12-12 20:44:37 -0800},
	Journal = {Int. J. Computer Vision},
	Pages = {213--221},
	Title = {Diffeomorphic groups and pattern matching in image analysis},
	Volume = {28},
	Year = {1995}}

@inproceedings{Lin:2017aa,
	Author = {Chen-Hsuan Lin and Simon Lucey},
	Booktitle = {Proceedings of the {IEEE} {C}onference on {C}omputer {V}ision and {P}attern {R}ecognition},
	Date-Added = {2018-12-12 20:10:17 -0800},
	Date-Modified = {2018-12-23 20:13:58 -0800},
	Title = {Inverse Compositional Spatial Transformer Networks},
	Year = {2017}}

@article{Freifeld:2017aa,
	Abstract = {We propose novel finite-dimensional spaces of well-behaved transformations. The latter are obtained by (fast and highly-accurate) integration of continuous piecewise-affine velocity fields. The proposed method is simple yet highly expressive, effortlessly handles optional constraints (e.g., volume preservation and/or boundary conditions), and supports convenient modeling choices such as smoothing priors and coarse-to-fine analysis. Importantly, the proposed approach, partly due to its rapid likelihood evaluations and partly due to its other properties, facilitates tractable inference over rich transformation spaces, including using Markov-Chain Monte-Carlo methods. Its applications include, but are not limited to: monotonic regression (more generally, optimization over monotonic functions); modeling cumulative distribution functions or histograms; time-warping; image warping; image registration; real-time diffeomorphic image editing; data augmentation for image classifiers. Our GPU-based code is publicly available.},
	Author = {Freifeld, Oren and Hauberg, Soren and Batmanghelich, Kayhan and Fisher, Jonn W},
	Date-Added = {2018-12-11 16:38:50 -0800},
	Date-Modified = {2018-12-11 16:38:50 -0800},
	Doi = {10.1109/TPAMI.2016.2646685},
	Journal = {IEEE Trans Pattern Anal Mach Intell},
	Journal-Full = {IEEE transactions on pattern analysis and machine intelligence},
	Month = {Dec},
	Number = {12},
	Pages = {2496-2509},
	Pmc = {PMC5889303},
	Pmid = {28092517},
	Pst = {ppublish},
	Title = {Transformations Based on Continuous Piecewise-Affine Velocity Fields},
	Volume = {39},
	Year = {2017},
	Bdsk-Url-1 = {https://doi.org/10.1109/TPAMI.2016.2646685}}

@inproceedings{Detlefsen:2018aa,
	Author = {Nicki Skafte Detlefsen and Oren Freifeld and S{\o}ren Hauberg},
	Booktitle = {Proceedings of the {IEEE} {C}onference on {C}omputer {V}ision and {P}attern {R}ecognition},
	Date-Added = {2018-12-11 16:32:53 -0800},
	Date-Modified = {2018-12-23 20:10:03 -0800},
	Title = {Deep Diffeomorphic Transformer Networks},
	Year = {2018}}

@inproceedings{Rocco:2017aa,
	Author = {I. Rocco and R. Arandjelovi{\'c} and J. Sivic},
	Booktitle = {Proceedings of the {IEEE} {C}onference on {C}omputer {V}ision and {P}attern {R}ecognition},
	Date-Added = {2018-12-11 13:15:53 -0800},
	Date-Modified = {2019-05-21 21:41:16 -0700},
	Title = {Convolutional neural network architecture for geometric matching},
	Year = {2017}}

@article{Dai:2017aa,
	Author = {Jifeng Dai and Haozhi Qi and Yuwen Xiong and Yi Li and Guodong Zhang and Han Hu and Yichen Wei},
	Date-Added = {2018-12-11 13:09:24 -0800},
	Date-Modified = {2018-12-11 13:10:27 -0800},
	Journal = {arXiv preprint arXiv:1703.06211},
	Title = {Deformable Convolutional Networks},
	Year = {2017}}

@article{Schmidhuber:2015aa,
	Author = {J{\"u}rgen Schmidhuber},
	Date-Added = {2018-12-10 20:34:28 -0800},
	Date-Modified = {2018-12-10 20:35:23 -0800},
	Journal = {Neural Networks},
	Pages = {85--117},
	Title = {Deep learning in neural networks: An overview},
	Volume = {61},
	Year = {2015}}

@article{Litjens:2017aa,
	Abstract = {Deep learning algorithms, in particular convolutional networks, have rapidly become a methodology of choice for analyzing medical images. This paper reviews the major deep learning concepts pertinent to medical image analysis and summarizes over 300 contributions to the field, most of which appeared in the last year. We survey the use of deep learning for image classification, object detection, segmentation, registration, and other tasks. Concise overviews are provided of studies per application area: neuro, retinal, pulmonary, digital pathology, breast, cardiac, abdominal, musculoskeletal. We end with a summary of the current state-of-the-art, a critical discussion of open challenges and directions for future research.},
	Author = {Litjens, Geert and Kooi, Thijs and Bejnordi, Babak Ehteshami and Setio, Arnaud Arindra Adiyoso and Ciompi, Francesco and Ghafoorian, Mohsen and van der Laak, Jeroen A W M and van Ginneken, Bram and S{\'a}nchez, Clara I},
	Date-Added = {2018-12-10 20:33:08 -0800},
	Date-Modified = {2018-12-10 20:33:08 -0800},
	Doi = {10.1016/j.media.2017.07.005},
	Journal = {Med Image Anal},
	Journal-Full = {Medical image analysis},
	Keywords = {Convolutional neural networks; Deep learning; Medical imaging; Survey},
	Mesh = {Algorithms; Diagnostic Imaging; Humans; Image Processing, Computer-Assisted; Machine Learning; Neural Networks (Computer)},
	Month = {Dec},
	Pages = {60-88},
	Pmid = {28778026},
	Pst = {ppublish},
	Title = {A survey on deep learning in medical image analysis},
	Volume = {42},
	Year = {2017},
	Bdsk-Url-1 = {https://doi.org/10.1016/j.media.2017.07.005}}

@article{Biswas:2019aa,
	Abstract = {Deep learning (DL) is affecting each and every sphere of public and private lives and becoming a tool for daily use. The power of DL lies in the fact that it tries to imitate the activities of neurons in the neocortex of human brain where the thought process takes place. Therefore, like the brain, it tries to learn and recognize patterns in the form of digital images. This power is built on the depth of many layers of computing neurons backed by high power processors and graphics processing units (GPUs) easily available today. In the current scenario, we have provided detailed survey of various types of DL systems available today, and specifically, we have concentrated our efforts on current applications of DL in medical imaging. We have also focused our efforts on explaining the readers the rapid transition of technology from machine learning to DL and have tried our best in reasoning this paradigm shift. Further, a detailed analysis of complexities involved in this shift and possible benefits accrued by the users and developers.},
	Author = {Biswas, Mainak and Kuppili, Venkatanareshbabu and Saba, Luca and Edla, Damodar Reddy and Suri, Harman S and Cuadrado-Godia, Elisa and Laird, John R and Marinhoe, Rui Tato and Sanches, Joao M and Nicolaides, Andrew and Suri, Jasjit S},
	Date-Added = {2018-12-10 20:25:39 -0800},
	Date-Modified = {2018-12-10 20:25:39 -0800},
	Journal = {Front Biosci (Landmark Ed)},
	Journal-Full = {Frontiers in bioscience (Landmark edition)},
	Month = {01},
	Pages = {392-426},
	Pmid = {30468663},
	Pst = {epublish},
	Title = {State-of-the-art review on deep learning in medical imaging},
	Volume = {24},
	Year = {2019}}

@article{Ker:2018aa,
	Author = {Justin Ker and Lipo Wang and Jai Rao and Tchoyoson Lim},
	Date-Added = {2018-12-10 20:19:27 -0800},
	Date-Modified = {2018-12-10 20:21:09 -0800},
	Journal = {IEEE Access},
	Pages = {9375--9389},
	Title = {Deep Learning Applications in Medical Image Analysis},
	Volume = {6},
	Year = {2018}}

@article{Ginneken:2017aa,
	Abstract = {Half a century ago, the term "computer-aided diagnosis" (CAD) was introduced in the scientific literature. Pulmonary imaging, with chest radiography and computed tomography, has always been one of the focus areas in this field. In this study, I describe how machine learning became the dominant technology for tackling CAD in the lungs, generally producing better results than do classical rule-based approaches, and how the field is now rapidly changing: in the last few years, we have seen how even better results can be obtained with deep learning. The key differences among rule-based processing, machine learning, and deep learning are summarized and illustrated for various applications of CAD in the chest.},
	Author = {van Ginneken, Bram},
	Date-Added = {2018-12-10 20:18:25 -0800},
	Date-Modified = {2018-12-10 20:18:25 -0800},
	Doi = {10.1007/s12194-017-0394-5},
	Journal = {Radiol Phys Technol},
	Journal-Full = {Radiological physics and technology},
	Keywords = {Computer-aided detection; Computer-aided diagnosis; Deep learning; Image processing; Machine learning; Pulmonary image analysis},
	Mesh = {Humans; Image Processing, Computer-Assisted; Lung Neoplasms; Machine Learning; Radiography, Thoracic},
	Month = {Mar},
	Number = {1},
	Pages = {23-32},
	Pmc = {PMC5337239},
	Pmid = {28211015},
	Pst = {ppublish},
	Title = {Fifty years of computer analysis in chest imaging: rule-based, machine learning, deep learning},
	Volume = {10},
	Year = {2017},
	Bdsk-Url-1 = {https://doi.org/10.1007/s12194-017-0394-5}}

@article{Gibson:2018aa,
	Abstract = {BACKGROUND AND OBJECTIVES: Medical image analysis and computer-assisted intervention problems are increasingly being addressed with deep-learning-based solutions. Established deep-learning platforms are flexible but do not provide specific functionality for medical image analysis and adapting them for this domain of application requires substantial implementation effort. Consequently, there has been substantial duplication of effort and incompatible infrastructure developed across many research groups. This work presents the open-source NiftyNet platform for deep learning in medical imaging. The ambition of NiftyNet is to accelerate and simplify the development of these solutions, and to provide a common mechanism for disseminating research outputs for the community to use, adapt and build upon.
METHODS: The NiftyNet infrastructure provides a modular deep-learning pipeline for a range of medical imaging applications including segmentation, regression, image generation and representation learning applications. Components of the NiftyNet pipeline including data loading, data augmentation, network architectures, loss functions and evaluation metrics are tailored to, and take advantage of, the idiosyncracies of medical image analysis and computer-assisted intervention. NiftyNet is built on the TensorFlow framework and supports features such as TensorBoard visualization of 2D and 3D images and computational graphs by default.
RESULTS: We present three illustrative medical image analysis applications built using NiftyNet infrastructure: (1) segmentation of multiple abdominal organs from computed tomography; (2) image regression to predict computed tomography attenuation maps from brain magnetic resonance images; and (3) generation of simulated ultrasound images for specified anatomical poses.
CONCLUSIONS: The NiftyNet infrastructure enables researchers to rapidly develop and distribute deep learning solutions for segmentation, regression, image generation and representation learning applications, or extend the platform to new applications.},
	Author = {Gibson, Eli and Li, Wenqi and Sudre, Carole and Fidon, Lucas and Shakir, Dzhoshkun I and Wang, Guotai and Eaton-Rosen, Zach and Gray, Robert and Doel, Tom and Hu, Yipeng and Whyntie, Tom and Nachev, Parashkev and Modat, Marc and Barratt, Dean C and Ourselin, S{\'e}bastien and Cardoso, M Jorge and Vercauteren, Tom},
	Date-Added = {2018-12-10 20:17:50 -0800},
	Date-Modified = {2018-12-10 20:17:50 -0800},
	Doi = {10.1016/j.cmpb.2018.01.025},
	Journal = {Comput Methods Programs Biomed},
	Journal-Full = {Computer methods and programs in biomedicine},
	Keywords = {Convolutional neural network; Deep learning; Generative adversarial network; Image regression; Medical image analysis; Segmentation},
	Mesh = {Abdomen; Brain; Computer Simulation; Databases, Factual; Diagnostic Imaging; Humans; Image Processing, Computer-Assisted; Machine Learning; Magnetic Resonance Imaging; Neural Networks (Computer); Ultrasonography},
	Month = {May},
	Pages = {113-122},
	Pmc = {PMC5869052},
	Pmid = {29544777},
	Pst = {ppublish},
	Title = {NiftyNet: a deep-learning platform for medical imaging},
	Volume = {158},
	Year = {2018},
	Bdsk-Url-1 = {https://doi.org/10.1016/j.cmpb.2018.01.025}}

@article{Suzuki:2017aa,
	Abstract = {The use of machine learning (ML) has been increasing rapidly in the medical imaging field, including computer-aided diagnosis (CAD), radiomics, and medical image analysis. Recently, an ML area called deep learning emerged in the computer vision field and became very popular in many fields. It started from an event in late 2012, when a deep-learning approach based on a convolutional neural network (CNN) won an overwhelming victory in the best-known worldwide computer vision competition, ImageNet Classification. Since then, researchers in virtually all fields, including medical imaging, have started actively participating in the explosively growing field of deep learning. In this paper, the area of deep learning in medical imaging is overviewed, including (1) what was changed in machine learning before and after the introduction of deep learning, (2) what is the source of the power of deep learning, (3) two major deep-learning models: a massive-training artificial neural network (MTANN) and a convolutional neural network (CNN), (4) similarities and differences between the two models, and (5) their applications to medical imaging. This review shows that ML with feature input (or feature-based ML) was dominant before the introduction of deep learning, and that the major and essential difference between ML before and after deep learning is the learning of image data directly without object segmentation or feature extraction; thus, it is the source of the power of deep learning, although the depth of the model is an important attribute. The class of ML with image input (or image-based ML) including deep learning has a long history, but recently gained popularity due to the use of the new terminology, deep learning. There are two major models in this class of ML in medical imaging, MTANN and CNN, which have similarities as well as several differences. In our experience, MTANNs were substantially more efficient in their development, had a higher performance, and required a lesser number of training cases than did CNNs. "Deep learning", or ML with image input, in medical imaging is an explosively growing, promising field. It is expected that ML with image input will be the mainstream area in the field of medical imaging in the next few decades.},
	Author = {Suzuki, Kenji},
	Date-Added = {2018-12-10 20:15:31 -0800},
	Date-Modified = {2018-12-10 20:15:31 -0800},
	Doi = {10.1007/s12194-017-0406-5},
	Journal = {Radiol Phys Technol},
	Journal-Full = {Radiological physics and technology},
	Keywords = {Classification; Computer-aided diagnosis; Convolutional neural network; Deep learning; Massive-training artificial neural network; Medical image analysis},
	Mesh = {Diagnostic Imaging; Image Processing, Computer-Assisted; Machine Learning},
	Month = {Sep},
	Number = {3},
	Pages = {257-273},
	Pmid = {28689314},
	Pst = {ppublish},
	Title = {Overview of deep learning in medical imaging},
	Volume = {10},
	Year = {2017},
	Bdsk-Url-1 = {https://doi.org/10.1007/s12194-017-0406-5}}

@article{Shen:2017aa,
	Abstract = {This review covers computer-assisted analysis of images in the field of medical imaging. Recent advances in machine learning, especially with regard to deep learning, are helping to identify, classify, and quantify patterns in medical images. At the core of these advances is the ability to exploit hierarchical feature representations learned solely from data, instead of features designed by hand according to domain-specific knowledge. Deep learning is rapidly becoming the state of the art, leading to enhanced performance in various medical applications. We introduce the fundamentals of deep learning methods and review their successes in image registration, detection of anatomical and cellular structures, tissue segmentation, computer-aided disease diagnosis and prognosis, and so on. We conclude by discussing research issues and suggesting future directions for further improvement.},
	Author = {Shen, Dinggang and Wu, Guorong and Suk, Heung-Il},
	Date-Added = {2018-12-10 20:15:02 -0800},
	Date-Modified = {2018-12-10 20:15:02 -0800},
	Doi = {10.1146/annurev-bioeng-071516-044442},
	Journal = {Annu Rev Biomed Eng},
	Journal-Full = {Annual review of biomedical engineering},
	Keywords = {deep learning; medical image analysis; unsupervised feature learning},
	Mesh = {Algorithms; Diagnostic Imaging; Image Enhancement; Image Interpretation, Computer-Assisted; Neural Networks (Computer); Pattern Recognition, Automated; Unsupervised Machine Learning},
	Month = {06},
	Pages = {221-248},
	Pmc = {PMC5479722},
	Pmid = {28301734},
	Pst = {ppublish},
	Title = {Deep Learning in Medical Image Analysis},
	Volume = {19},
	Year = {2017},
	Bdsk-Url-1 = {https://doi.org/10.1146/annurev-bioeng-071516-044442}}

@article{Greenspan:2016aa,
	Author = {Hayit Greenspan and Bram Van Ginneken and Ronald M. Summers},
	Date-Added = {2018-12-10 20:09:21 -0800},
	Date-Modified = {2018-12-10 20:13:01 -0800},
	Journal = {IEEE Trans Med Imaging},
	Number = {5},
	Pages = {1153--1159},
	Title = {Deep Learning in Medical Imaging: Overview and Future Promise of an Exciting New Technique},
	Volume = {35},
	Year = {2016}}

@webpage{imageNetKaggle,
	Date-Added = {2018-12-10 15:48:35 -0800},
	Date-Modified = {2018-12-10 15:48:35 -0800},
	Lastchecked = {Dec. 10, 2018},
	Url = {https://www.kaggle.com/c/imagenet-object-localization-challenge},
	Bdsk-Url-1 = {https://www.kaggle.com/c/imagenet-object-localization-challenge}}

@article{He:2015,
	Archiveprefix = {arXiv},
	Author = {Kaiming He and Xiangyu Zhang and Shaoqing Ren and Jian Sun},
	Bibsource = {dblp computer science bibliography, https://dblp.org},
	Biburl = {https://dblp.org/rec/bib/journals/corr/HeZRS15},
	Date-Added = {2018-12-10 14:19:21 -0800},
	Date-Modified = {2018-12-10 14:19:21 -0800},
	Eprint = {1512.03385},
	Journal = {CoRR},
	Timestamp = {Wed, 07 Jun 2017 14:41:17 +0200},
	Title = {Deep Residual Learning for Image Recognition},
	Url = {http://arxiv.org/abs/1512.03385},
	Volume = {abs/1512.03385},
	Year = {2015},
	Bdsk-Url-1 = {http://arxiv.org/abs/1512.03385}}

@article{Szegedy:2015,
	Archiveprefix = {arXiv},
	Author = {Christian Szegedy and Vincent Vanhoucke and Sergey Ioffe and Jonathon Shlens and Zbigniew Wojna},
	Bibsource = {dblp computer science bibliography, https://dblp.org},
	Biburl = {https://dblp.org/rec/bib/journals/corr/SzegedyVISW15},
	Date-Added = {2018-12-08 20:37:54 -0800},
	Date-Modified = {2018-12-08 20:37:54 -0800},
	Eprint = {1512.00567},
	Journal = {CoRR},
	Timestamp = {Wed, 07 Jun 2017 14:40:22 +0200},
	Title = {Rethinking the Inception Architecture for Computer Vision},
	Url = {http://arxiv.org/abs/1512.00567},
	Volume = {abs/1512.00567},
	Year = {2015},
	Bdsk-Url-1 = {http://arxiv.org/abs/1512.00567}}

@article{Simonyan:2014,
	Archiveprefix = {arXiv},
	Author = {Karen Simonyan and Andrew Zisserman},
	Bibsource = {dblp computer science bibliography, https://dblp.org},
	Biburl = {https://dblp.org/rec/bib/journals/corr/SimonyanZ14a},
	Date-Added = {2018-12-08 20:37:09 -0800},
	Date-Modified = {2019-05-21 22:13:20 -0700},
	Eprint = {1409.1556},
	Journal = {CoRR},
	Timestamp = {Wed, 07 Jun 2017 14:41:51 +0200},
	Title = {Very Deep Convolutional Networks for Large-Scale Image Recognition},
	Volume = {abs/1409.1556},
	Year = {2014},
	Bdsk-Url-1 = {http://arxiv.org/abs/1409.1556}}

@article{Russakovsky:2015aa,
	Author = {Olga Russakovsky and Jia Deng and Hao Su and Jonathan Krause and Sanjeev Satheesh and Sean Ma and Zhiheng Huang and Andrej Karpathy and Aditya Khosla and Michael Bernstein and Alexander C. Berg and Li Fei-Fei},
	Date-Added = {2018-12-08 20:34:23 -0800},
	Date-Modified = {2019-05-21 22:14:36 -0700},
	Journal = {Int J Comput Vis},
	Month = {December},
	Number = {3},
	Pages = {211-252},
	Title = {{ImageNet} Large Scale Visual Recognition Challenge},
	Volume = {115},
	Year = {2015}}

@inproceedings{Ronneberger:2015aa,
	Author = {Olaf Ronneberger and Philipp Fischer and Thomas Brox},
	Booktitle = {Proceedings of the {I}nternational {C}onference on {M}edical {I}mage {C}omputing and {C}omputer-{A}ssisted {I}ntervention},
	Date-Added = {2018-12-08 20:34:19 -0800},
	Date-Modified = {2018-12-23 20:13:39 -0800},
	Pages = {234-241},
	Publisher = {Springer},
	Series = {LNCS},
	Title = {U-Net: Convolutional Networks for Biomedical Image Segmentation},
	Volume = {9351},
	Year = {2015}}

@inproceedings{Krizhevsky:2012,
	Acmid = {2999257},
	Address = {USA},
	Author = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E.},
	Booktitle = {Proceedings of the 25th {I}nternational {C}onference on {N}eural {I}nformation {P}rocessing {S}ystems},
	Date-Added = {2018-12-08 20:33:50 -0800},
	Date-Modified = {2019-05-21 22:13:38 -0700},
	Location = {Lake Tahoe, Nevada},
	Numpages = {9},
	Pages = {1097--1105},
	Publisher = {Curran Associates Inc.},
	Series = {NIPS'12},
	Title = {ImageNet Classification with Deep Convolutional Neural Networks},
	Year = {2012},
	Bdsk-Url-1 = {http://dl.acm.org/citation.cfm?id=2999134.2999257}}

@inproceedings{Waibel:1987aa,
	Author = {Alex Waibel},
	Booktitle = {Meeting of the {I}nstitute of {E}lectrical, {I}nformation and {C}ommunication {E}ngineers ({IEICE}).},
	Date-Added = {2018-12-08 19:05:03 -0800},
	Date-Modified = {2018-12-23 20:11:11 -0800},
	Title = {Phoneme Recognition Using Time-Delay Neural Networks},
	Year = {1987}}

@article{Hubel:1962aa,
	Author = {D. H. Hubel and T. N. Wiesel},
	Date-Added = {2018-12-08 18:42:46 -0800},
	Date-Modified = {2018-12-08 18:43:37 -0800},
	Journal = {J Physiol},
	Journal-Full = {The Journal of physiology},
	Keywords = {CEREBRAL CORTEX/physiology},
	Mesh = {Animals; Cats; Cerebral Cortex; Visual Cortex},
	Month = {Jan},
	Pages = {106-54},
	Pmc = {PMC1359523},
	Pmid = {14449617},
	Pst = {ppublish},
	Title = {Receptive fields, binocular interaction and functional architecture in the cat's visual cortex},
	Volume = {160},
	Year = {1962}}

@article{LeCun:1989aa,
	Author = {Y. LeCun and B. Boser and J. S. Denker and D. Henderson and R. E. Howard and W. Hubbard and L. D. Jacke},
	Date-Added = {2018-12-08 18:38:39 -0800},
	Date-Modified = {2018-12-08 18:40:03 -0800},
	Journal = {Neural Computation},
	Number = {4},
	Pages = {541--551},
	Title = {Backpropagation Applied to Handwritten Zip Code Recognition},
	Volume = {1},
	Year = {1989}}

@article{LeCun:2015aa,
	Abstract = {Deep learning allows computational models that are composed of multiple processing layers to learn representations of data with multiple levels of abstraction. These methods have dramatically improved the state-of-the-art in speech recognition, visual object recognition, object detection and many other domains such as drug discovery and genomics. Deep learning discovers intricate structure in large data sets by using the backpropagation algorithm to indicate how a machine should change its internal parameters that are used to compute the representation in each layer from the representation in the previous layer. Deep convolutional nets have brought about breakthroughs in processing images, video, speech and audio, whereas recurrent nets have shone light on sequential data such as text and speech. },
	Author = {LeCun, Yann and Bengio, Yoshua and Hinton, Geoffrey},
	Date-Added = {2018-12-08 18:32:49 -0800},
	Date-Modified = {2018-12-08 18:33:14 -0800},
	Doi = {10.1038/nature14539},
	Journal = {Nature},
	Journal-Full = {Nature},
	Mesh = {Algorithms; Artificial Intelligence; Computers; Language; Neural Networks (Computer)},
	Month = {May},
	Number = {7553},
	Pages = {436-44},
	Pmid = {26017442},
	Pst = {ppublish},
	Title = {Deep learning},
	Volume = {521},
	Year = {2015},
	Bdsk-Url-1 = {https://doi.org/10.1038/nature14539}}

@article{Fukushima:1980aa,
	Abstract = {A neural network model for a mechanism of visual pattern recognition is proposed in this paper. The network is self-organized by "learning without a teacher", and acquires an ability to recognize stimulus patterns based on the geometrical similarity (Gestalt) of their shapes without affected by their positions. This network is given a nickname "neocognitron". After completion of self-organization, the network has a structure similar to the hierarchy model of the visual nervous system proposed by Hubel and Wiesel. The network consists of an input layer (photoreceptor array) followed by a cascade connection of a number of modular structures, each of which is composed of two layers of cells connected in a cascade. The first layer of each module consists of "S-cells", which show characteristics similar to simple cells or lower order hypercomplex cells, and the second layer consists of "C-cells" similar to complex cells or higher order hypercomplex cells. The afferent synapses to each S-cell have plasticity and are modifiable. The network has an ability of unsupervised learning: We do not need any "teacher" during the process of self-organization, and it is only needed to present a set of stimulus patterns repeatedly to the input layer of the network. The network has been simulated on a digital computer. After repetitive presentation of a set of stimulus patterns, each stimulus pattern has become to elicit an output only from one of the C-cells of the last layer, and conversely, this C-cell has become selectively responsive only to that stimulus pattern. That is, none of the C-cells of the last layer responds to more than one stimulus pattern. The response of the C-cells of the last layer is not affected by the pattern's position at all. Neither is it affected by a small change in shape nor in size of the stimulus pattern.},
	Author = {Fukushima, K},
	Date-Added = {2018-12-08 18:19:32 -0800},
	Date-Modified = {2018-12-08 18:19:32 -0800},
	Journal = {Biol Cybern},
	Journal-Full = {Biological cybernetics},
	Mesh = {Cognition; Computers; Form Perception; Learning; Models, Neurological; Nerve Net; Nervous System Physiological Phenomena; Pattern Recognition, Visual},
	Number = {4},
	Pages = {193-202},
	Pmid = {7370364},
	Pst = {ppublish},
	Title = {Neocognitron: a self organizing neural network model for a mechanism of pattern recognition unaffected by shift in position},
	Volume = {36},
	Year = {1980}}

@article{Ivakhnenko:1971aa,
	Author = {A. G. Ivakhnenko},
	Date-Added = {2018-12-08 18:05:08 -0800},
	Date-Modified = {2019-05-21 22:19:22 -0700},
	Journal = {IEEE Trans Syst Man Cybern Syst},
	Month = {Oct},
	Number = {4},
	Pages = {364--378},
	Title = {Polynomial Theory of Complex Systems},
	Volume = {SMC-1},
	Year = {1971}}

@article{Pluim:2003aa,
	Abstract = {An overview is presented of the medical image processing literature on mutual-information-based registration. The aim of the survey is threefold: an introduction for those new to the field, an overview for those working in the field, and a reference for those searching for literature on a specific application. Methods are classified according to the different aspects of mutual-information-based registration. The main division is in aspects of the methodology and of the application. The part on methodology describes choices made on facets such as preprocessing of images, gray value interpolation, optimization, adaptations to the mutual information measure, and different types of geometrical transformations. The part on applications is a reference of the literature available on different modalities, on interpatient registration and on different anatomical objects. Comparison studies including mutual information are also considered. The paper starts with a description of entropy and mutual information and it closes with a discussion on past achievements and some future challenges.},
	Author = {Pluim, Josien P W and Maintz, J B Antoine and Viergever, Max A},
	Date-Added = {2018-12-06 21:14:24 -0800},
	Date-Modified = {2018-12-06 21:14:24 -0800},
	Doi = {10.1109/TMI.2003.815867},
	Journal = {IEEE Trans Med Imaging},
	Journal-Full = {IEEE transactions on medical imaging},
	Mesh = {Algorithms; Anatomy, Cross-Sectional; Humans; Image Enhancement; Image Interpretation, Computer-Assisted; Imaging, Three-Dimensional; Pattern Recognition, Automated; Subtraction Technique},
	Month = {Aug},
	Number = {8},
	Pages = {986-1004},
	Pmid = {12906253},
	Pst = {ppublish},
	Title = {Mutual-information-based registration of medical images: a survey},
	Volume = {22},
	Year = {2003},
	Bdsk-Url-1 = {https://doi.org/10.1109/TMI.2003.815867}}

@article{Gholipour:2007aa,
	Abstract = {Functional localization is a concept which involves the application of a sequence of geometrical and statistical image processing operations in order to define the location of brain activity or to produce functional/parametric maps with respect to the brain structure or anatomy. Considering that functional brain images do not normally convey detailed structural information and, thus, do not present an anatomically specific localization of functional activity, various image registration techniques are introduced in the literature for the purpose of mapping functional activity into an anatomical image or a brain atlas. The problems addressed by these techniques differ depending on the application and the type of analysis, i.e., single-subject versus group analysis. Functional to anatomical brain image registration is the core part of functional localization in most applications and is accompanied by intersubject and subject-to-atlas registration for group analysis studies. Cortical surface registration and automatic brain labeling are some of the other tools towards establishing a fully automatic functional localization procedure. While several previous survey papers have reviewed and classified general-purpose medical image registration techniques, this paper provides an overview of brain functional localization along with a survey and classification of the image registration techniques related to this problem.},
	Author = {Gholipour, Ali and Kehtarnavaz, Nasser and Briggs, Richard and Devous, Michael and Gopinath, Kaundinya},
	Date-Added = {2018-12-06 21:12:34 -0800},
	Date-Modified = {2018-12-06 21:12:34 -0800},
	Doi = {10.1109/TMI.2007.892508},
	Journal = {IEEE Trans Med Imaging},
	Journal-Full = {IEEE transactions on medical imaging},
	Mesh = {Algorithms; Artificial Intelligence; Brain; Brain Mapping; Cluster Analysis; Evoked Potentials; Humans; Image Enhancement; Image Interpretation, Computer-Assisted; Imaging, Three-Dimensional; Magnetic Resonance Imaging; Pattern Recognition, Automated; Reproducibility of Results; Sensitivity and Specificity; Subtraction Technique},
	Month = {Apr},
	Number = {4},
	Pages = {427-51},
	Pmid = {17427731},
	Pst = {ppublish},
	Title = {Brain functional localization: a survey of image registration techniques},
	Volume = {26},
	Year = {2007},
	Bdsk-Url-1 = {https://doi.org/10.1109/TMI.2007.892508}}

@article{Maintz:1998aa,
	Abstract = {The purpose of this paper is to present a survey of recent (published in 1993 or later) publications concerning medical image registration techniques. These publications will be classified according to a model based on nine salient criteria, the main dichotomy of which is extrinsic versus intrinsic methods. The statistics of the classification show definite trends in the evolving registration techniques, which will be discussed. At this moment, the bulk of interesting intrinsic methods is based on either segmented points or surfaces, or on techniques endeavouring to use the full information content of the images involved.},
	Author = {Maintz, J B and Viergever, M A},
	Date-Added = {2018-12-06 21:11:12 -0800},
	Date-Modified = {2018-12-06 21:11:12 -0800},
	Journal = {Med Image Anal},
	Journal-Full = {Medical image analysis},
	Mesh = {Abdomen; Diagnostic Imaging; Extremities; Head; Humans; Pelvis; Reproducibility of Results; Spine; Thorax},
	Month = {Mar},
	Number = {1},
	Pages = {1-36},
	Pmid = {10638851},
	Pst = {ppublish},
	Title = {A survey of medical image registration},
	Volume = {2},
	Year = {1998}}

@article{Brown:1992,
	Acmid = {146374},
	Address = {New York, NY, USA},
	Author = {Brown, Lisa Gottesfeld},
	Date-Added = {2018-12-06 21:08:51 -0800},
	Date-Modified = {2019-05-21 22:20:16 -0700},
	Doi = {10.1145/146370.146374},
	Issn = {0360-0300},
	Issue_Date = {Dec. 1992},
	Journal = {ACM Comput Surv},
	Keywords = {image registration, image warping, rectification, template matching},
	Month = dec,
	Number = {4},
	Numpages = {52},
	Pages = {325--376},
	Publisher = {ACM},
	Title = {A Survey of Image Registration Techniques},
	Volume = {24},
	Year = {1992},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/146370.146374},
	Bdsk-Url-2 = {https://doi.org/10.1145/146370.146374}}

@article{Keszei:2017aa,
	Abstract = {We catalogue available software solutions for non-rigid image registration to support scientists in selecting suitable tools for specific medical registration purposes. Registration tools were identified using non-systematic search in Pubmed, Web of Science, IEEE Xplore{\textregistered} Digital Library, Google Scholar, and through references in identified sources (nâ€‰=â€‰22). Exclusions are due to unavailability or inappropriateness. The remaining (nâ€‰=â€‰18) tools were classified by (i) access and technology, (ii) interfaces and application, (iii) living community, (iv) supported file formats, and (v) types of registration methodologies emphasizing the similarity measures implemented. Out of the 18 tools, (i) 12 are open source, 8 are released under a permissive free license, which imposes the least restrictions on the use and further development of the tool, 8 provide graphical processing unit (GPU) support; (ii) 7 are built on software platforms, 5 were developed for brain image registration; (iii) 6 are under active development but only 3 have had their last update in 2015 or 2016; (iv) 16 support the Analyze format, while 7 file formats can be read with only one of the tools; and (v) 6 provide multiple registration methods and 6 provide landmark-based registration methods. Based on open source, licensing, GPU support, active community, several file formats, algorithms, and similarity measures, the tools Elastics and Plastimatch are chosen for the platform ITK and without platform requirements, respectively. Researchers in medical image analysis already have a large choice of registration tools freely available. However, the most recently published algorithms may not be included in the tools, yet.},
	Author = {Keszei, Andr{\'a}s P and Berkels, Benjamin and Deserno, Thomas M},
	Date-Added = {2018-12-06 21:07:25 -0800},
	Date-Modified = {2018-12-06 21:07:25 -0800},
	Doi = {10.1007/s10278-016-9915-8},
	Journal = {J Digit Imaging},
	Journal-Full = {Journal of digital imaging},
	Keywords = {Image alignment; Image analysis; Image registration; Open-source software; Public domain software; Software tool},
	Mesh = {Algorithms; Brain; Humans; Radiology Information Systems; Software; Surveys and Questionnaires; User-Computer Interface},
	Month = {02},
	Number = {1},
	Pages = {102-116},
	Pmc = {PMC5267604},
	Pmid = {27730414},
	Pst = {ppublish},
	Title = {Survey of Non-Rigid Registration Tools in Medicine},
	Volume = {30},
	Year = {2017},
	Bdsk-Url-1 = {https://doi.org/10.1007/s10278-016-9915-8}}

@article{Viergever:2016aa,
	Abstract = {A retrospective view on the past two decades of the field of medical image registration is presented, guided by the article "A survey of medical image registration" (Maintz and Viergever, 1998). It shows that the classification of the field introduced in that article is still usable, although some modifications to do justice to advances in the field would be due. The main changes over the last twenty years are the shift from extrinsic to intrinsic registration, the primacy of intensity-based registration, the breakthrough of nonlinear registration, the progress of inter-subject registration, and the availability of generic image registration software packages. Two problems that were called urgent already 20 years ago, are even more urgent nowadays: Validation of registration methods, and translation of results of image registration research to clinical practice. It may be concluded that the field of medical image registration has evolved, but still is in need of further development in various aspects.},
	Author = {Viergever, Max A and Maintz, J B Antoine and Klein, Stefan and Murphy, Keelin and Staring, Marius and Pluim, Josien P W},
	Date-Added = {2018-12-06 21:05:51 -0800},
	Date-Modified = {2018-12-06 21:05:51 -0800},
	Doi = {10.1016/j.media.2016.06.030},
	Journal = {Med Image Anal},
	Journal-Full = {Medical image analysis},
	Keywords = {Medical image registration},
	Mesh = {Algorithms; Humans; Image Processing, Computer-Assisted; Retrospective Studies},
	Month = {10},
	Pages = {140-144},
	Pmid = {27427472},
	Pst = {ppublish},
	Title = {A survey of medical image registration - under review},
	Volume = {33},
	Year = {2016},
	Bdsk-Url-1 = {https://doi.org/10.1016/j.media.2016.06.030}}

@article{Avants:2010aa,
	Abstract = {We use a new, unsupervised multivariate imaging and analysis strategy to identify related patterns of reduced white matter integrity, measured with the fractional anisotropy (FA) derived from diffusion tensor imaging (DTI), and decreases in cortical thickness, measured by high resolution T1-weighted imaging, in Alzheimer's disease (AD) and frontotemporal dementia (FTD). This process is based on a novel computational model derived from sparse canonical correlation analysis (SCCA) that allows us to automatically identify mutually predictive, distributed neuroanatomical regions from different imaging modalities. We apply the SCCA model to a dataset that includes 23 control subjects that are demographically matched to 49 subjects with autopsy or CSF-biomarker-diagnosed AD (n=24) and FTD (n=25) with both DTI and T1-weighted structural imaging. SCCA shows that the FTD-related frontal and temporal degeneration pattern is correlated across modalities with permutation corrected p<0.0005. In AD, we find significant association between cortical thinning and reduction in white matter integrity within a distributed parietal and temporal network (p<0.0005). Furthermore, we show that-within SCCA identified regions-significant differences exist between FTD and AD cortical-connective degeneration patterns. We validate these distinct, multimodal imaging patterns by showing unique relationships with cognitive measures in AD and FTD. We conclude that SCCA is a potentially valuable approach in image analysis that can be applied productively to distinguishing between neurodegenerative conditions.},
	Author = {Avants, Brian B and Cook, Philip A and Ungar, Lyle and Gee, James C and Grossman, Murray},
	Date-Added = {2018-12-06 20:45:59 -0800},
	Date-Modified = {2018-12-06 20:45:59 -0800},
	Doi = {10.1016/j.neuroimage.2010.01.041},
	Journal = {Neuroimage},
	Journal-Full = {NeuroImage},
	Mesh = {Alzheimer Disease; Anisotropy; Biomarkers; Brain; Cerebral Cortex; Computer Simulation; Databases, Factual; Dementia; Diffusion Tensor Imaging; Female; Frontotemporal Dementia; Humans; Image Processing, Computer-Assisted; Magnetic Resonance Imaging; Male; Middle Aged; Models, Neurological; Multivariate Analysis; Nerve Fibers, Myelinated; Organ Size},
	Month = {Apr},
	Number = {3},
	Pages = {1004-16},
	Pmc = {PMC2953719},
	Pmid = {20083207},
	Pst = {ppublish},
	Title = {Dementia induces correlated reductions in white matter integrity and cortical thickness: a multivariate neuroimaging study with sparse canonical correlation analysis},
	Volume = {50},
	Year = {2010},
	Bdsk-Url-1 = {https://doi.org/10.1016/j.neuroimage.2010.01.041}}

@article{Iglesias:2015aa,
	Abstract = {Multi-atlas segmentation (MAS), first introduced and popularized by the pioneering work of Rohlfing, et al. (2004), Klein, et al. (2005), and Heckemann, et al. (2006), is becoming one of the most widely-used and successful image segmentation techniques in biomedical applications. By manipulating and utilizing the entire dataset of "atlases" (training images that have been previously labeled, e.g., manually by an expert), rather than some model-based average representation, MAS has the flexibility to better capture anatomical variation, thus offering superior segmentation accuracy. This benefit, however, typically comes at a high computational cost. Recent advancements in computer hardware and image processing software have been instrumental in addressing this challenge and facilitated the wide adoption of MAS. Today, MAS has come a long way and the approach includes a wide array of sophisticated algorithms that employ ideas from machine learning, probabilistic modeling, optimization, and computer vision, among other fields. This paper presents a survey of published MAS algorithms and studies that have applied these methods to various biomedical problems. In writing this survey, we have three distinct aims. Our primary goal is to document how MAS was originally conceived, later evolved, and now relates to alternative methods. Second, this paper is intended to be a detailed reference of past research activity in MAS, which now spans over a decade (2003-2014) and entails novel methodological developments and application-specific solutions. Finally, our goal is to also present a perspective on the future of MAS, which, we believe, will be one of the dominant approaches in biomedical image segmentation.},
	Author = {Iglesias, Juan Eugenio and Sabuncu, Mert R},
	Date-Added = {2018-12-06 20:22:39 -0800},
	Date-Modified = {2018-12-06 20:22:39 -0800},
	Doi = {10.1016/j.media.2015.06.012},
	Journal = {Med Image Anal},
	Journal-Full = {Medical image analysis},
	Keywords = {Label fusion; Multi-atlas segmentation; Survey},
	Mesh = {Algorithms; Humans; Image Interpretation, Computer-Assisted; Pattern Recognition, Automated; Reproducibility of Results; Sensitivity and Specificity; Subtraction Technique},
	Month = {Aug},
	Number = {1},
	Pages = {205-219},
	Pmc = {PMC4532640},
	Pmid = {26201875},
	Pst = {ppublish},
	Title = {Multi-atlas segmentation of biomedical images: A survey},
	Volume = {24},
	Year = {2015},
	Bdsk-Url-1 = {https://doi.org/10.1016/j.media.2015.06.012}}

@article{Singh:2013aa,
	Abstract = {This paper presents a novel approach for diffeomorphic image regression and atlas estimation that results in improved convergence and numerical stability. We use a vector momenta representation of a diffeomorphism's initial conditions instead of the standard scalar momentum that is typically used. The corresponding variational problem results in a closed-form update for template estimation in both the geodesic regression and atlas estimation problems. While we show that the theoretical optimal solution is equivalent to the scalar momenta case, the simplification of the optimization problem leads to more stable and efficient estimation in practice. We demonstrate the effectiveness of our method for atlas estimation and geodesic regression using synthetically generated shapes and 3D MRI brain scans.},
	Author = {Singh, Nikhil and Hinkle, Jacob and Joshi, Sarang and Fletcher, P Thomas},
	Date-Added = {2018-11-26 20:18:45 -0800},
	Date-Modified = {2018-11-26 20:19:50 -0800},
	Doi = {10.1109/ISBI.2013.6556700},
	Journal = {Proc IEEE Int Symp Biomed Imaging},
	Journal-Full = {Proceedings. IEEE International Symposium on Biomedical Imaging},
	Keywords = {Atlas; Geodesic regression; LDDMM; Vector Momentum},
	Month = {Apr},
	Pages = {1219-1222},
	Pmc = {PMC4232950},
	Pmid = {25404997},
	Pst = {ppublish},
	Title = {A Vector Momenta Formulation of Diffeomorphisms for Improved Geodesic Regression And Atlas Construction},
	Volume = {2013},
	Year = {2013},
	Bdsk-Url-1 = {https://doi.org/10.1109/ISBI.2013.6556700}}

@article{Miller:2006aa,
	Abstract = {Studying large deformations with a Riemannian approach has been an efficient point of view to generate metrics between deformable objects, and to provide accurate, non ambiguous and smooth matchings between images. In this paper, we study the geodesics of such large deformation diffeomorphisms, and more precisely, introduce a fundamental property that they satisfy, namely the conservation of momentum. This property allows us to generate and store complex deformations with the help of one initial "momentum" which serves as the initial state of a differential equation in the group of diffeomorphisms. Moreover, it is shown that this momentum can be also used for describing a deformation of given visual structures, like points, contours or images, and that, it has the same dimension as the described object, as a consequence of the normal momentum constraint we introduce.},
	Author = {Miller, Michael I and Trouv{\'e}, Alain and Younes, Laurent},
	Date-Added = {2018-11-26 18:55:31 -0800},
	Date-Modified = {2018-11-26 18:55:31 -0800},
	Doi = {10.1007/s10851-005-3624-0},
	Journal = {J Math Imaging Vis},
	Journal-Full = {Journal of mathematical imaging and vision},
	Month = {Jan},
	Number = {2},
	Pages = {209-228},
	Pmc = {PMC2897162},
	Pmid = {20613972},
	Pst = {ppublish},
	Title = {Geodesic Shooting for Computational Anatomy},
	Volume = {24},
	Year = {2006},
	Bdsk-Url-1 = {https://doi.org/10.1007/s10851-005-3624-0}}

@article{Vercauteren:2009aa,
	Abstract = {We propose an efficient non-parametric diffeomorphic image registration algorithm based on Thirion's demons algorithm. In the first part of this paper, we show that Thirion's demons algorithm can be seen as an optimization procedure on the entire space of displacement fields. We provide strong theoretical roots to the different variants of Thirion's demons algorithm. This analysis predicts a theoretical advantage for the symmetric forces variant of the demons algorithm. We show on controlled experiments that this advantage is confirmed in practice and yields a faster convergence. In the second part of this paper, we adapt the optimization procedure underlying the demons algorithm to a space of diffeomorphic transformations. In contrast to many diffeomorphic registration algorithms, our solution is computationally efficient since in practice it only replaces an addition of displacement fields by a few compositions. Our experiments show that in addition to being diffeomorphic, our algorithm provides results that are similar to the ones from the demons algorithm but with transformations that are much smoother and closer to the gold standard, available in controlled experiments, in terms of Jacobians.},
	Author = {Vercauteren, Tom and Pennec, Xavier and Perchant, Aymeric and Ayache, Nicholas},
	Date-Added = {2018-11-26 18:53:33 -0800},
	Date-Modified = {2018-11-26 18:53:33 -0800},
	Doi = {10.1016/j.neuroimage.2008.10.040},
	Journal = {Neuroimage},
	Journal-Full = {NeuroImage},
	Mesh = {Algorithms; Humans; Image Processing, Computer-Assisted},
	Month = {Mar},
	Number = {1 Suppl},
	Pages = {S61-72},
	Pmid = {19041946},
	Pst = {ppublish},
	Title = {Diffeomorphic demons: efficient non-parametric image registration},
	Volume = {45},
	Year = {2009},
	Bdsk-Url-1 = {https://doi.org/10.1016/j.neuroimage.2008.10.040}}

@article{Ashburner:2007aa,
	Abstract = {This paper describes DARTEL, which is an algorithm for diffeomorphic image registration. It is implemented for both 2D and 3D image registration and has been formulated to include an option for estimating inverse consistent deformations. Nonlinear registration is considered as a local optimisation problem, which is solved using a Levenberg-Marquardt strategy. The necessary matrix solutions are obtained in reasonable time using a multigrid method. A constant Eulerian velocity framework is used, which allows a rapid scaling and squaring method to be used in the computations. DARTEL has been applied to intersubject registration of 471 whole brain images, and the resulting deformations were evaluated in terms of how well they encode the shape information necessary to separate male and female subjects and to predict the ages of the subjects.},
	Author = {Ashburner, John},
	Date-Added = {2018-11-26 18:50:44 -0800},
	Date-Modified = {2018-11-26 18:50:44 -0800},
	Doi = {10.1016/j.neuroimage.2007.07.007},
	Journal = {Neuroimage},
	Journal-Full = {NeuroImage},
	Mesh = {Algorithms; Artificial Intelligence; Brain; Humans; Image Enhancement; Image Interpretation, Computer-Assisted; Imaging, Three-Dimensional; Magnetic Resonance Imaging; Pattern Recognition, Automated; Reproducibility of Results; Sensitivity and Specificity; Subtraction Technique},
	Month = {Oct},
	Number = {1},
	Pages = {95-113},
	Pmid = {17761438},
	Pst = {ppublish},
	Title = {A fast diffeomorphic image registration algorithm},
	Volume = {38},
	Year = {2007},
	Bdsk-Url-1 = {https://doi.org/10.1016/j.neuroimage.2007.07.007}}

@article{Zhang:2017aa,
	Abstract = {This paper presents an efficient algorithm for large deformation diffeomorphic metric mapping (LDDMM) with geodesic shooting for image registration. We introduce a novel finite dimensional Fourier representation of diffeomorphic deformations based on the key fact that the high frequency components of a diffeomorphism remain stationary throughout the integration process when computing the deformation associated with smooth velocity fields. We show that manipulating high dimensional diffeomorphisms can be carried out entirely in the bandlimited space by integrating the nonstationary low frequency components of the displacement field. This insight substantially reduces the computational cost of the registration problem. Experimental results show that our method is significantly faster than the state-of-the-art diffeomorphic image registration methods while producing equally accurate alignment. We demonstrate our algorithm in two different applications of image registration: neuroimaging and in-utero imaging.},
	Author = {Zhang, Miaomiao and Liao, Ruizhi and Dalca, Adrian V and Turk, Esra A and Luo, Jie and Grant, P Ellen and Golland, Polina},
	Date-Added = {2018-11-26 18:48:45 -0800},
	Date-Modified = {2018-11-26 18:48:45 -0800},
	Doi = {10.1007/978-3-319-59050-9_44},
	Journal = {Inf Process Med Imaging},
	Journal-Full = {Information processing in medical imaging : proceedings of the ... conference},
	Mesh = {Algorithms; Brain; Fetus; Humans; Image Enhancement; Image Interpretation, Computer-Assisted; Neuroimaging; Pattern Recognition, Automated; Reproducibility of Results; Sensitivity and Specificity},
	Month = {Jun},
	Pages = {559-570},
	Pmc = {PMC5788203},
	Pmid = {29391767},
	Pst = {ppublish},
	Title = {Frequency Diffeomorphisms for Efficient Image Registration},
	Volume = {10265},
	Year = {2017},
	Bdsk-Url-1 = {https://doi.org/10.1007/978-3-319-59050-9_44}}

@article{Avants:2008aa,
	Abstract = {One of the most challenging problems in modern neuroimaging is detailed characterization of neurodegeneration. Quantifying spatial and longitudinal atrophy patterns is an important component of this process. These spatiotemporal signals will aid in discriminating between related diseases, such as frontotemporal dementia (FTD) and Alzheimer's disease (AD), which manifest themselves in the same at-risk population. Here, we develop a novel symmetric image normalization method (SyN) for maximizing the cross-correlation within the space of diffeomorphic maps and provide the Euler-Lagrange equations necessary for this optimization. We then turn to a careful evaluation of our method. Our evaluation uses gold standard, human cortical segmentation to contrast SyN's performance with a related elastic method and with the standard ITK implementation of Thirion's Demons algorithm. The new method compares favorably with both approaches, in particular when the distance between the template brain and the target brain is large. We then report the correlation of volumes gained by algorithmic cortical labelings of FTD and control subjects with those gained by the manual rater. This comparison shows that, of the three methods tested, SyN's volume measurements are the most strongly correlated with volume measurements gained by expert labeling. This study indicates that SyN, with cross-correlation, is a reliable method for normalizing and making anatomical measurements in volumetric MRI of patients and at-risk elderly individuals.},
	Author = {Avants, B B and Epstein, C L and Grossman, M and Gee, J C},
	Date-Added = {2018-11-26 18:45:42 -0800},
	Date-Modified = {2018-11-26 18:45:42 -0800},
	Doi = {10.1016/j.media.2007.06.004},
	Journal = {Med Image Anal},
	Journal-Full = {Medical image analysis},
	Mesh = {Algorithms; Atrophy; Cerebral Cortex; Dementia; Humans; Image Enhancement; Image Interpretation, Computer-Assisted; Magnetic Resonance Imaging},
	Month = {Feb},
	Number = {1},
	Pages = {26-41},
	Pmc = {PMC2276735},
	Pmid = {17659998},
	Pst = {ppublish},
	Title = {Symmetric diffeomorphic image registration with cross-correlation: evaluating automated labeling of elderly and neurodegenerative brain},
	Volume = {12},
	Year = {2008},
	Bdsk-Url-1 = {https://doi.org/10.1016/j.media.2007.06.004}}

@article{Christensen:1996aa,
	Abstract = {A general automatic approach is presented for accommodating local shape variation when mapping a two-dimensional (2-D) or three-dimensional (3-D) template image into alignment with a topologically similar target image. Local shape variability is accommodated by applying a vector-field transformation to the underlying material coordinate system of the template while constraining the transformation to be smooth (globally positive definite Jacobian). Smoothness is guaranteed without specifically penalizing large-magnitude deformations of small subvolumes by constraining the transformation on the basis of a Stokesian limit of the fluid-dynamical Navier-Stokes equations. This differs fundamentally from quadratic penalty methods, such as those based on linearized elasticity or thin-plate splines, in that stress restraining the motion relaxes over time allowing large-magnitude deformations. Kinematic nonlinearities are inherently necessary to maintain continuity of structures during large-magnitude deformations, and are included in all results. After initial global registration, final mappings are obtained by numerically solving a set of nonlinear partial differential equations associated with the constrained optimization problem. Automatic regridding is performed by propagating templates as the nonlinear transformations evaluated on a finite lattice become singular. Application of the method to intersubject registration of neuroanatomical structures illustrates the ability to account for local anatomical variability.},
	Author = {Christensen, G E and Rabbitt, R D and Miller, M I},
	Date-Added = {2018-11-26 18:37:25 -0800},
	Date-Modified = {2018-11-26 18:37:25 -0800},
	Doi = {10.1109/83.536892},
	Journal = {IEEE Trans Image Process},
	Journal-Full = {IEEE transactions on image processing : a publication of the IEEE Signal Processing Society},
	Number = {10},
	Pages = {1435-47},
	Pmid = {18290061},
	Pst = {ppublish},
	Title = {Deformable templates using large deformation kinematics},
	Volume = {5},
	Year = {1996},
	Bdsk-Url-1 = {https://doi.org/10.1109/83.536892}}

@article{Beg:2005aa,
	Author = {M. Faisal Beg and Michael I. Miller and Alain Trouv{\'e} and Laurent Younes},
	Date-Added = {2018-11-26 13:05:53 -0800},
	Date-Modified = {2018-11-26 13:06:53 -0800},
	Journal = {International Journal of Computer Vision},
	Month = {February},
	Number = {2},
	Pages = {139--157},
	Title = {Computing Large Deformation Metric Mappings via Geodesic Flows of Diffeomorphisms},
	Volume = {61},
	Year = {2004}}

@article{Shams:2010aa,
	Author = {R. Shams and P. Sadeghi and R. A. Kennedy and R. I. Hartley},
	Date-Added = {2018-11-26 12:58:03 -0800},
	Date-Modified = {2018-11-26 13:00:41 -0800},
	Journal = {IEEE Signal Process Mag},
	Number = {2},
	Pages = {50--60},
	Title = {A survey of medical image registration on multicore and the GPU},
	Volume = {27},
	Year = {2010}}

@article{Vialard:2012aa,
	Author = {Fran{\c c}ois-Xavier Vialard and Laurent Risser and Daniel Rueckert and Colin J. Cotter},
	Date-Added = {2018-11-26 12:55:50 -0800},
	Date-Modified = {2019-05-21 21:38:32 -0700},
	Journal = {Int J Comput Vis},
	Pages = {229--241},
	Title = {Diffeomorphic {3D} Image Registration via Geodesic Shooting Using an Efficient Adjoint Calculation},
	Volume = {97},
	Year = {2012}}

@inproceedings{Rohe:2017aa,
	Abstract = {In this paper, we propose an innovative approach for registration based on the deterministic prediction of the parameters from both images instead of the optimization of a energy criteria. The method relies on a fully convolutional network whose architecture consists of contracting layers to detect relevant features and a symmetric expanding path that matches them together and outputs the transformation parametrization. Whereas convolutional networks have seen a widespread expansion and have been already applied to many medical imaging problems such as segmentation and classification, its application to registration has so far faced the challenge of defining ground truth data on which to train the algorithm. Here, we present a novel training strategy to build reference deformations which relies on the registration of segmented regions of interest. We apply this methodology to the problem of inter-patient heart registration and show an important improvement over a state of the art optimization based algorithm. Not only our method is more accurate but it is also faster - registration of two 3D-images taking less than 30 ms second on a GPU - and more robust to outliers.},
	Address = {Cham},
	Author = {Roh{\'e}, Marc-Michel and Datar, Manasi and Heimann, Tobias and Sermesant, Maxime and Pennec, Xavier},
	Booktitle = {Proceedings of the {I}nternational {C}onference on {M}edical {I}mage {C}omputing and {C}omputer-{A}ssisted {I}ntervention},
	Date-Added = {2018-11-08 14:30:54 -0800},
	Date-Modified = {2019-05-21 21:56:33 -0700},
	Editor = {Descoteaux, Maxime and Maier-Hein, Lena and Franz, Alfred and Jannin, Pierre and Collins, D. Louis and Duchesne, Simon},
	Isbn = {978-3-319-66182-7},
	Pages = {266--274},
	Publisher = {Springer International Publishing},
	Title = {SVF-Net: Learning Deformable Image Registration Using Shape Matching},
	Year = {2017}}

@inproceedings{Sokooti:2017aa,
	Abstract = {In this paper we propose a method to solve nonrigid image registration through a learning approach, instead of via iterative optimization of a predefined dissimilarity metric. We design a Convolutional Neural Network (CNN) architecture that, in contrast to all other work, directly estimates the displacement vector field (DVF) from a pair of input images. The proposed RegNet is trained using a large set of artificially generated DVFs, does not explicitly define a dissimilarity metric, and integrates image content at multiple scales to equip the network with contextual information. At testing time nonrigid registration is performed in a single shot, in contrast to current iterative methods. We tested RegNet on 3D chest CT follow-up data. The results show that the accuracy of RegNet is on par with a conventional B-spline registration, for anatomy within the capture range. Training RegNet with artificially generated DVFs is therefore a promising approach for obtaining good results on real clinical data, thereby greatly simplifying the training problem. Deformable image registration can therefore be successfully casted as a learning problem.},
	Address = {Cham},
	Author = {Sokooti, Hessam and de Vos, Bob and Berendsen, Floris and Lelieveldt, Boudewijn P. F. and I{\v{s}}gum, Ivana and Staring, Marius},
	Booktitle = {Proceedings of the {I}nternational {C}onference on {M}edical {I}mage {C}omputing and {C}omputer-{A}ssisted {I}ntervention},
	Date-Added = {2018-11-08 14:26:19 -0800},
	Date-Modified = {2019-05-21 21:39:26 -0700},
	Editor = {Descoteaux, Maxime and Maier-Hein, Lena and Franz, Alfred and Jannin, Pierre and Collins, D. Louis and Duchesne, Simon},
	Isbn = {978-3-319-66182-7},
	Pages = {232--239},
	Publisher = {Springer International Publishing},
	Title = {Nonrigid Image Registration Using Multi-scale 3D Convolutional Neural Networks},
	Year = {2017}}

@article{Yang:2017aa,
	Abstract = {This paper introduces Quicksilver, a fast deformable image registration method. Quicksilver registration for image-pairs works by patch-wise prediction of a deformation model based directly on image appearance. A deep encoder-decoder network is used as the prediction model. While the prediction strategy is general, we focus on predictions for the Large Deformation Diffeomorphic Metric Mapping (LDDMM) model. Specifically, we predict the momentum-parameterization of LDDMM, which facilitates a patch-wise prediction strategy while maintaining the theoretical properties of LDDMM, such as guaranteed diffeomorphic mappings for sufficiently strong regularization. We also provide a probabilistic version of our prediction network which can be sampled during the testing time to calculate uncertainties in the predicted deformations. Finally, we introduce a new correction network which greatly increases the prediction accuracy of an already existing prediction network. We show experimental results for uni-modal atlas-to-image as well as uni-/multi-modal image-to-image registrations. These experiments demonstrate that our method accurately predicts registrations obtained by numerical optimization, is very fast, achieves state-of-the-art registration results on four standard validation datasets, and can jointly learn an image similarity measure. Quicksilver is freely available as an open-source software.},
	Author = {Yang, Xiao and Kwitt, Roland and Styner, Martin and Niethammer, Marc},
	Date-Added = {2018-11-08 14:16:53 -0800},
	Date-Modified = {2018-12-25 11:57:27 -0800},
	Doi = {10.1016/j.neuroimage.2017.07.008},
	Journal = {Neuroimage},
	Journal-Full = {NeuroImage},
	Keywords = {Brain imaging; Deep learning; Image registration},
	Mesh = {Algorithms; Brain; Brain Mapping; Humans; Image Processing, Computer-Assisted; Imaging, Three-Dimensional; Machine Learning; Pattern Recognition, Automated},
	Month = {09},
	Pages = {378-396},
	Pmc = {PMC6036629},
	Pmid = {28705497},
	Pst = {ppublish},
	Title = {Quicksilver: Fast predictive image registration---A deep learning approach},
	Volume = {158},
	Year = {2017},
	Bdsk-Url-1 = {https://doi.org/10.1016/j.neuroimage.2017.07.008}}

@article{Wu:2016aa,
	Abstract = {Feature selection is a critical step in deformable image registration. In particular, selecting the most discriminative features that accurately and concisely describe complex morphological patterns in image patches improves correspondence detection, which in turn improves image registration accuracy. Furthermore, since more and more imaging modalities are being invented to better identify morphological changes in medical imaging data, the development of deformable image registration method that scales well to new image modalities or new image applications with little to no human intervention would have a significant impact on the medical image analysis community. To address these concerns, a learning-based image registration framework is proposed that uses deep learning to discover compact and highly discriminative features upon observed imaging data. Specifically, the proposed feature selection method uses a convolutional stacked autoencoder to identify intrinsic deep feature representations in image patches. Since deep learning is an unsupervised learning method, no ground truth label knowledge is required. This makes the proposed feature selection method more flexible to new imaging modalities since feature representations can be directly learned from the observed imaging data in a very short amount of time. Using the LONI and ADNI imaging datasets, image registration performance was compared to two existing state-of-the-art deformable image registration methods that use handcrafted features. To demonstrate the scalability of the proposed image registration framework, image registration experiments were conducted on 7.0-T brain MR images. In all experiments, the results showed that the new image registration framework consistently demonstrated more accurate registration results when compared to state of the art.},
	Author = {Wu, Guorong and Kim, Minjeong and Wang, Qian and Munsell, Brent C and Shen, Dinggang},
	Date-Added = {2018-11-08 14:16:01 -0800},
	Date-Modified = {2018-11-08 14:16:01 -0800},
	Doi = {10.1109/TBME.2015.2496253},
	Journal = {IEEE Trans Biomed Eng},
	Journal-Full = {IEEE transactions on bio-medical engineering},
	Mesh = {Algorithms; Brain; Humans; Image Processing, Computer-Assisted; Magnetic Resonance Imaging; Unsupervised Machine Learning},
	Month = {07},
	Number = {7},
	Pages = {1505-16},
	Pmc = {PMC4853306},
	Pmid = {26552069},
	Pst = {ppublish},
	Title = {Scalable High-Performance Image Registration Framework by Unsupervised Deep Feature Representations Learning},
	Volume = {63},
	Year = {2016},
	Bdsk-Url-1 = {https://doi.org/10.1109/TBME.2015.2496253}}

@inproceedings{Wohlhart:2015aa,
	Author = {Paul Wohlhart and Vincent Lepetit},
	Bibsource = {dblp computer science bibliography, https://dblp.org},
	Biburl = {https://dblp.org/rec/bib/conf/cvpr/WohlhartL15},
	Booktitle = {{IEEE} Conference on Computer Vision and Pattern Recognition, {CVPR} 2015, Boston, MA, USA, June 7-12, 2015},
	Crossref = {DBLP:conf/cvpr/2015},
	Date-Added = {2018-11-08 14:14:57 -0800},
	Date-Modified = {2018-11-08 14:15:16 -0800},
	Doi = {10.1109/CVPR.2015.7298930},
	Pages = {3109--3118},
	Timestamp = {Thu, 25 May 2017 00:41:23 +0200},
	Title = {Learning descriptors for object recognition and 3D pose estimation},
	Url = {https://doi.org/10.1109/CVPR.2015.7298930},
	Year = {2015},
	Bdsk-Url-1 = {https://doi.org/10.1109/CVPR.2015.7298930}}

@inproceedings{Weinzaepfel:2013aa,
	Author = {P. Weinzaepfel and J. Revaud and Z. Harchaoui and C. Schmid},
	Booktitle = {Proceedings of the {IEEE} {I}nternational {C}onference on {C}omputer {V}ision},
	Date-Added = {2018-11-08 14:12:17 -0800},
	Date-Modified = {2019-05-21 21:59:21 -0700},
	Doi = {10.1109/ICCV.2013.175},
	Issn = {1550-5499},
	Keywords = {computer vision;convolution;image matching;image motion analysis;image retrieval;image sampling;image sequences;minimisation;smoothing methods;variational techniques;large displacement optical flow;deep matching;optical flow computation;computer vision systems;large displacement handling;DeepFlow algorithm;variational approach;descriptor matching algorithm;multistage architecture;interleaving convolutions;max-pooling;deep convolutional nets;dense sampling;quasidense correspondence retrieval;smoothing effect;energy minimization framework;optical flow estimation;MPI-Sintel dataset;Optical imaging;Integrated optics;Nonlinear optics;Optical filters;Adaptive optics;Estimation;Equations;optical flow;large displacements;dense matching;non-rigid matching;deep convolutional networks},
	Month = {Dec},
	Pages = {1385-1392},
	Title = {DeepFlow: Large Displacement Optical Flow with Deep Matching},
	Year = {2013},
	Bdsk-Url-1 = {https://doi.org/10.1109/ICCV.2013.175}}

@inproceedings{Uzunova:2017aa,
	Abstract = {Convolutional neural networks (CNNs) have been successfully used for fast and accurate estimation of dense correspondences between images in computer vision applications. However, much of their success is based on the availability of large training datasets with dense ground truth correspondences, which are only rarely available in medical applications. In this paper, we, therefore, address the problem of CNNs learning from few training data for medical image registration. Our contributions are threefold: (1) We present a novel approach for learning highly expressive appearance models from few training samples, (2) we show that this approach can be used to synthesize huge amounts of realistic ground truth training data for CNN-based medical image registration, and (3) we adapt the FlowNet architecture for CNN-based optical flow estimation to the medical image registration problem. This pipeline is applied to two medical data sets with less than 40 training images. We show that CNNs learned from the proposed generative model outperform those trained on random deformations or displacement fields estimated via classical image registration.},
	Address = {Cham},
	Author = {Uzunova, Hristina and Wilms, Matthias and Handels, Heinz and Ehrhardt, Jan},
	Booktitle = {Medical Image Computing and Computer Assisted Intervention âˆ’ MICCAI 2017},
	Date-Added = {2018-11-08 14:09:20 -0800},
	Date-Modified = {2018-11-08 14:09:41 -0800},
	Editor = {Descoteaux, Maxime and Maier-Hein, Lena and Franz, Alfred and Jannin, Pierre and Collins, D. Louis and Duchesne, Simon},
	Isbn = {978-3-319-66182-7},
	Pages = {223--231},
	Publisher = {Springer International Publishing},
	Title = {Training CNNs for Image Registration from Few Samples with Model-based Data Augmentation},
	Year = {2017}}

@inproceedings{deVos:2017aa,
	Abstract = {In this work we propose a deep learning network for deformable image registration (DIRNet). The DIRNet consists of a convolutional neural network (ConvNet) regressor, a spatial transformer, and a resampler. The ConvNet analyzes a pair of fixed and moving images and outputs parameters for the spatial transformer, which generates the displacement vector field that enables the resampler to warp the moving image to the fixed image. The DIRNet is trained end-to-end by unsupervised optimization of a similarity metric between input image pairs. A trained DIRNet can be applied to perform registration on unseen image pairs in one pass, thus non-iteratively. Evaluation was performed with registration of images of handwritten digits (MNIST) and cardiac cine MR scans (Sunnybrook Cardiac Data). The results demonstrate that registration with DIRNet is as accurate as a conventional deformable image registration method with short execution times.},
	Address = {Cham},
	Author = {de Vos, Bob D. and Berendsen, Floris F. and Viergever, Max A. and Staring, Marius and I{\v{s}}gum, Ivana},
	Booktitle = {Deep Learning in Medical Image Analysis and Multimodal Learning for Clinical Decision Support},
	Date-Added = {2018-11-08 14:08:22 -0800},
	Date-Modified = {2018-11-08 14:08:33 -0800},
	Editor = {Cardoso, M. Jorge and Arbel, Tal and Carneiro, Gustavo and Syeda-Mahmood, Tanveer and Tavares, Jo{\~a}o Manuel R.S. and Moradi, Mehdi and Bradley, Andrew and Greenspan, Hayit and Papa, Jo{\~a}o Paulo and Madabhushi, Anant and Nascimento, Jacinto C. and Cardoso, Jaime S. and Belagiannis, Vasileios and Lu, Zhi},
	Isbn = {978-3-319-67558-9},
	Pages = {204--212},
	Publisher = {Springer International Publishing},
	Title = {End-to-End Unsupervised Deformable Image Registration with a Convolutional Neural Network},
	Year = {2017}}

@inproceedings{Sloan:2018aa,
	Author = {J. M. Sloan and K. A. Goatman and J. P. Siebert},
	Booktitle = {Proceedings of the 11th {I}nternational {J}oint {C}onference on {B}iomedical {E}ngineering {S}ystems and {T}echnologies ({BIOSTEC} 2018) - Volume 2: Bioimaging},
	Date-Added = {2018-11-08 14:01:48 -0800},
	Date-Modified = {2019-05-21 21:40:27 -0700},
	Pages = {89--99},
	Title = {Learning Rigid Image Registration - Utilizing Convolutional Neural Networks for Medical Image Registration},
	Year = {2018}}

@inproceedings{Sheikhjafari:2018aa,
	Author = {Ameneh Sheikhjafari and Michelle Noga and Kumaradevan Punithakumar and Nilanjan Ray},
	Booktitle = {Proceedings of {M}edical {I}maging with {D}eep {L}earning},
	Date-Added = {2018-11-08 13:59:52 -0800},
	Date-Modified = {2019-05-21 21:29:07 -0700},
	Title = {Unsupervised Deformable Image Registration with Fully Connected Generative Neural Network},
	Year = {2018}}

@inproceedings{Sergeev:2012aa,
	Author = {Sergey Sergeev and Yang Zhao and Marius George Linguraru and Kazunori Okada,},
	Booktitle = {Proceedings of the {SPIE}},
	Date-Added = {2018-11-08 13:57:02 -0800},
	Date-Modified = {2019-05-21 14:51:13 -0700},
	Title = {Medical image registration using machine learning-based interest point detector},
	Year = {2012}}

@article{Miao:2016aa,
	Abstract = {In this paper, we present a Convolutional Neural Network (CNN) regression approach to address the two major limitations of existing intensity-based 2-D/3-D registration technology: 1) slow computation and 2) small capture range. Different from optimization-based methods, which iteratively optimize the transformation parameters over a scalar-valued metric function representing the quality of the registration, the proposed method exploits the information embedded in the appearances of the digitally reconstructed radiograph and X-ray images, and employs CNN regressors to directly estimate the transformation parameters. An automatic feature extraction step is introduced to calculate 3-D pose-indexed features that are sensitive to the variables to be regressed while robust to other factors. The CNN regressors are then trained for local zones and applied in a hierarchical manner to break down the complex regression task into multiple simpler sub-tasks that can be learned separately. Weight sharing is furthermore employed in the CNN regression model to reduce the memory footprint. The proposed approach has been quantitatively evaluated on 3 potential clinical applications, demonstrating its significant advantage in providing highly accurate real-time 2-D/3-D registration with a significantly enlarged capture range when compared to intensity-based methods.},
	Author = {Shun Miao and Wang, Z Jane and Rui Liao},
	Date-Added = {2018-11-08 13:53:54 -0800},
	Date-Modified = {2019-05-21 21:32:00 -0700},
	Doi = {10.1109/TMI.2016.2521800},
	Journal = {IEEE Trans Med Imaging},
	Journal-Full = {IEEE transactions on medical imaging},
	Mesh = {Arthroplasty, Replacement, Knee; Echocardiography, Transesophageal; Humans; Imaging, Three-Dimensional; Knee Joint; Machine Learning; Neural Networks (Computer); Radiography; Regression Analysis},
	Month = {05},
	Number = {5},
	Pages = {1352-1363},
	Pmid = {26829785},
	Pst = {ppublish},
	Title = {A {CNN} Regression Approach for Real-Time {2D/3D} Registration},
	Volume = {35},
	Year = {2016},
	Bdsk-Url-1 = {https://doi.org/10.1109/TMI.2016.2521800}}

@conference{Liao:2017aa,
	Author = {Rui Liao and Shun Miao and Pierre de Tournemire and Sasa Grbic and Ali Kamen and Tommaso Mansi and Dorin Comaniciu},
	Booktitle = {Proceedings of the Thirty-First AAAI Conference on Artificial Intelligence},
	Date-Added = {2018-11-08 13:52:24 -0800},
	Date-Modified = {2018-11-08 13:53:26 -0800},
	Title = {An Artificial Agent for Robust Image Registration},
	Year = {2017}}

@inproceedings{Eppenhof:2018aa,
	Author = {Koen A. J. Eppenhof and Maxime W. Lafarge and Pim Moeskops and Mitko Veta and Josien P. W. Pluim},
	Booktitle = {Proceedings of the SPIE: Medical Imaging: Image Processing},
	Date-Added = {2018-11-08 13:49:08 -0800},
	Date-Modified = {2019-05-21 21:56:04 -0700},
	Title = {Deformable image registration using convolutional neural networks},
	Year = {2018}}

@inproceedings{Cao:2017aa,
	Abstract = {Existing deformable registration methods require exhaustively iterative optimization, along with careful parameter tuning, to estimate the deformation field between images. Although some learning-based methods have been proposed for initiating deformation estimation, they are often template-specific and not flexible in practical use. In this paper, we propose a convolutional neural network (CNN) based regression model to directly learn the complex mapping from the input image pair (i.e., a pair of template and subject) to their corresponding deformation field. Specifically, our CNN architecture is designed in a patch-based manner to learn the complex mapping from the input patch pairs to their respective deformation field. First, the equalized active-points guided sampling strategy is introduced to facilitate accurate CNN model learning upon a limited image dataset. Then, the similarity-steered CNN architecture is designed, where we propose to add the auxiliary contextual cue, i.e., the similarity between input patches, to more directly guide the learning process. Experiments on different brain image datasets demonstrate promising registration performance based on our CNN model. Furthermore, it is found that the trained CNN model from one dataset can be successfully transferred to another dataset, although brain appearances across datasets are quite variable.},
	Author = {Cao, Xiaohuan and Yang, Jianhua and Zhang, Jun and Nie, Dong and Kim, Min-Jeong and Wang, Qian and Shen, Dinggang},
	Booktitle = {Proceedings of the {I}nternational {C}onference on {M}edical {I}mage {C}omputing and {C}omputer-{A}ssisted {I}ntervention},
	Date-Added = {2018-11-08 13:47:53 -0800},
	Date-Modified = {2019-05-21 21:54:21 -0700},
	Doi = {10.1007/978-3-319-66182-7_35},
	Journal-Full = {Medical image computing and computer-assisted intervention : MICCAI ... International Conference on Medical Image Computing and Computer-Assisted Intervention},
	Mesh = {Algorithms; Brain; Humans; Machine Learning; Neural Networks (Computer); Neuroimaging; Reproducibility of Results; Sensitivity and Specificity; Young Adult},
	Month = {Sep},
	Pages = {300-308},
	Pmc = {PMC5731783},
	Pmid = {29250613},
	Pst = {ppublish},
	Title = {Deformable Image Registration based on Similarity-Steered CNN Regression},
	Volume = {10433},
	Year = {2017},
	Bdsk-Url-1 = {https://doi.org/10.1007/978-3-319-66182-7_35}}

@inproceedings{Jaderberg:2015aa,
	Author = {Max Jaderberg and Karen Simonyan and Andrew Zisserman and Koray Kavukcuoglu},
	Booktitle = {{N}eural {I}nformation {P}rocessing {S}ystems},
	Date-Added = {2018-11-08 13:45:45 -0800},
	Date-Modified = {2019-05-21 22:06:02 -0700},
	Title = {Spatial Transformer Networks},
	Year = {2015}}

@article{Hu:2018aa,
	Abstract = {One of the fundamental challenges in supervised learning for multimodal image registration is the lack of ground-truth for voxel-level spatial correspondence. This work describes a method to infer voxel-level transformation from higher-level correspondence information contained in anatomical labels. We argue that such labels are more reliable and practical to obtain for reference sets of image pairs than voxel-level correspondence. Typical anatomical labels of interest may include solid organs, vessels, ducts, structure boundaries and other subject-specific ad hoc landmarks. The proposed end-to-end convolutional neural network approach aims to predict displacement fields to align multiple labelled corresponding structures for individual image pairs during the training, while only unlabelled image pairs are used as the network input for inference. We highlight the versatility of the proposed strategy, for training, utilising diverse types of anatomical labels, which need not to be identifiable over all training image pairs. At inference, the resulting 3D deformable image registration algorithm runs in real-time and is fully-automated without requiring any anatomical labels or initialisation. Several network architecture variants are compared for registering T2-weighted magnetic resonance images and 3D transrectal ultrasound images from prostate cancer patients. A median target registration error of 3.6â€¯mm on landmark centroids and a median Dice of 0.87 on prostate glands are achieved from cross-validation experiments, in which 108 pairs of multimodal images from 76 patients were tested with high-quality anatomical labels.},
	Author = {Hu, Yipeng and Modat, Marc and Gibson, Eli and Li, Wenqi and Ghavami, Nooshin and Bonmati, Ester and Wang, Guotai and Bandula, Steven and Moore, Caroline M and Emberton, Mark and Ourselin, S{\'e}bastien and Noble, J Alison and Barratt, Dean C and Vercauteren, Tom},
	Date-Added = {2018-11-08 13:44:50 -0800},
	Date-Modified = {2018-11-08 13:44:50 -0800},
	Doi = {10.1016/j.media.2018.07.002},
	Journal = {Med Image Anal},
	Journal-Full = {Medical image analysis},
	Keywords = {Convolutional neural network; Image-guided intervention; Medical image registration; Prostate cancer; Weakly-supervised learning},
	Month = {Oct},
	Pages = {1-13},
	Pmid = {30007253},
	Pst = {ppublish},
	Title = {Weakly-supervised convolutional neural networks for multimodal image registration},
	Volume = {49},
	Year = {2018},
	Bdsk-Url-1 = {https://doi.org/10.1016/j.media.2018.07.002}}

@inproceedings{Dosovitskiy:2015aa,
	Acmid = {2919957},
	Address = {Washington, DC, USA},
	Author = {Dosovitskiy, Alexey and Fischery, Philipp and Ilg, Eddy and Hausser, Philip and Hazirbas, Caner and Golkov, Vladimir and Smagt, Patrick van der and Cremers, Daniel and Brox, Thomas},
	Booktitle = {Proceedings of the {IEEE} {C}onference on {C}omputer {V}ision and {P}attern {R}ecognition},
	Date-Added = {2018-11-08 13:44:01 -0800},
	Date-Modified = {2019-05-21 21:53:00 -0700},
	Doi = {10.1109/ICCV.2015.316},
	Isbn = {978-1-4673-8391-2},
	Numpages = {9},
	Pages = {2758--2766},
	Publisher = {IEEE Computer Society},
	Series = {ICCV '15},
	Title = {FlowNet: Learning Optical Flow with Convolutional Networks},
	Url = {http://dx.doi.org/10.1109/ICCV.2015.316},
	Year = {2015},
	Bdsk-Url-1 = {http://dx.doi.org/10.1109/ICCV.2015.316}}

@inproceedings{Dalca:2018aa,
	Abstract = {Traditional deformable registration techniques achieve impressive results and offer a rigorous theoretical treatment, but are computationally intensive since they solve an optimization problem for each image pair. Recently, learning-based methods have facilitated fast registration by learning spatial deformation functions. However, these approaches use restricted deformation models, require supervised labels, or do not guarantee a diffeomorphic (topology-preserving) registration. Furthermore, learning-based registration tools have not been derived from a probabilistic framework that can offer uncertainty estimates. In this paper, we present a probabilistic generative model and derive an unsupervised learning-based inference algorithm that makes use of recent developments in convolutional neural networks (CNNs). We demonstrate our method on a 3D brain registration task, and provide an empirical analysis of the algorithm. Our approach results in state of the art accuracy and very fast runtimes, while providing diffeomorphic guarantees and uncertainty estimates. Our implementation is available online at http://voxelmorph.csail.mit.edu.},
	Address = {Cham},
	Author = {Dalca, Adrian V. and Balakrishnan, Guha and Guttag, John and Sabuncu, Mert R.},
	Booktitle = {Proceedings of the {I}nternational {C}onference on {M}edical {I}mage {C}omputing and {C}omputer-{A}ssisted {I}ntervention},
	Date-Added = {2018-11-08 13:39:10 -0800},
	Date-Modified = {2019-05-21 21:50:45 -0700},
	Editor = {Frangi, Alejandro F. and Schnabel, Julia A. and Davatzikos, Christos and Alberola-L{\'o}pez, Carlos and Fichtinger, Gabor},
	Isbn = {978-3-030-00928-1},
	Pages = {729--738},
	Publisher = {Springer International Publishing},
	Title = {Unsupervised Learning for Fast Probabilistic Diffeomorphic Registration},
	Year = {2018},
	Bdsk-File-1 = {YnBsaXN0MDDSAQIDBFxyZWxhdGl2ZVBhdGhZYWxpYXNEYXRhXxBeLi4vLi4vLi4vLi4vLi4vRG93bmxvYWRzL2F1dG9lbmNvZGVycy1taW5pbXVtLWRlc2NyaXB0aW9uLWxlbmd0aC1hbmQtaGVsbWhvbHR6LWZyZWUtZW5lcmd5LmJpYk8RAiwAAAAAAiwAAgAADE1hY2ludG9zaCBIRAAAAAAAAAAAAAAAAAAAAAAAAABCRAAB/////x9hdXRvZW5jb2RlcnMtbWluaW0jRkZGRkZGRkYuYmliAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAD/////AAAAAAAAAAAAAAAAAAUAAgAACiBjdQAAAAAAAAAAAAAAAAAJRG93bmxvYWRzAAACAGEvOlVzZXJzOm50dXN0aXNvbjpEb3dubG9hZHM6YXV0b2VuY29kZXJzLW1pbmltdW0tZGVzY3JpcHRpb24tbGVuZ3RoLWFuZC1oZWxtaG9sdHotZnJlZS1lbmVyZ3kuYmliAAAOAIwARQBhAHUAdABvAGUAbgBjAG8AZABlAHIAcwAtAG0AaQBuAGkAbQB1AG0ALQBkAGUAcwBjAHIAaQBwAHQAaQBvAG4ALQBsAGUAbgBnAHQAaAAtAGEAbgBkAC0AaABlAGwAbQBoAG8AbAB0AHoALQBmAHIAZQBlAC0AZQBuAGUAcgBnAHkALgBiAGkAYgAPABoADABNAGEAYwBpAG4AdABvAHMAaAAgAEgARAASAF9Vc2Vycy9udHVzdGlzb24vRG93bmxvYWRzL2F1dG9lbmNvZGVycy1taW5pbXVtLWRlc2NyaXB0aW9uLWxlbmd0aC1hbmQtaGVsbWhvbHR6LWZyZWUtZW5lcmd5LmJpYgAAEwABLwAAFQACABD//wAAAAgADQAaACQAhQAAAAAAAAIBAAAAAAAAAAUAAAAAAAAAAAAAAAAAAAK1}}

@article{Bermudez:2018aa,
	Abstract = {An important task in image processing and neuroimaging is to extract quantitative information from the acquired images in order to make observations about the presence of disease or markers of development in populations. Having a low-dimensional manifold of an image allows for easier statistical comparisons between groups and the synthesis of group representatives. Previous studies have sought to identify the best mapping of brain MRI to a low-dimensional manifold, but have been limited by assumptions of explicit similarity measures. In this work, we use deep learning techniques to investigate implicit manifolds of normal brains and generate new, high-quality images. We explore implicit manifolds by addressing the problems of image synthesis and image denoising as important tools in manifold learning. First, we propose the unsupervised synthesis of T1-weighted brain MRI using a Generative Adversarial Network (GAN) by learning from 528 examples of 2D axial slices of brain MRI. Synthesized images were first shown to be unique by performing a cross-correlation with the training set. Real and synthesized images were then assessed in a blinded manner by two imaging experts providing an image quality score of 1-5. The quality score of the synthetic image showed substantial overlap with that of the real images. Moreover, we use an autoencoder with skip connections for image denoising, showing that the proposed method results in higher PSNR than FSL SUSAN after denoising. This work shows the power of artificial networks to synthesize realistic imaging data, which can be used to improve image processing techniques and provide a quantitative framework to structural changes in the brain.},
	Author = {Bermudez, Camilo and Plassard, Andrew J and Davis, Taylor L and Newton, Allen T and Resnick, Susan M and Landman, Bennett A},
	Date-Added = {2018-11-08 13:36:22 -0800},
	Date-Modified = {2018-11-08 13:36:22 -0800},
	Doi = {10.1117/12.2293515},
	Journal = {Proc SPIE Int Soc Opt Eng},
	Journal-Full = {Proceedings of SPIE--the International Society for Optical Engineering},
	Keywords = {Manifold learning; brain MRI; deep neural networks; generative adversarial networks; image synthesis},
	Month = {Mar},
	Pmc = {PMC5990281},
	Pmid = {29887659},
	Pst = {ppublish},
	Title = {Learning Implicit Brain MRI Manifolds with Deep Learning},
	Volume = {10574},
	Year = {2018},
	Bdsk-Url-1 = {https://doi.org/10.1117/12.2293515}}

@inproceedings{Balakrishnan:2018aa,
	Author = {Guha Balakrishnan and Amy Zhao and Mert R. Sabuncu and John Guttag and Adrian V. Dalca},
	Booktitle = {Proceedings of the {IEEE} {C}onference on {C}omputer {V}ision and {P}attern {R}ecognition},
	Date-Added = {2018-11-08 13:28:08 -0800},
	Date-Modified = {2019-05-21 21:52:48 -0700},
	Title = {An Unsupervised Learning Model for Deformable Medical Image Registration},
	Year = {2018}}
