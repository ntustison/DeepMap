%% This BibTeX bibliography file was created using BibDesk.
%% http://bibdesk.sourceforge.net/

%% Created for Nicholas Tustison at 2018-12-24 14:08:33 -0800 


%% Saved with string encoding Unicode (UTF-8) 



@article{Bernal:2018aa,
	Abstract = {In recent years, deep convolutional neural networks (CNNs) have shown record-shattering performance in a variety of computer vision problems, such as visual object recognition, detection and segmentation. These methods have also been utilised in medical image analysis domain for lesion segmentation, anatomical segmentation and classification. We present an extensive literature review of CNN techniques applied in brain magnetic resonance imaging (MRI) analysis, focusing on the architectures, pre-processing, data-preparation and post-processing strategies available in these works. The aim of this study is three-fold. Our primary goal is to report how different CNN architectures have evolved, discuss state-of-the-art strategies, condense their results obtained using public datasets and examine their pros and cons. Second, this paper is intended to be a detailed reference of the research activity in deep CNN for brain MRI analysis. Finally, we present a perspective on the future of CNNs in which we hint some of the research directions in subsequent years.},
	Author = {Bernal, Jose and Kushibar, Kaisar and Asfaw, Daniel S and Valverde, Sergi and Oliver, Arnau and Mart{\'\i}, Robert and Llad{\'o}, Xavier},
	Date-Added = {2018-12-24 14:03:09 -0800},
	Date-Modified = {2018-12-24 14:03:09 -0800},
	Doi = {10.1016/j.artmed.2018.08.008},
	Journal = {Artif Intell Med},
	Journal-Full = {Artificial intelligence in medicine},
	Keywords = {Brain MRI; Deep convolutional neural network; Review; Segmentation},
	Month = {Sep},
	Pmid = {30195984},
	Pst = {aheadofprint},
	Title = {Deep convolutional neural networks for brain image analysis on magnetic resonance imaging: a review},
	Year = {2018},
	Bdsk-Url-1 = {https://doi.org/10.1016/j.artmed.2018.08.008}}

@inproceedings{paszke:2017aa,
	Author = {Paszke, Adam and Gross, Sam and Chintala, Soumith and Chanan, Gregory and Yang, Edward and DeVito, Zachary and Lin, Zeming and Desmaison, Alban and Antiga, Luca and Lerer, Adam},
	Booktitle = {NIPS-W},
	Date-Added = {2018-12-24 13:59:28 -0800},
	Date-Modified = {2018-12-24 14:00:30 -0800},
	Title = {Automatic differentiation in PyTorch},
	Year = {2017}}

@article{Ashburner:2000aa,
	Abstract = {At its simplest, voxel-based morphometry (VBM) involves a voxel-wise comparison of the local concentration of gray matter between two groups of subjects. The procedure is relatively straightforward and involves spatially normalizing high-resolution images from all the subjects in the study into the same stereotactic space. This is followed by segmenting the gray matter from the spatially normalized images and smoothing the gray-matter segments. Voxel-wise parametric statistical tests which compare the smoothed gray-matter images from the two groups are performed. Corrections for multiple comparisons are made using the theory of Gaussian random fields. This paper describes the steps involved in VBM, with particular emphasis on segmenting gray matter from MR images with nonuniformity artifact. We provide evaluations of the assumptions that underpin the method, including the accuracy of the segmentation and the assumptions made about the statistical distribution of the data.},
	Author = {Ashburner, J and Friston, K J},
	Date-Added = {2018-12-24 13:48:09 -0800},
	Date-Modified = {2018-12-24 13:48:09 -0800},
	Doi = {10.1006/nimg.2000.0582},
	Journal = {Neuroimage},
	Journal-Full = {NeuroImage},
	Mesh = {Brain; False Positive Reactions; Humans; Magnetic Resonance Imaging; Models, Neurological; Periaqueductal Gray; Random Allocation},
	Month = {Jun},
	Number = {6 Pt 1},
	Pages = {805-21},
	Pmid = {10860804},
	Pst = {ppublish},
	Title = {Voxel-based morphometry--the methods},
	Volume = {11},
	Year = {2000},
	Bdsk-Url-1 = {https://doi.org/10.1006/nimg.2000.0582}}

@article{Anwar:2018aa,
	Abstract = {The science of solving clinical problems by analyzing images generated in clinical practice is known as medical image analysis. The aim is to extract information in an affective and efficient manner for improved clinical diagnosis. The recent advances in the field of biomedical engineering have made medical image analysis one of the top research and development area. One of the reasons for this advancement is the application of machine learning techniques for the analysis of medical images. Deep learning is successfully used as a tool for machine learning, where a neural network is capable of automatically learning features. This is in contrast to those methods where traditionally hand crafted features are used. The selection and calculation of these features is a challenging task. Among deep learning techniques, deep convolutional networks are actively used for the purpose of medical image analysis. This includes application areas such as segmentation, abnormality detection, disease classification, computer aided diagnosis and retrieval. In this study, a comprehensive review of the current state-of-the-art in medical image analysis using deep convolutional networks is presented. The challenges and potential of these techniques are also highlighted.},
	Author = {Anwar, Syed Muhammad and Majid, Muhammad and Qayyum, Adnan and Awais, Muhammad and Alnowami, Majdi and Khan, Muhammad Khurram},
	Date-Added = {2018-12-23 18:40:53 -0800},
	Date-Modified = {2018-12-23 18:40:53 -0800},
	Doi = {10.1007/s10916-018-1088-1},
	Journal = {J Med Syst},
	Journal-Full = {Journal of medical systems},
	Keywords = {Classification; Computer aided diagnosis; Convolutional neural network; Medical image analysis; Segmentation},
	Month = {Oct},
	Number = {11},
	Pages = {226},
	Pmid = {30298337},
	Pst = {epublish},
	Title = {Medical Image Analysis using Convolutional Neural Networks: A Review},
	Volume = {42},
	Year = {2018},
	Bdsk-Url-1 = {https://doi.org/10.1007/s10916-018-1088-1}}

@article{Sahiner:2018aa,
	Abstract = {The goals of this review paper on deep learning (DL) in medical imaging and radiation therapy are to (a) summarize what has been achieved to date; (b) identify common and unique challenges, and strategies that researchers have taken to address these challenges; and (c) identify some of the promising avenues for the future both in terms of applications as well as technical innovations. We introduce the general principles of DL and convolutional neural networks, survey five major areas of application of DL in medical imaging and radiation therapy, identify common themes, discuss methods for dataset expansion, and conclude by summarizing lessons learned, remaining challenges, and future directions.},
	Author = {Sahiner, Berkman and Pezeshk, Aria and Hadjiiski, Lubomir M and Wang, Xiaosong and Drukker, Karen and Cha, Kenny H and Summers, Ronald M and Giger, Maryellen L},
	Date-Added = {2018-12-23 18:35:29 -0800},
	Date-Modified = {2018-12-23 18:35:29 -0800},
	Doi = {10.1002/mp.13264},
	Journal = {Med Phys},
	Journal-Full = {Medical physics},
	Keywords = {computer-aided detection/characterization; deep learning, machine learning; reconstruction; segmentation; treatment},
	Month = {Oct},
	Pmid = {30367497},
	Pst = {aheadofprint},
	Title = {Deep learning in medical imaging and radiation therapy},
	Year = {2018},
	Bdsk-Url-1 = {https://doi.org/10.1002/mp.13264}}

@article{Falk:2019aa,
	Abstract = {U-Net is a generic deep-learning solution for frequently occurring quantification tasks such as cell detection and shape measurements in biomedical image data. We present an ImageJ plugin that enables non-machine-learning experts to analyze their data with U-Net on either a local computer or a remote server/cloud service. The plugin comes with pretrained models for single-cell segmentation and allows for U-Net to be adapted to new tasks on the basis of a few annotated samples.},
	Author = {Falk, Thorsten and Mai, Dominic and Bensch, Robert and {\c C}i{\c c}ek, {\"O}zg{\"u}n and Abdulkadir, Ahmed and Marrakchi, Yassine and B{\"o}hm, Anton and Deubner, Jan and J{\"a}ckel, Zoe and Seiwald, Katharina and Dovzhenko, Alexander and Tietz, Olaf and Dal Bosco, Cristina and Walsh, Sean and Saltukoglu, Deniz and Tay, Tuan Leng and Prinz, Marco and Palme, Klaus and Simons, Matias and Diester, Ilka and Brox, Thomas and Ronneberger, Olaf},
	Date-Added = {2018-12-23 18:31:19 -0800},
	Date-Modified = {2018-12-23 18:31:19 -0800},
	Doi = {10.1038/s41592-018-0261-2},
	Journal = {Nat Methods},
	Journal-Full = {Nature methods},
	Month = {Jan},
	Number = {1},
	Pages = {67-70},
	Pmid = {30559429},
	Pst = {ppublish},
	Title = {U-Net: deep learning for cell counting, detection, and morphometry},
	Volume = {16},
	Year = {2019},
	Bdsk-Url-1 = {https://doi.org/10.1038/s41592-018-0261-2}}

@misc{tensorflow,
	Author = {Mart\'{\i}n~Abadi and Ashish~Agarwal and Paul~Barham and Eugene~Brevdo and Zhifeng~Chen and Craig~Citro and Greg~S.~Corrado and Andy~Davis and Jeffrey~Dean and Matthieu~Devin and Sanjay~Ghemawat and Ian~Goodfellow and Andrew~Harp and Geoffrey~Irving and Michael~Isard and Yangqing Jia and Rafal~Jozefowicz and Lukasz~Kaiser and Manjunath~Kudlur and Josh~Levenberg and Dan~Man\'{e} and Rajat~Monga and Sherry~Moore and Derek~Murray and Chris~Olah and Mike~Schuster and Jonathon~Shlens and Benoit~Steiner and Ilya~Sutskever and Kunal~Talwar and Paul~Tucker and Vincent~Vanhoucke and Vijay~Vasudevan and Fernanda~Vi\'{e}gas and Oriol~Vinyals and Pete~Warden and Martin~Wattenberg and Martin~Wicke and Yuan~Yu and Xiaoqiang~Zheng},
	Date-Added = {2018-12-23 17:28:11 -0800},
	Date-Modified = {2018-12-23 17:29:39 -0800},
	Title = {{TensorFlow}: Large-Scale Machine Learning on Heterogeneous Systems},
	Year = {2015}}

@misc{keras,
	Author = {Chollet, Fran\c{c}ois and others},
	Date-Added = {2018-12-23 17:23:08 -0800},
	Date-Modified = {2018-12-23 17:25:48 -0800},
	Howpublished = {{\url{https://github.com/fchollet/keras}}},
	Title = {Keras}}

@article{Modat:2010aa,
	Abstract = {A large number of algorithms have been developed to perform non-rigid registration and it is a tool commonly used in medical image analysis. The free-form deformation algorithm is a well-established technique, but is extremely time consuming. In this paper we present a parallel-friendly formulation of the algorithm suitable for graphics processing unit execution. Using our approach we perform registration of T1-weighted MR images in less than 1 min and show the same level of accuracy as a classical serial implementation when performing segmentation propagation. This technology could be of significant utility in time-critical applications such as image-guided interventions, or in the processing of large data sets.},
	Author = {Modat, Marc and Ridgway, Gerard R and Taylor, Zeike A and Lehmann, Manja and Barnes, Josephine and Hawkes, David J and Fox, Nick C and Ourselin, S{\'e}bastien},
	Date-Added = {2018-12-23 15:37:33 -0800},
	Date-Modified = {2018-12-23 15:37:33 -0800},
	Doi = {10.1016/j.cmpb.2009.09.002},
	Journal = {Comput Methods Programs Biomed},
	Journal-Full = {Computer methods and programs in biomedicine},
	Mesh = {Algorithms; Computer Graphics; Diagnostic Imaging; Image Processing, Computer-Assisted; Software},
	Month = {Jun},
	Number = {3},
	Pages = {278-84},
	Pmid = {19818524},
	Pst = {ppublish},
	Title = {Fast free-form deformation using graphics processing units},
	Volume = {98},
	Year = {2010},
	Bdsk-Url-1 = {https://doi.org/10.1016/j.cmpb.2009.09.002}}

@article{Yi:2018aa,
	Author = {Xin Yi and Ekta Walia and Paul Babyn},
	Date-Added = {2018-12-23 15:20:11 -0800},
	Date-Modified = {2018-12-23 15:21:03 -0800},
	Journal = {arXiv preprint},
	Title = {Generative Adversarial Network in Medical Imaging: A Review},
	Year = {2018}}

@proceedings{brats2018,
	Date-Added = {2018-12-23 14:30:38 -0800},
	Date-Modified = {2018-12-23 14:30:59 -0800},
	Title = {Pre-Conference Proceedings of the 7th {MICCAI} {BraTS} Challenge},
	Year = {2018}}

@proceedings{brats2014,
	Date-Added = {2018-12-23 14:27:45 -0800},
	Date-Modified = {2018-12-23 14:31:12 -0800},
	Title = {Conference Proceedings of the 3rd {MICCAI} {BraTS} Challenge},
	Year = {2014}}

@article{Menze:2015aa,
	Abstract = {In this paper we report the set-up and results of the Multimodal Brain Tumor Image Segmentation Benchmark (BRATS) organized in conjunction with the MICCAI 2012 and 2013 conferences. Twenty state-of-the-art tumor segmentation algorithms were applied to a set of 65 multi-contrast MR scans of low- and high-grade glioma patients-manually annotated by up to four raters-and to 65 comparable scans generated using tumor image simulation software. Quantitative evaluations revealed considerable disagreement between the human raters in segmenting various tumor sub-regions (Dice scores in the range 74%-85%), illustrating the difficulty of this task. We found that different algorithms worked best for different sub-regions (reaching performance comparable to human inter-rater variability), but that no single algorithm ranked in the top for all sub-regions simultaneously. Fusing several good algorithms using a hierarchical majority vote yielded segmentations that consistently ranked above all individual algorithms, indicating remaining opportunities for further methodological improvements. The BRATS image data and manual annotations continue to be publicly available through an online evaluation system as an ongoing benchmarking resource. },
	Author = {Menze, Bjoern H and Jakab, Andras and Bauer, Stefan and Kalpathy-Cramer, Jayashree and Farahani, Keyvan and Kirby, Justin and Burren, Yuliya and Porz, Nicole and Slotboom, Johannes and Wiest, Roland and Lanczi, Levente and Gerstner, Elizabeth and Weber, Marc-Andr{\'e} and Arbel, Tal and Avants, Brian B and Ayache, Nicholas and Buendia, Patricia and Collins, D Louis and Cordier, Nicolas and Corso, Jason J and Criminisi, Antonio and Das, Tilak and Delingette, Herv{\'e} and Demiralp, {\c C}a{\u g}atay and Durst, Christopher R and Dojat, Michel and Doyle, Senan and Festa, Joana and Forbes, Florence and Geremia, Ezequiel and Glocker, Ben and Golland, Polina and Guo, Xiaotao and Hamamci, Andac and Iftekharuddin, Khan M and Jena, Raj and John, Nigel M and Konukoglu, Ender and Lashkari, Danial and Mariz, Jos{\'e} Antoni{\'o} and Meier, Raphael and Pereira, S{\'e}rgio and Precup, Doina and Price, Stephen J and Raviv, Tammy Riklin and Reza, Syed M S and Ryan, Michael and Sarikaya, Duygu and Schwartz, Lawrence and Shin, Hoo-Chang and Shotton, Jamie and Silva, Carlos A and Sousa, Nuno and Subbanna, Nagesh K and Szekely, Gabor and Taylor, Thomas J and Thomas, Owen M and Tustison, Nicholas J and Unal, Gozde and Vasseur, Flor and Wintermark, Max and Ye, Dong Hye and Zhao, Liang and Zhao, Binsheng and Zikic, Darko and Prastawa, Marcel and Reyes, Mauricio and Van Leemput, Koen},
	Date-Added = {2018-12-23 14:24:45 -0800},
	Date-Modified = {2018-12-23 14:24:45 -0800},
	Doi = {10.1109/TMI.2014.2377694},
	Journal = {IEEE Trans Med Imaging},
	Journal-Full = {IEEE transactions on medical imaging},
	Mesh = {Algorithms; Benchmarking; Glioma; Humans; Magnetic Resonance Imaging; Neuroimaging},
	Month = {Oct},
	Number = {10},
	Pages = {1993-2024},
	Pmc = {PMC4833122},
	Pmid = {25494501},
	Pst = {ppublish},
	Title = {The Multimodal Brain Tumor Image Segmentation Benchmark (BRATS)},
	Volume = {34},
	Year = {2015},
	Bdsk-Url-1 = {https://doi.org/10.1109/TMI.2014.2377694}}

@article{Chan:1995aa,
	Abstract = {We are developing a computer program for automated detection of clustered microcalcifications on mammograms. In this study, we investigated the effectiveness of a signal classifier based on a convolution neural network (CNN) approach for improvement of the accuracy of the detection program. Fifty-two mammograms with clustered microcalcifications were selected from patient files. The clusters on the mammograms were ranked by experienced mammographers and divided into an obvious group, an average group, and a subtle group. The average and subtle groups were combined and randomly divided into two sets, each of which was used as training or test set alternately. The obvious group served as an additional independent test set. Regions of interest (ROIs) containing potential individual microcalcifications were first located on each mammogram by the automated detection program. The ROIs from one set of the mammograms were used to train CNNs of different configurations with a back-propagation method. The generalization capability of the trained CNNs was then examined by their accuracy of classifying the ROIs from the other set and from the obvious group. The classification accuracy of the CNNs for the ROIs was evaluated by receiver operating characteristic (ROC) analysis. It was found that CNNs of many different configurations can reach approximately the same performance level, with the area under the ROC curve (Az) of 0.9. We incorporated a trained CNN into the detection program and evaluated the improvement of the detection accuracy by the CNN using free response ROC analysis. Our results indicated that, over a wide range of true-positive (TP) cluster detection rate, the CNN classifier could reduce the number of false-positive (FP) clusters per image by more than 70%. For the obvious cases, at a TP rate of 100%, the FP rate reduced from 0.35 cluster per image to 0.1 cluster per image. For the average and subtle cases, the detection accuracy improved from a TP rate of 87% at an FP rate of four clusters per image to a TP rate of 90% at an FP rate of 1.5 clusters per image.},
	Author = {Chan, H P and Lo, S C and Sahiner, B and Lam, K L and Helvie, M A},
	Date-Added = {2018-12-22 19:10:17 -0800},
	Date-Modified = {2018-12-22 19:10:17 -0800},
	Doi = {10.1118/1.597428},
	Journal = {Med Phys},
	Journal-Full = {Medical physics},
	Mesh = {Automation; Breast Diseases; Breast Neoplasms; Calcinosis; False Positive Reactions; Female; Humans; Mammography; Mathematics; Neural Networks (Computer); Patient Selection; Radiographic Image Interpretation, Computer-Assisted; Reproducibility of Results; Risk Factors},
	Month = {Oct},
	Number = {10},
	Pages = {1555-67},
	Pmid = {8551980},
	Pst = {ppublish},
	Title = {Computer-aided detection of mammographic microcalcifications: pattern recognition with an artificial neural network},
	Volume = {22},
	Year = {1995},
	Bdsk-Url-1 = {https://doi.org/10.1118/1.597428}}

@article{Tan:2014aa,
	Abstract = {PURPOSE: Selecting optimal features from a large image feature pool remains a major challenge in developing computer-aided detection (CAD) schemes of medical images. The objective of this study is to investigate a new approach to significantly improve efficacy of image feature selection and classifier optimization in developing a CAD scheme of mammographic masses.
METHODS: An image dataset including 1600 regions of interest (ROIs) in which 800 are positive (depicting malignant masses) and 800 are negative (depicting CAD-generated false positive regions) was used in this study. After segmentation of each suspicious lesion by a multilayer topographic region growth algorithm, 271 features were computed in different feature categories including shape, texture, contrast, isodensity, spiculation, local topological features, as well as the features related to the presence and location of fat and calcifications. Besides computing features from the original images, the authors also computed new texture features from the dilated lesion segments. In order to select optimal features from this initial feature pool and build a highly performing classifier, the authors examined and compared four feature selection methods to optimize an artificial neural network (ANN) based classifier, namely: (1) Phased Searching with NEAT in a Time-Scaled Framework, (2) A sequential floating forward selection (SFFS) method, (3) A genetic algorithm (GA), and (4) A sequential forward selection (SFS) method. Performances of the four approaches were assessed using a tenfold cross validation method.
RESULTS: Among these four methods, SFFS has highest efficacy, which takes 3%-5% of computational time as compared to GA approach, and yields the highest performance level with the area under a receiver operating characteristic curve (AUC) = 0.864 $\pm$ 0.034. The results also demonstrated that except using GA, including the new texture features computed from the dilated mass segments improved the AUC results of the ANNs optimized using other three feature selection methods. In addition, among 271 features, the shape, local morphological features, fat and calcification based features were the most frequently selected features to build ANNs.
CONCLUSIONS: Although conventional GA is a powerful tool in optimizing classifiers used in CAD schemes of medical images, it is very computationally intensive. This study demonstrated that using a new SFFS based approach enabled to significantly improve efficacy of image feature selection for developing CAD schemes.},
	Author = {Tan, Maxine and Pu, Jiantao and Zheng, Bin},
	Date-Added = {2018-12-22 19:09:34 -0800},
	Date-Modified = {2018-12-22 19:09:34 -0800},
	Doi = {10.1118/1.4890080},
	Journal = {Med Phys},
	Journal-Full = {Medical physics},
	Mesh = {Algorithms; Area Under Curve; Breast Neoplasms; Datasets as Topic; Humans; Mammography; Neural Networks (Computer); Pattern Recognition, Automated; ROC Curve; Radiographic Image Interpretation, Computer-Assisted; Time Factors},
	Month = {Aug},
	Number = {8},
	Pages = {081906},
	Pmc = {PMC4105957},
	Pmid = {25086537},
	Pst = {ppublish},
	Title = {A new and fast image feature selection method for developing an optimal mammographic mass detection scheme},
	Volume = {41},
	Year = {2014},
	Bdsk-Url-1 = {https://doi.org/10.1118/1.4890080}}

@inproceedings{Lo:1992aa,
	Author = {Lo, S C and Freedman, M T and Lin, J S and Mun, S K},
	Booktitle = {Proc. SPIE: Medical Imaging: Image Processing},
	Date-Added = {2018-12-22 19:05:14 -0800},
	Date-Modified = {2018-12-22 19:08:09 -0800},
	Pages = {859--869},
	Title = {Computer-aided detection of mammographic calcifications: Pattern recognition with an artificial neural network},
	Volume = {1898},
	Year = {1992}}

@article{Lo:1993aa,
	Abstract = {The potential advantages of using digital techniques instead of film-based radiography have been discussed extensively for the past 10 years. A major future application of digital techniques is computer-assisted diagnosis: the use of computer techniques to assist the radiologist in the diagnostic process. One aspect of this assistance is computer-assisted detection. The detection of small lung nodule has been recognized as a clinically difficult task for many years. Most of the literature has indicated that the rate for finding lung nodules (size range from 3 mm to 15 mm) is only approximately 65%, in those cases in which the undetected nodules could be found retrospectively. In recent published research, image processing techniques, such as thresholding and morphological analysis, have been used to enhance true-positive detection. However, these methods still produce many false-positive detections. We have been investigating the use of neural networks to distinguish true-positives nodule detections among those areas of interest that are generated from a signal enhanced image. The initial results show that the trained neural networks program can increase true-positive detections and moderately reduce the number of false-positive detections. The program reported here can perform three modes of lung nodule detection: thresholding, profile matching analysis, and neural network. This program is fully automatic and has been implemented in a DEC 5000/200 (Digital Equipment Corp, Maynard, MA) workstation. The total processing time for all three methods is less than 35 seconds. In this report, key image processing techniques and neural network for the lung nodule detection are described and the results of this initial study are reported.},
	Author = {Lo, S C and Freedman, M T and Lin, J S and Mun, S K},
	Date-Added = {2018-12-22 18:55:03 -0800},
	Date-Modified = {2018-12-22 18:55:03 -0800},
	Journal = {J Digit Imaging},
	Journal-Full = {Journal of digital imaging},
	Mesh = {Algorithms; Diagnosis, Computer-Assisted; Humans; Image Processing, Computer-Assisted; Lung Neoplasms; Neural Networks (Computer); Predictive Value of Tests; Radiographic Image Enhancement; Solitary Pulmonary Nodule},
	Month = {Feb},
	Number = {1},
	Pages = {48-54},
	Pmid = {8439583},
	Pst = {ppublish},
	Title = {Automatic lung nodule detection using profile matching and back-propagation neural network techniques},
	Volume = {6},
	Year = {1993}}

@article{Sahiner:1996aa,
	Abstract = {The authors investigated the classification of regions of interest (ROI's) on mammograms as either mass or normal tissue using a convolution neural network (CNN). A CNN is a backpropagation neural network with two-dimensional (2-D) weight kernels that operate on images. A generalized, fast and stable implementation of the CNN was developed. The input images to the CNN were obtained from the ROI's using two techniques. The first technique employed averaging and subsampling. The second technique employed texture feature extraction methods applied to small subregions inside the ROI. Features computed over different subregions were arranged as texture images, which were subsequently used as CNN inputs. The effects of CNN architecture and texture feature parameters on classification accuracy were studied. Receiver operating characteristic (ROC) methodology was used to evaluate the classification accuracy. A data set consisting of 168 ROIs containing biopsy-proven masses and 504 ROI's containing normal breast tissue was extracted from 168 mammograms by radiologists experienced in mammography. This data set was used for training and testing the CNN. With the best combination of CNN architecture and texture feature parameters, the area under the test ROC curve reached 0.87, which corresponded to a true-positive fraction of 90% at a false positive fraction of 31%. The authors' results demonstrate the feasibility of using a CNN for classification of masses and normal tissue on mammograms.},
	Author = {Sahiner, B and Chan, H P and Petrick, N and Wei, D and Helvie, M A and Adler, D D and Goodsitt, M M},
	Date-Added = {2018-12-22 18:54:38 -0800},
	Date-Modified = {2018-12-22 18:54:38 -0800},
	Doi = {10.1109/42.538937},
	Journal = {IEEE Trans Med Imaging},
	Journal-Full = {IEEE transactions on medical imaging},
	Number = {5},
	Pages = {598-610},
	Pmid = {18215941},
	Pst = {ppublish},
	Title = {Classification of mass and normal breast tissue: a convolution neural network classifier with spatial domain and texture images},
	Volume = {15},
	Year = {1996},
	Bdsk-Url-1 = {https://doi.org/10.1109/42.538937}}

@article{Mazurowski:2018aa,
	Author = {Maciej A. Mazurowski and Mateusz Buda and Ashirbani Saha and and Mustafa R. Bashir},
	Date-Added = {2018-12-22 18:44:09 -0800},
	Date-Modified = {2018-12-22 18:45:24 -0800},
	Journal = {Journal of Magnetic Resonance Imaging},
	Title = {Deep Learning in Radiology: An Overview of the Concepts and a Survey of the State of the Art With Focus on MRI},
	Year = {2018}}

@article{Hochreiter:1997aa,
	Abstract = {Learning to store information over extended time intervals by recurrent backpropagation takes a very long time, mostly because of insufficient, decaying error backflow. We briefly review Hochreiter's (1991) analysis of this problem, then address it by introducing a novel, efficient, gradient-based method called long short-term memory (LSTM). Truncating the gradient where this does not do harm, LSTM can learn to bridge minimal time lags in excess of 1000 discrete-time steps by enforcing constant error flow through constant error carousels within special units. Multiplicative gate units learn to open and close access to the constant error flow. LSTM is local in space and time; its computational complexity per time step and weight is O(1). Our experiments with artificial data involve local, distributed, real-valued, and noisy pattern representations. In comparisons with real-time recurrent learning, back propagation through time, recurrent cascade correlation, Elman nets, and neural sequence chunking, LSTM leads to many more successful runs, and learns much faster. LSTM also solves complex, artificial long-time-lag tasks that have never been solved by previous recurrent network algorithms.},
	Author = {Hochreiter, S and Schmidhuber, J},
	Date-Added = {2018-12-22 18:35:11 -0800},
	Date-Modified = {2018-12-22 18:35:11 -0800},
	Journal = {Neural Comput},
	Journal-Full = {Neural computation},
	Mesh = {Algorithms; Learning; Memory; Memory, Short-Term; Models, Neurological; Models, Psychological; Nerve Net; Neural Networks (Computer); Time Factors},
	Month = {Nov},
	Number = {8},
	Pages = {1735-80},
	Pmid = {9377276},
	Pst = {ppublish},
	Title = {Long short-term memory},
	Volume = {9},
	Year = {1997}}

@inproceedings{He:2015ab,
	Author = {Kaiming He and Xiangyu Zhang and Shaoqing Ren and Jian Sun},
	Booktitle = {Proceedings of the {IEEE} {C}onference on {C}omputer {V}ision and {P}attern {R}ecognition},
	Date-Added = {2018-12-22 14:05:38 -0800},
	Date-Modified = {2018-12-23 20:12:34 -0800},
	Title = {Delving deep into rectifiers: Surpassing human-level performance on imagenet classification},
	Year = {2015}}

@article{Lv:2018aa,
	Abstract = {OBJECTIVE: Free-breathing abdomen imaging requires non-rigid motion registration of unavoidable respiratory motion in three-dimensional undersampled data sets. In this work, we introduce an image registration method based on the convolutional neural network (CNN) to obtain motion-free abdominal images throughout the respiratory cycle.
METHODS: Abdominal data were acquired from 10 volunteers using a 1.5 T MRI system. The respiratory signal was extracted from the central-space spokes, and the acquired data were reordered in three bins according to the corresponding breathing signal. Retrospective image reconstruction of the three near-motion free respiratory phases was performed using non-Cartesian iterative SENSE reconstruction. Then, we trained a CNN to analyse the spatial transform among the different bins. This network could generate the displacement vector field and be applied to perform registration on unseen image pairs. To demonstrate the feasibility of this registration method, we compared the performance of three different registration approaches for accurate image fusion of three bins: non-motion corrected (NMC), local affine registration method (LREG) and CNN.
RESULTS: Visualization of coronal images indicated that LREG had caused broken blood vessels, while the vessels of the CNN were sharper and more consecutive. As shown in the sagittal view, compared to NMC and CNN, distorted and blurred liver contours were caused by LREG. At the same time, zoom-in axial images presented that the vessels were delineated more clearly by CNN than LREG. The statistical results of the signal-to-noise ratio, visual score, vessel sharpness and registration time over all volunteers were compared among the NMC, LREG and CNN approaches. The SNR indicated that the CNN acquired the best image quality (207.42 {\^A}$\pm$ 96.73), which was better than NMC (116.67 {\^A}$\pm$ 44.70) and LREG (187.93 {\^A}$\pm$ 96.68). The image visual score agreed with SNR, marking CNN (3.85 {\^A}$\pm$ 0.12) as the best, followed by LREG (3.43 {\^A}$\pm$ 0.13) and NMC (2.55 {\^A}$\pm$ 0.09). A vessel sharpness assessment yielded similar values between the CNN (0.81 {\^A}$\pm$ 0.03) and LREG (0.80 {\^A}$\pm$ 0.04), differentiating them from the NMC (0.78 {\^A}$\pm$ 0.06). When compared with the LREG-based reconstruction, the CNN-based reconstruction reduces the registration time from 1 h to 1 min.
CONCLUSION: Our preliminary results demonstrate the feasibility of the CNN-based approach, and this scheme outperforms the NMC- and LREG-based methods. Advances in knowledge: This method reduces the registration time from ~1 h to ~1 min, which has promising prospects for clinical use. To the best of our knowledge, this study shows the first convolutional neural network-based registration method to be applied in abdominal images.},
	Author = {Lv, Jun and Yang, Ming and Zhang, Jue and Wang, Xiaoying},
	Date-Added = {2018-12-22 09:15:13 -0800},
	Date-Modified = {2018-12-22 09:15:13 -0800},
	Doi = {10.1259/bjr.20170788},
	Journal = {Br J Radiol},
	Journal-Full = {The British journal of radiology},
	Mesh = {Abdomen; Adult; Feasibility Studies; Female; Healthy Volunteers; Humans; Image Enhancement; Image Interpretation, Computer-Assisted; Imaging, Three-Dimensional; Magnetic Resonance Imaging; Male; Motion; Neural Networks (Computer); Respiratory-Gated Imaging Techniques; Signal-To-Noise Ratio},
	Month = {Feb},
	Number = {1083},
	Pages = {20170788},
	Pmc = {PMC5965487},
	Pmid = {29261334},
	Pst = {ppublish},
	Title = {Respiratory motion correction for free-breathing 3D abdominal MRI using CNN-based image registration: a feasibility study},
	Volume = {91},
	Year = {2018},
	Bdsk-Url-1 = {https://doi.org/10.1259/bjr.20170788}}

@inproceedings{Chopra:2005aa,
	Author = {Sumit Chopra and Raia Hadsell and Yann LeCun},
	Booktitle = {Proceedings of the International Conference of Computer Vision},
	Date-Added = {2018-12-20 11:40:08 -0800},
	Date-Modified = {2018-12-20 11:41:06 -0800},
	Title = {Learning a Similarity Metric Discriminatively, with Application to Face Verification},
	Year = {2005}}

@inproceedings{Simonovsky:2016aa,
	Author = {Martin Simonovsky and Benjamın Gutierrez-Becker and Diana Mateus and Nassir Navab and Nikos Komodakis},
	Booktitle = {Proceedings of the International Conference on Medical Image Computing and Computer-Assisted Intervention},
	Date-Added = {2018-12-17 10:29:09 -0800},
	Date-Modified = {2018-12-17 10:30:22 -0800},
	Title = {A Deep Metric for Multimodal Registration},
	Year = {2016}}

@inproceedings{Mahapatra:2018aa,
	Author = {Dwarikanath Mahapatra and Bhavna Antony and Suman Sedai and Rahil Garnavi},
	Booktitle = {Proceedings of IEEE 15th International Symposium on Biomedical Imaging},
	Date-Added = {2018-12-16 19:56:17 -0800},
	Date-Modified = {2018-12-16 19:58:19 -0800},
	Title = {Deformable medical image registration using generative adversarial networks},
	Year = {2018}}

@article{Shan:2018aa,
	Author = {Siyuan Shan and Wen Yan and Xiaoqing Guo and Eric I-Chao Chang and Yubo Fan and Yan Xu},
	Date-Added = {2018-12-16 15:10:19 -0800},
	Date-Modified = {2018-12-16 15:11:41 -0800},
	Journal = {arxiv},
	Title = {Unsupervised End-to-end Learning for Deformable Medical Image Registration},
	Year = {2018}}

@article{Nazib:2018aa,
	Author = {Abdullah Nazib and Clinton Fookes and Dimitri Perrin},
	Date-Added = {2018-12-16 13:47:38 -0800},
	Date-Modified = {2018-12-16 13:48:22 -0800},
	Journal = {arXiv preprint},
	Title = {A Comparative Analysis of Registration Tools: Traditional vs Deep Learning Approach on High Resolution Tissue Cleared Data},
	Year = {2018}}

@inproceedings{Hu:2018ab,
	Author = {Yipeng Hu and Marc Modat and Eli Gibson and Nooshin Ghavami and Ester Bonmati and Caroline M. Moore and Mark Emberton and J. Alison Noble and Dean C. Barratt and Tom Vercauteren},
	Booktitle = {Proceedings of IEEE 15th International Symposium on Biomedical Imaging},
	Date-Added = {2018-12-16 13:22:06 -0800},
	Date-Modified = {2018-12-16 13:25:44 -0800},
	Title = {Label-driven weakly-supervised learning for multimodal deformable image registration},
	Year = {2018}}

@article{DeTone:2016aa,
	Author = {Daniel DeTone and Tomasz Malisiewicz and Andrew Rabinovich},
	Date-Added = {2018-12-14 16:36:50 -0800},
	Date-Modified = {2018-12-14 16:38:56 -0800},
	Journal = {arXiv:1606.03798},
	Title = {Deep Image Homography Estimation},
	Year = {2016}}

@inproceedings{Nowruzi:2017aa,
	Author = {Farzan Erlik Nowruzi and Robert Laganiere and Nathalie Japkowicz},
	Booktitle = {Proceedings of the International Conference of Computer Vision},
	Date-Added = {2018-12-14 16:35:09 -0800},
	Date-Modified = {2018-12-14 16:36:45 -0800},
	Title = {Homography Estimation from Image Pairs with Hierarchical Convolutional Networks},
	Year = {2017}}

@inproceedings{Nguyen:2018aa,
	Author = {Nguyen, Ty and Chen, Steven W and Shivakumar, Shreyas S and Taylor, Camillo J and Kumar, Vijay},
	Booktitle = {Proceedings of IEEE Robotics and Automation Letters},
	Date-Added = {2018-12-14 16:29:02 -0800},
	Date-Modified = {2018-12-14 16:31:56 -0800},
	Title = {Unsupervised Deep Homography: A Fast and Robust Homography Estimation Model},
	Year = {2018}}

@article{Ghosal:2017aa,
	Author = {Sayan Ghosal and Nilanjan Ray},
	Date-Added = {2018-12-14 16:09:18 -0800},
	Date-Modified = {2018-12-14 16:12:57 -0800},
	Journal = {Pattern Recognition Letters},
	Month = {July},
	Number = {15},
	Pages = {81--86},
	Title = {Deep Deformable Registration: Enhancing Accuracy by Fully Convolutional Neural Net},
	Volume = {94},
	Year = {2017}}

@inproceedings{Fan:2018aa,
	Author = {Jingfan Fan and Xiaohuan Cao and Zhong Xue and Pew-Thian Yap and Dinggang Shen},
	Booktitle = {Med Image Comput Comput Assist Interv},
	Date-Added = {2018-12-14 16:06:00 -0800},
	Date-Modified = {2018-12-14 16:08:06 -0800},
	Title = {Adversarial Similarity Network for Evaluating Image Alignment in Deep Learning Based Registration},
	Year = {2018}}

@article{Dupuis:1998,
	Author = {P. Dupuis and U. Grenander and M. I. Miller},
	Date-Added = {2018-12-12 21:02:49 -0800},
	Date-Modified = {2018-12-12 21:04:03 -0800},
	Journal = {Quarterly of Applied Mathematics},
	Pages = {587--600},
	Title = {Variational problems on flows of diffeomorphisms for image matching},
	Volume = {LVI},
	Year = {1998}}

@article{Trouve:1995aa,
	Author = {A. Trouv\'{e}},
	Date-Added = {2018-12-12 20:43:25 -0800},
	Date-Modified = {2018-12-12 20:44:37 -0800},
	Journal = {Int. J. Computer Vision},
	Pages = {213--221},
	Title = {Diffeomorphic groups and pattern matching in image analysis},
	Volume = {28},
	Year = {1995}}

@inproceedings{Lin:2017aa,
	Author = {Chen-Hsuan Lin and Simon Lucey},
	Booktitle = {Proceedings of the {IEEE} {C}onference on {C}omputer {V}ision and {P}attern {R}ecognition},
	Date-Added = {2018-12-12 20:10:17 -0800},
	Date-Modified = {2018-12-23 20:13:58 -0800},
	Title = {Inverse Compositional Spatial Transformer Networks},
	Year = {2017}}

@article{Freifeld:2017aa,
	Abstract = {We propose novel finite-dimensional spaces of well-behaved transformations. The latter are obtained by (fast and highly-accurate) integration of continuous piecewise-affine velocity fields. The proposed method is simple yet highly expressive, effortlessly handles optional constraints (e.g., volume preservation and/or boundary conditions), and supports convenient modeling choices such as smoothing priors and coarse-to-fine analysis. Importantly, the proposed approach, partly due to its rapid likelihood evaluations and partly due to its other properties, facilitates tractable inference over rich transformation spaces, including using Markov-Chain Monte-Carlo methods. Its applications include, but are not limited to: monotonic regression (more generally, optimization over monotonic functions); modeling cumulative distribution functions or histograms; time-warping; image warping; image registration; real-time diffeomorphic image editing; data augmentation for image classifiers. Our GPU-based code is publicly available.},
	Author = {Freifeld, Oren and Hauberg, Soren and Batmanghelich, Kayhan and Fisher, Jonn W},
	Date-Added = {2018-12-11 16:38:50 -0800},
	Date-Modified = {2018-12-11 16:38:50 -0800},
	Doi = {10.1109/TPAMI.2016.2646685},
	Journal = {IEEE Trans Pattern Anal Mach Intell},
	Journal-Full = {IEEE transactions on pattern analysis and machine intelligence},
	Month = {Dec},
	Number = {12},
	Pages = {2496-2509},
	Pmc = {PMC5889303},
	Pmid = {28092517},
	Pst = {ppublish},
	Title = {Transformations Based on Continuous Piecewise-Affine Velocity Fields},
	Volume = {39},
	Year = {2017},
	Bdsk-Url-1 = {https://doi.org/10.1109/TPAMI.2016.2646685}}

@inproceedings{Detlefsen:2018aa,
	Author = {Nicki Skafte Detlefsen and Oren Freifeld and S{\o}ren Hauberg},
	Booktitle = {Proceedings of the {IEEE} {C}onference on {C}omputer {V}ision and {P}attern {R}ecognition},
	Date-Added = {2018-12-11 16:32:53 -0800},
	Date-Modified = {2018-12-23 20:10:03 -0800},
	Title = {Deep Diffeomorphic Transformer Networks},
	Year = {2018}}

@inproceedings{Rocco:2017aa,
	Author = {I. Rocco and R. Arandjelovi{\'c} and J. Sivic},
	Booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
	Date-Added = {2018-12-11 13:15:53 -0800},
	Date-Modified = {2018-12-11 13:18:13 -0800},
	Title = {Convolutional neural network architecture for geometric matching},
	Year = {2017}}

@article{Dai:2017aa,
	Author = {Jifeng Dai and Haozhi Qi and Yuwen Xiong and Yi Li and Guodong Zhang and Han Hu and Yichen Wei},
	Date-Added = {2018-12-11 13:09:24 -0800},
	Date-Modified = {2018-12-11 13:10:27 -0800},
	Journal = {arXiv preprint arXiv:1703.06211},
	Title = {Deformable Convolutional Networks},
	Year = {2017}}

@article{Schmidhuber:2015aa,
	Author = {J{\"u}rgen Schmidhuber},
	Date-Added = {2018-12-10 20:34:28 -0800},
	Date-Modified = {2018-12-10 20:35:23 -0800},
	Journal = {Neural Networks},
	Pages = {85--117},
	Title = {Deep learning in neural networks: An overview},
	Volume = {61},
	Year = {2015}}

@article{Litjens:2017aa,
	Abstract = {Deep learning algorithms, in particular convolutional networks, have rapidly become a methodology of choice for analyzing medical images. This paper reviews the major deep learning concepts pertinent to medical image analysis and summarizes over 300 contributions to the field, most of which appeared in the last year. We survey the use of deep learning for image classification, object detection, segmentation, registration, and other tasks. Concise overviews are provided of studies per application area: neuro, retinal, pulmonary, digital pathology, breast, cardiac, abdominal, musculoskeletal. We end with a summary of the current state-of-the-art, a critical discussion of open challenges and directions for future research.},
	Author = {Litjens, Geert and Kooi, Thijs and Bejnordi, Babak Ehteshami and Setio, Arnaud Arindra Adiyoso and Ciompi, Francesco and Ghafoorian, Mohsen and van der Laak, Jeroen A W M and van Ginneken, Bram and S{\'a}nchez, Clara I},
	Date-Added = {2018-12-10 20:33:08 -0800},
	Date-Modified = {2018-12-10 20:33:08 -0800},
	Doi = {10.1016/j.media.2017.07.005},
	Journal = {Med Image Anal},
	Journal-Full = {Medical image analysis},
	Keywords = {Convolutional neural networks; Deep learning; Medical imaging; Survey},
	Mesh = {Algorithms; Diagnostic Imaging; Humans; Image Processing, Computer-Assisted; Machine Learning; Neural Networks (Computer)},
	Month = {Dec},
	Pages = {60-88},
	Pmid = {28778026},
	Pst = {ppublish},
	Title = {A survey on deep learning in medical image analysis},
	Volume = {42},
	Year = {2017},
	Bdsk-Url-1 = {https://doi.org/10.1016/j.media.2017.07.005}}

@article{Biswas:2019aa,
	Abstract = {Deep learning (DL) is affecting each and every sphere of public and private lives and becoming a tool for daily use. The power of DL lies in the fact that it tries to imitate the activities of neurons in the neocortex of human brain where the thought process takes place. Therefore, like the brain, it tries to learn and recognize patterns in the form of digital images. This power is built on the depth of many layers of computing neurons backed by high power processors and graphics processing units (GPUs) easily available today. In the current scenario, we have provided detailed survey of various types of DL systems available today, and specifically, we have concentrated our efforts on current applications of DL in medical imaging. We have also focused our efforts on explaining the readers the rapid transition of technology from machine learning to DL and have tried our best in reasoning this paradigm shift. Further, a detailed analysis of complexities involved in this shift and possible benefits accrued by the users and developers.},
	Author = {Biswas, Mainak and Kuppili, Venkatanareshbabu and Saba, Luca and Edla, Damodar Reddy and Suri, Harman S and Cuadrado-Godia, Elisa and Laird, John R and Marinhoe, Rui Tato and Sanches, Joao M and Nicolaides, Andrew and Suri, Jasjit S},
	Date-Added = {2018-12-10 20:25:39 -0800},
	Date-Modified = {2018-12-10 20:25:39 -0800},
	Journal = {Front Biosci (Landmark Ed)},
	Journal-Full = {Frontiers in bioscience (Landmark edition)},
	Month = {01},
	Pages = {392-426},
	Pmid = {30468663},
	Pst = {epublish},
	Title = {State-of-the-art review on deep learning in medical imaging},
	Volume = {24},
	Year = {2019}}

@article{Ker:2018aa,
	Author = {Justin Ker and Lipo Wang and Jai Rao and Tchoyoson Lim},
	Date-Added = {2018-12-10 20:19:27 -0800},
	Date-Modified = {2018-12-10 20:21:09 -0800},
	Journal = {IEEE Access},
	Pages = {9375--9389},
	Title = {Deep Learning Applications in Medical Image Analysis},
	Volume = {6},
	Year = {2018}}

@article{Ginneken:2017aa,
	Abstract = {Half a century ago, the term "computer-aided diagnosis" (CAD) was introduced in the scientific literature. Pulmonary imaging, with chest radiography and computed tomography, has always been one of the focus areas in this field. In this study, I describe how machine learning became the dominant technology for tackling CAD in the lungs, generally producing better results than do classical rule-based approaches, and how the field is now rapidly changing: in the last few years, we have seen how even better results can be obtained with deep learning. The key differences among rule-based processing, machine learning, and deep learning are summarized and illustrated for various applications of CAD in the chest.},
	Author = {van Ginneken, Bram},
	Date-Added = {2018-12-10 20:18:25 -0800},
	Date-Modified = {2018-12-10 20:18:25 -0800},
	Doi = {10.1007/s12194-017-0394-5},
	Journal = {Radiol Phys Technol},
	Journal-Full = {Radiological physics and technology},
	Keywords = {Computer-aided detection; Computer-aided diagnosis; Deep learning; Image processing; Machine learning; Pulmonary image analysis},
	Mesh = {Humans; Image Processing, Computer-Assisted; Lung Neoplasms; Machine Learning; Radiography, Thoracic},
	Month = {Mar},
	Number = {1},
	Pages = {23-32},
	Pmc = {PMC5337239},
	Pmid = {28211015},
	Pst = {ppublish},
	Title = {Fifty years of computer analysis in chest imaging: rule-based, machine learning, deep learning},
	Volume = {10},
	Year = {2017},
	Bdsk-Url-1 = {https://doi.org/10.1007/s12194-017-0394-5}}

@article{Gibson:2018aa,
	Abstract = {BACKGROUND AND OBJECTIVES: Medical image analysis and computer-assisted intervention problems are increasingly being addressed with deep-learning-based solutions. Established deep-learning platforms are flexible but do not provide specific functionality for medical image analysis and adapting them for this domain of application requires substantial implementation effort. Consequently, there has been substantial duplication of effort and incompatible infrastructure developed across many research groups. This work presents the open-source NiftyNet platform for deep learning in medical imaging. The ambition of NiftyNet is to accelerate and simplify the development of these solutions, and to provide a common mechanism for disseminating research outputs for the community to use, adapt and build upon.
METHODS: The NiftyNet infrastructure provides a modular deep-learning pipeline for a range of medical imaging applications including segmentation, regression, image generation and representation learning applications. Components of the NiftyNet pipeline including data loading, data augmentation, network architectures, loss functions and evaluation metrics are tailored to, and take advantage of, the idiosyncracies of medical image analysis and computer-assisted intervention. NiftyNet is built on the TensorFlow framework and supports features such as TensorBoard visualization of 2D and 3D images and computational graphs by default.
RESULTS: We present three illustrative medical image analysis applications built using NiftyNet infrastructure: (1) segmentation of multiple abdominal organs from computed tomography; (2) image regression to predict computed tomography attenuation maps from brain magnetic resonance images; and (3) generation of simulated ultrasound images for specified anatomical poses.
CONCLUSIONS: The NiftyNet infrastructure enables researchers to rapidly develop and distribute deep learning solutions for segmentation, regression, image generation and representation learning applications, or extend the platform to new applications.},
	Author = {Gibson, Eli and Li, Wenqi and Sudre, Carole and Fidon, Lucas and Shakir, Dzhoshkun I and Wang, Guotai and Eaton-Rosen, Zach and Gray, Robert and Doel, Tom and Hu, Yipeng and Whyntie, Tom and Nachev, Parashkev and Modat, Marc and Barratt, Dean C and Ourselin, S{\'e}bastien and Cardoso, M Jorge and Vercauteren, Tom},
	Date-Added = {2018-12-10 20:17:50 -0800},
	Date-Modified = {2018-12-10 20:17:50 -0800},
	Doi = {10.1016/j.cmpb.2018.01.025},
	Journal = {Comput Methods Programs Biomed},
	Journal-Full = {Computer methods and programs in biomedicine},
	Keywords = {Convolutional neural network; Deep learning; Generative adversarial network; Image regression; Medical image analysis; Segmentation},
	Mesh = {Abdomen; Brain; Computer Simulation; Databases, Factual; Diagnostic Imaging; Humans; Image Processing, Computer-Assisted; Machine Learning; Magnetic Resonance Imaging; Neural Networks (Computer); Ultrasonography},
	Month = {May},
	Pages = {113-122},
	Pmc = {PMC5869052},
	Pmid = {29544777},
	Pst = {ppublish},
	Title = {NiftyNet: a deep-learning platform for medical imaging},
	Volume = {158},
	Year = {2018},
	Bdsk-Url-1 = {https://doi.org/10.1016/j.cmpb.2018.01.025}}

@article{Suzuki:2017aa,
	Abstract = {The use of machine learning (ML) has been increasing rapidly in the medical imaging field, including computer-aided diagnosis (CAD), radiomics, and medical image analysis. Recently, an ML area called deep learning emerged in the computer vision field and became very popular in many fields. It started from an event in late 2012, when a deep-learning approach based on a convolutional neural network (CNN) won an overwhelming victory in the best-known worldwide computer vision competition, ImageNet Classification. Since then, researchers in virtually all fields, including medical imaging, have started actively participating in the explosively growing field of deep learning. In this paper, the area of deep learning in medical imaging is overviewed, including (1) what was changed in machine learning before and after the introduction of deep learning, (2) what is the source of the power of deep learning, (3) two major deep-learning models: a massive-training artificial neural network (MTANN) and a convolutional neural network (CNN), (4) similarities and differences between the two models, and (5) their applications to medical imaging. This review shows that ML with feature input (or feature-based ML) was dominant before the introduction of deep learning, and that the major and essential difference between ML before and after deep learning is the learning of image data directly without object segmentation or feature extraction; thus, it is the source of the power of deep learning, although the depth of the model is an important attribute. The class of ML with image input (or image-based ML) including deep learning has a long history, but recently gained popularity due to the use of the new terminology, deep learning. There are two major models in this class of ML in medical imaging, MTANN and CNN, which have similarities as well as several differences. In our experience, MTANNs were substantially more efficient in their development, had a higher performance, and required a lesser number of training cases than did CNNs. "Deep learning", or ML with image input, in medical imaging is an explosively growing, promising field. It is expected that ML with image input will be the mainstream area in the field of medical imaging in the next few decades.},
	Author = {Suzuki, Kenji},
	Date-Added = {2018-12-10 20:15:31 -0800},
	Date-Modified = {2018-12-10 20:15:31 -0800},
	Doi = {10.1007/s12194-017-0406-5},
	Journal = {Radiol Phys Technol},
	Journal-Full = {Radiological physics and technology},
	Keywords = {Classification; Computer-aided diagnosis; Convolutional neural network; Deep learning; Massive-training artificial neural network; Medical image analysis},
	Mesh = {Diagnostic Imaging; Image Processing, Computer-Assisted; Machine Learning},
	Month = {Sep},
	Number = {3},
	Pages = {257-273},
	Pmid = {28689314},
	Pst = {ppublish},
	Title = {Overview of deep learning in medical imaging},
	Volume = {10},
	Year = {2017},
	Bdsk-Url-1 = {https://doi.org/10.1007/s12194-017-0406-5}}

@article{Shen:2017aa,
	Abstract = {This review covers computer-assisted analysis of images in the field of medical imaging. Recent advances in machine learning, especially with regard to deep learning, are helping to identify, classify, and quantify patterns in medical images. At the core of these advances is the ability to exploit hierarchical feature representations learned solely from data, instead of features designed by hand according to domain-specific knowledge. Deep learning is rapidly becoming the state of the art, leading to enhanced performance in various medical applications. We introduce the fundamentals of deep learning methods and review their successes in image registration, detection of anatomical and cellular structures, tissue segmentation, computer-aided disease diagnosis and prognosis, and so on. We conclude by discussing research issues and suggesting future directions for further improvement.},
	Author = {Shen, Dinggang and Wu, Guorong and Suk, Heung-Il},
	Date-Added = {2018-12-10 20:15:02 -0800},
	Date-Modified = {2018-12-10 20:15:02 -0800},
	Doi = {10.1146/annurev-bioeng-071516-044442},
	Journal = {Annu Rev Biomed Eng},
	Journal-Full = {Annual review of biomedical engineering},
	Keywords = {deep learning; medical image analysis; unsupervised feature learning},
	Mesh = {Algorithms; Diagnostic Imaging; Image Enhancement; Image Interpretation, Computer-Assisted; Neural Networks (Computer); Pattern Recognition, Automated; Unsupervised Machine Learning},
	Month = {06},
	Pages = {221-248},
	Pmc = {PMC5479722},
	Pmid = {28301734},
	Pst = {ppublish},
	Title = {Deep Learning in Medical Image Analysis},
	Volume = {19},
	Year = {2017},
	Bdsk-Url-1 = {https://doi.org/10.1146/annurev-bioeng-071516-044442}}

@article{Greenspan:2016aa,
	Author = {Hayit Greenspan and Bram Van Ginneken and Ronald M. Summers},
	Date-Added = {2018-12-10 20:09:21 -0800},
	Date-Modified = {2018-12-10 20:13:01 -0800},
	Journal = {IEEE Trans Med Imaging},
	Number = {5},
	Pages = {1153--1159},
	Title = {Deep Learning in Medical Imaging: Overview and Future Promise of an Exciting New Technique},
	Volume = {35},
	Year = {2016}}

@webpage{imageNetKaggle,
	Date-Added = {2018-12-10 15:48:35 -0800},
	Date-Modified = {2018-12-10 15:48:35 -0800},
	Lastchecked = {Dec. 10, 2018},
	Url = {https://www.kaggle.com/c/imagenet-object-localization-challenge},
	Bdsk-Url-1 = {https://www.kaggle.com/c/imagenet-object-localization-challenge}}

@article{He:2015,
	Archiveprefix = {arXiv},
	Author = {Kaiming He and Xiangyu Zhang and Shaoqing Ren and Jian Sun},
	Bibsource = {dblp computer science bibliography, https://dblp.org},
	Biburl = {https://dblp.org/rec/bib/journals/corr/HeZRS15},
	Date-Added = {2018-12-10 14:19:21 -0800},
	Date-Modified = {2018-12-10 14:19:21 -0800},
	Eprint = {1512.03385},
	Journal = {CoRR},
	Timestamp = {Wed, 07 Jun 2017 14:41:17 +0200},
	Title = {Deep Residual Learning for Image Recognition},
	Url = {http://arxiv.org/abs/1512.03385},
	Volume = {abs/1512.03385},
	Year = {2015},
	Bdsk-Url-1 = {http://arxiv.org/abs/1512.03385}}

@article{Szegedy:2015,
	Archiveprefix = {arXiv},
	Author = {Christian Szegedy and Vincent Vanhoucke and Sergey Ioffe and Jonathon Shlens and Zbigniew Wojna},
	Bibsource = {dblp computer science bibliography, https://dblp.org},
	Biburl = {https://dblp.org/rec/bib/journals/corr/SzegedyVISW15},
	Date-Added = {2018-12-08 20:37:54 -0800},
	Date-Modified = {2018-12-08 20:37:54 -0800},
	Eprint = {1512.00567},
	Journal = {CoRR},
	Timestamp = {Wed, 07 Jun 2017 14:40:22 +0200},
	Title = {Rethinking the Inception Architecture for Computer Vision},
	Url = {http://arxiv.org/abs/1512.00567},
	Volume = {abs/1512.00567},
	Year = {2015},
	Bdsk-Url-1 = {http://arxiv.org/abs/1512.00567}}

@article{Simonyan:2014,
	Archiveprefix = {arXiv},
	Author = {Karen Simonyan and Andrew Zisserman},
	Bibsource = {dblp computer science bibliography, https://dblp.org},
	Biburl = {https://dblp.org/rec/bib/journals/corr/SimonyanZ14a},
	Date-Added = {2018-12-08 20:37:09 -0800},
	Date-Modified = {2018-12-08 20:37:09 -0800},
	Eprint = {1409.1556},
	Journal = {CoRR},
	Timestamp = {Wed, 07 Jun 2017 14:41:51 +0200},
	Title = {Very Deep Convolutional Networks for Large-Scale Image Recognition},
	Url = {http://arxiv.org/abs/1409.1556},
	Volume = {abs/1409.1556},
	Year = {2014},
	Bdsk-Url-1 = {http://arxiv.org/abs/1409.1556}}

@article{Russakovsky:2015aa,
	Author = {Olga Russakovsky and Jia Deng and Hao Su and Jonathan Krause and Sanjeev Satheesh and Sean Ma and Zhiheng Huang and Andrej Karpathy and Aditya Khosla and Michael Bernstein and Alexander C. Berg and Li Fei-Fei},
	Date-Added = {2018-12-08 20:34:23 -0800},
	Date-Modified = {2018-12-08 20:34:23 -0800},
	Journal = {International Journal of Computer Vision},
	Month = {December},
	Number = {3},
	Pages = {211-252},
	Title = {{ImageNet} Large Scale Visual Recognition Challenge},
	Volume = {115},
	Year = {2015}}

@inproceedings{Ronneberger:2015aa,
	Author = {Olaf Ronneberger and Philipp Fischer and Thomas Brox},
	Booktitle = {Proceedings of the {I}nternational {C}onference on {M}edical {I}mage {C}omputing and {C}omputer-{A}ssisted {I}ntervention},
	Date-Added = {2018-12-08 20:34:19 -0800},
	Date-Modified = {2018-12-23 20:13:39 -0800},
	Pages = {234-241},
	Publisher = {Springer},
	Series = {LNCS},
	Title = {U-Net: Convolutional Networks for Biomedical Image Segmentation},
	Volume = {9351},
	Year = {2015}}

@inproceedings{Krizhevsky:2012,
	Acmid = {2999257},
	Address = {USA},
	Author = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E.},
	Booktitle = {Proceedings of the 25th {I}nternational {C}onference on {N}eural {I}nformation {P}rocessing {S}ystems},
	Date-Added = {2018-12-08 20:33:50 -0800},
	Date-Modified = {2018-12-23 20:11:57 -0800},
	Location = {Lake Tahoe, Nevada},
	Numpages = {9},
	Pages = {1097--1105},
	Publisher = {Curran Associates Inc.},
	Series = {NIPS'12},
	Title = {ImageNet Classification with Deep Convolutional Neural Networks},
	Url = {http://dl.acm.org/citation.cfm?id=2999134.2999257},
	Year = {2012},
	Bdsk-Url-1 = {http://dl.acm.org/citation.cfm?id=2999134.2999257}}

@inproceedings{Waibel:1987aa,
	Author = {Alex Waibel},
	Booktitle = {Meeting of the {I}nstitute of {E}lectrical, {I}nformation and {C}ommunication {E}ngineers ({IEICE}).},
	Date-Added = {2018-12-08 19:05:03 -0800},
	Date-Modified = {2018-12-23 20:11:11 -0800},
	Title = {Phoneme Recognition Using Time-Delay Neural Networks},
	Year = {1987}}

@article{Hubel:1962aa,
	Author = {D. H. Hubel and T. N. Wiesel},
	Date-Added = {2018-12-08 18:42:46 -0800},
	Date-Modified = {2018-12-08 18:43:37 -0800},
	Journal = {J Physiol},
	Journal-Full = {The Journal of physiology},
	Keywords = {CEREBRAL CORTEX/physiology},
	Mesh = {Animals; Cats; Cerebral Cortex; Visual Cortex},
	Month = {Jan},
	Pages = {106-54},
	Pmc = {PMC1359523},
	Pmid = {14449617},
	Pst = {ppublish},
	Title = {Receptive fields, binocular interaction and functional architecture in the cat's visual cortex},
	Volume = {160},
	Year = {1962}}

@article{LeCun:1989aa,
	Author = {Y. LeCun and B. Boser and J. S. Denker and D. Henderson and R. E. Howard and W. Hubbard and L. D. Jacke},
	Date-Added = {2018-12-08 18:38:39 -0800},
	Date-Modified = {2018-12-08 18:40:03 -0800},
	Journal = {Neural Computation},
	Number = {4},
	Pages = {541--551},
	Title = {Backpropagation Applied to Handwritten Zip Code Recognition},
	Volume = {1},
	Year = {1989}}

@article{LeCun:2015aa,
	Abstract = {Deep learning allows computational models that are composed of multiple processing layers to learn representations of data with multiple levels of abstraction. These methods have dramatically improved the state-of-the-art in speech recognition, visual object recognition, object detection and many other domains such as drug discovery and genomics. Deep learning discovers intricate structure in large data sets by using the backpropagation algorithm to indicate how a machine should change its internal parameters that are used to compute the representation in each layer from the representation in the previous layer. Deep convolutional nets have brought about breakthroughs in processing images, video, speech and audio, whereas recurrent nets have shone light on sequential data such as text and speech. },
	Author = {LeCun, Yann and Bengio, Yoshua and Hinton, Geoffrey},
	Date-Added = {2018-12-08 18:32:49 -0800},
	Date-Modified = {2018-12-08 18:33:14 -0800},
	Doi = {10.1038/nature14539},
	Journal = {Nature},
	Journal-Full = {Nature},
	Mesh = {Algorithms; Artificial Intelligence; Computers; Language; Neural Networks (Computer)},
	Month = {May},
	Number = {7553},
	Pages = {436-44},
	Pmid = {26017442},
	Pst = {ppublish},
	Title = {Deep learning},
	Volume = {521},
	Year = {2015},
	Bdsk-Url-1 = {https://doi.org/10.1038/nature14539}}

@article{Fukushima:1980aa,
	Abstract = {A neural network model for a mechanism of visual pattern recognition is proposed in this paper. The network is self-organized by "learning without a teacher", and acquires an ability to recognize stimulus patterns based on the geometrical similarity (Gestalt) of their shapes without affected by their positions. This network is given a nickname "neocognitron". After completion of self-organization, the network has a structure similar to the hierarchy model of the visual nervous system proposed by Hubel and Wiesel. The network consists of an input layer (photoreceptor array) followed by a cascade connection of a number of modular structures, each of which is composed of two layers of cells connected in a cascade. The first layer of each module consists of "S-cells", which show characteristics similar to simple cells or lower order hypercomplex cells, and the second layer consists of "C-cells" similar to complex cells or higher order hypercomplex cells. The afferent synapses to each S-cell have plasticity and are modifiable. The network has an ability of unsupervised learning: We do not need any "teacher" during the process of self-organization, and it is only needed to present a set of stimulus patterns repeatedly to the input layer of the network. The network has been simulated on a digital computer. After repetitive presentation of a set of stimulus patterns, each stimulus pattern has become to elicit an output only from one of the C-cells of the last layer, and conversely, this C-cell has become selectively responsive only to that stimulus pattern. That is, none of the C-cells of the last layer responds to more than one stimulus pattern. The response of the C-cells of the last layer is not affected by the pattern's position at all. Neither is it affected by a small change in shape nor in size of the stimulus pattern.},
	Author = {Fukushima, K},
	Date-Added = {2018-12-08 18:19:32 -0800},
	Date-Modified = {2018-12-08 18:19:32 -0800},
	Journal = {Biol Cybern},
	Journal-Full = {Biological cybernetics},
	Mesh = {Cognition; Computers; Form Perception; Learning; Models, Neurological; Nerve Net; Nervous System Physiological Phenomena; Pattern Recognition, Visual},
	Number = {4},
	Pages = {193-202},
	Pmid = {7370364},
	Pst = {ppublish},
	Title = {Neocognitron: a self organizing neural network model for a mechanism of pattern recognition unaffected by shift in position},
	Volume = {36},
	Year = {1980}}

@article{Ivakhnenko:1971aa,
	Author = {A. G. Ivakhnenko},
	Date-Added = {2018-12-08 18:05:08 -0800},
	Date-Modified = {2018-12-08 18:08:03 -0800},
	Journal = {IEEE Transactions on Systems, Man, and Cybernetics},
	Month = {Oct},
	Number = {4},
	Pages = {364--378},
	Title = {Polynomial Theory of Complex Systems},
	Volume = {SMC-1},
	Year = {1971}}

@article{Pluim:2003aa,
	Abstract = {An overview is presented of the medical image processing literature on mutual-information-based registration. The aim of the survey is threefold: an introduction for those new to the field, an overview for those working in the field, and a reference for those searching for literature on a specific application. Methods are classified according to the different aspects of mutual-information-based registration. The main division is in aspects of the methodology and of the application. The part on methodology describes choices made on facets such as preprocessing of images, gray value interpolation, optimization, adaptations to the mutual information measure, and different types of geometrical transformations. The part on applications is a reference of the literature available on different modalities, on interpatient registration and on different anatomical objects. Comparison studies including mutual information are also considered. The paper starts with a description of entropy and mutual information and it closes with a discussion on past achievements and some future challenges.},
	Author = {Pluim, Josien P W and Maintz, J B Antoine and Viergever, Max A},
	Date-Added = {2018-12-06 21:14:24 -0800},
	Date-Modified = {2018-12-06 21:14:24 -0800},
	Doi = {10.1109/TMI.2003.815867},
	Journal = {IEEE Trans Med Imaging},
	Journal-Full = {IEEE transactions on medical imaging},
	Mesh = {Algorithms; Anatomy, Cross-Sectional; Humans; Image Enhancement; Image Interpretation, Computer-Assisted; Imaging, Three-Dimensional; Pattern Recognition, Automated; Subtraction Technique},
	Month = {Aug},
	Number = {8},
	Pages = {986-1004},
	Pmid = {12906253},
	Pst = {ppublish},
	Title = {Mutual-information-based registration of medical images: a survey},
	Volume = {22},
	Year = {2003},
	Bdsk-Url-1 = {https://doi.org/10.1109/TMI.2003.815867}}

@article{Gholipour:2007aa,
	Abstract = {Functional localization is a concept which involves the application of a sequence of geometrical and statistical image processing operations in order to define the location of brain activity or to produce functional/parametric maps with respect to the brain structure or anatomy. Considering that functional brain images do not normally convey detailed structural information and, thus, do not present an anatomically specific localization of functional activity, various image registration techniques are introduced in the literature for the purpose of mapping functional activity into an anatomical image or a brain atlas. The problems addressed by these techniques differ depending on the application and the type of analysis, i.e., single-subject versus group analysis. Functional to anatomical brain image registration is the core part of functional localization in most applications and is accompanied by intersubject and subject-to-atlas registration for group analysis studies. Cortical surface registration and automatic brain labeling are some of the other tools towards establishing a fully automatic functional localization procedure. While several previous survey papers have reviewed and classified general-purpose medical image registration techniques, this paper provides an overview of brain functional localization along with a survey and classification of the image registration techniques related to this problem.},
	Author = {Gholipour, Ali and Kehtarnavaz, Nasser and Briggs, Richard and Devous, Michael and Gopinath, Kaundinya},
	Date-Added = {2018-12-06 21:12:34 -0800},
	Date-Modified = {2018-12-06 21:12:34 -0800},
	Doi = {10.1109/TMI.2007.892508},
	Journal = {IEEE Trans Med Imaging},
	Journal-Full = {IEEE transactions on medical imaging},
	Mesh = {Algorithms; Artificial Intelligence; Brain; Brain Mapping; Cluster Analysis; Evoked Potentials; Humans; Image Enhancement; Image Interpretation, Computer-Assisted; Imaging, Three-Dimensional; Magnetic Resonance Imaging; Pattern Recognition, Automated; Reproducibility of Results; Sensitivity and Specificity; Subtraction Technique},
	Month = {Apr},
	Number = {4},
	Pages = {427-51},
	Pmid = {17427731},
	Pst = {ppublish},
	Title = {Brain functional localization: a survey of image registration techniques},
	Volume = {26},
	Year = {2007},
	Bdsk-Url-1 = {https://doi.org/10.1109/TMI.2007.892508}}

@article{Maintz:1998aa,
	Abstract = {The purpose of this paper is to present a survey of recent (published in 1993 or later) publications concerning medical image registration techniques. These publications will be classified according to a model based on nine salient criteria, the main dichotomy of which is extrinsic versus intrinsic methods. The statistics of the classification show definite trends in the evolving registration techniques, which will be discussed. At this moment, the bulk of interesting intrinsic methods is based on either segmented points or surfaces, or on techniques endeavouring to use the full information content of the images involved.},
	Author = {Maintz, J B and Viergever, M A},
	Date-Added = {2018-12-06 21:11:12 -0800},
	Date-Modified = {2018-12-06 21:11:12 -0800},
	Journal = {Med Image Anal},
	Journal-Full = {Medical image analysis},
	Mesh = {Abdomen; Diagnostic Imaging; Extremities; Head; Humans; Pelvis; Reproducibility of Results; Spine; Thorax},
	Month = {Mar},
	Number = {1},
	Pages = {1-36},
	Pmid = {10638851},
	Pst = {ppublish},
	Title = {A survey of medical image registration},
	Volume = {2},
	Year = {1998}}

@article{Brown:1992,
	Acmid = {146374},
	Address = {New York, NY, USA},
	Author = {Brown, Lisa Gottesfeld},
	Date-Added = {2018-12-06 21:08:51 -0800},
	Date-Modified = {2018-12-06 21:09:04 -0800},
	Doi = {10.1145/146370.146374},
	Issn = {0360-0300},
	Issue_Date = {Dec. 1992},
	Journal = {ACM Comput. Surv.},
	Keywords = {image registration, image warping, rectification, template matching},
	Month = dec,
	Number = {4},
	Numpages = {52},
	Pages = {325--376},
	Publisher = {ACM},
	Title = {A Survey of Image Registration Techniques},
	Url = {http://doi.acm.org/10.1145/146370.146374},
	Volume = {24},
	Year = {1992},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/146370.146374},
	Bdsk-Url-2 = {https://doi.org/10.1145/146370.146374}}

@article{Keszei:2017aa,
	Abstract = {We catalogue available software solutions for non-rigid image registration to support scientists in selecting suitable tools for specific medical registration purposes. Registration tools were identified using non-systematic search in Pubmed, Web of Science, IEEE Xplore{\textregistered} Digital Library, Google Scholar, and through references in identified sources (n = 22). Exclusions are due to unavailability or inappropriateness. The remaining (n = 18) tools were classified by (i) access and technology, (ii) interfaces and application, (iii) living community, (iv) supported file formats, and (v) types of registration methodologies emphasizing the similarity measures implemented. Out of the 18 tools, (i) 12 are open source, 8 are released under a permissive free license, which imposes the least restrictions on the use and further development of the tool, 8 provide graphical processing unit (GPU) support; (ii) 7 are built on software platforms, 5 were developed for brain image registration; (iii) 6 are under active development but only 3 have had their last update in 2015 or 2016; (iv) 16 support the Analyze format, while 7 file formats can be read with only one of the tools; and (v) 6 provide multiple registration methods and 6 provide landmark-based registration methods. Based on open source, licensing, GPU support, active community, several file formats, algorithms, and similarity measures, the tools Elastics and Plastimatch are chosen for the platform ITK and without platform requirements, respectively. Researchers in medical image analysis already have a large choice of registration tools freely available. However, the most recently published algorithms may not be included in the tools, yet.},
	Author = {Keszei, Andr{\'a}s P and Berkels, Benjamin and Deserno, Thomas M},
	Date-Added = {2018-12-06 21:07:25 -0800},
	Date-Modified = {2018-12-06 21:07:25 -0800},
	Doi = {10.1007/s10278-016-9915-8},
	Journal = {J Digit Imaging},
	Journal-Full = {Journal of digital imaging},
	Keywords = {Image alignment; Image analysis; Image registration; Open-source software; Public domain software; Software tool},
	Mesh = {Algorithms; Brain; Humans; Radiology Information Systems; Software; Surveys and Questionnaires; User-Computer Interface},
	Month = {02},
	Number = {1},
	Pages = {102-116},
	Pmc = {PMC5267604},
	Pmid = {27730414},
	Pst = {ppublish},
	Title = {Survey of Non-Rigid Registration Tools in Medicine},
	Volume = {30},
	Year = {2017},
	Bdsk-Url-1 = {https://doi.org/10.1007/s10278-016-9915-8}}

@article{Viergever:2016aa,
	Abstract = {A retrospective view on the past two decades of the field of medical image registration is presented, guided by the article "A survey of medical image registration" (Maintz and Viergever, 1998). It shows that the classification of the field introduced in that article is still usable, although some modifications to do justice to advances in the field would be due. The main changes over the last twenty years are the shift from extrinsic to intrinsic registration, the primacy of intensity-based registration, the breakthrough of nonlinear registration, the progress of inter-subject registration, and the availability of generic image registration software packages. Two problems that were called urgent already 20 years ago, are even more urgent nowadays: Validation of registration methods, and translation of results of image registration research to clinical practice. It may be concluded that the field of medical image registration has evolved, but still is in need of further development in various aspects.},
	Author = {Viergever, Max A and Maintz, J B Antoine and Klein, Stefan and Murphy, Keelin and Staring, Marius and Pluim, Josien P W},
	Date-Added = {2018-12-06 21:05:51 -0800},
	Date-Modified = {2018-12-06 21:05:51 -0800},
	Doi = {10.1016/j.media.2016.06.030},
	Journal = {Med Image Anal},
	Journal-Full = {Medical image analysis},
	Keywords = {Medical image registration},
	Mesh = {Algorithms; Humans; Image Processing, Computer-Assisted; Retrospective Studies},
	Month = {10},
	Pages = {140-144},
	Pmid = {27427472},
	Pst = {ppublish},
	Title = {A survey of medical image registration - under review},
	Volume = {33},
	Year = {2016},
	Bdsk-Url-1 = {https://doi.org/10.1016/j.media.2016.06.030}}

@article{Avants:2010aa,
	Abstract = {We use a new, unsupervised multivariate imaging and analysis strategy to identify related patterns of reduced white matter integrity, measured with the fractional anisotropy (FA) derived from diffusion tensor imaging (DTI), and decreases in cortical thickness, measured by high resolution T1-weighted imaging, in Alzheimer's disease (AD) and frontotemporal dementia (FTD). This process is based on a novel computational model derived from sparse canonical correlation analysis (SCCA) that allows us to automatically identify mutually predictive, distributed neuroanatomical regions from different imaging modalities. We apply the SCCA model to a dataset that includes 23 control subjects that are demographically matched to 49 subjects with autopsy or CSF-biomarker-diagnosed AD (n=24) and FTD (n=25) with both DTI and T1-weighted structural imaging. SCCA shows that the FTD-related frontal and temporal degeneration pattern is correlated across modalities with permutation corrected p<0.0005. In AD, we find significant association between cortical thinning and reduction in white matter integrity within a distributed parietal and temporal network (p<0.0005). Furthermore, we show that-within SCCA identified regions-significant differences exist between FTD and AD cortical-connective degeneration patterns. We validate these distinct, multimodal imaging patterns by showing unique relationships with cognitive measures in AD and FTD. We conclude that SCCA is a potentially valuable approach in image analysis that can be applied productively to distinguishing between neurodegenerative conditions.},
	Author = {Avants, Brian B and Cook, Philip A and Ungar, Lyle and Gee, James C and Grossman, Murray},
	Date-Added = {2018-12-06 20:45:59 -0800},
	Date-Modified = {2018-12-06 20:45:59 -0800},
	Doi = {10.1016/j.neuroimage.2010.01.041},
	Journal = {Neuroimage},
	Journal-Full = {NeuroImage},
	Mesh = {Alzheimer Disease; Anisotropy; Biomarkers; Brain; Cerebral Cortex; Computer Simulation; Databases, Factual; Dementia; Diffusion Tensor Imaging; Female; Frontotemporal Dementia; Humans; Image Processing, Computer-Assisted; Magnetic Resonance Imaging; Male; Middle Aged; Models, Neurological; Multivariate Analysis; Nerve Fibers, Myelinated; Organ Size},
	Month = {Apr},
	Number = {3},
	Pages = {1004-16},
	Pmc = {PMC2953719},
	Pmid = {20083207},
	Pst = {ppublish},
	Title = {Dementia induces correlated reductions in white matter integrity and cortical thickness: a multivariate neuroimaging study with sparse canonical correlation analysis},
	Volume = {50},
	Year = {2010},
	Bdsk-Url-1 = {https://doi.org/10.1016/j.neuroimage.2010.01.041}}

@article{Iglesias:2015aa,
	Abstract = {Multi-atlas segmentation (MAS), first introduced and popularized by the pioneering work of Rohlfing, et al. (2004), Klein, et al. (2005), and Heckemann, et al. (2006), is becoming one of the most widely-used and successful image segmentation techniques in biomedical applications. By manipulating and utilizing the entire dataset of "atlases" (training images that have been previously labeled, e.g., manually by an expert), rather than some model-based average representation, MAS has the flexibility to better capture anatomical variation, thus offering superior segmentation accuracy. This benefit, however, typically comes at a high computational cost. Recent advancements in computer hardware and image processing software have been instrumental in addressing this challenge and facilitated the wide adoption of MAS. Today, MAS has come a long way and the approach includes a wide array of sophisticated algorithms that employ ideas from machine learning, probabilistic modeling, optimization, and computer vision, among other fields. This paper presents a survey of published MAS algorithms and studies that have applied these methods to various biomedical problems. In writing this survey, we have three distinct aims. Our primary goal is to document how MAS was originally conceived, later evolved, and now relates to alternative methods. Second, this paper is intended to be a detailed reference of past research activity in MAS, which now spans over a decade (2003-2014) and entails novel methodological developments and application-specific solutions. Finally, our goal is to also present a perspective on the future of MAS, which, we believe, will be one of the dominant approaches in biomedical image segmentation.},
	Author = {Iglesias, Juan Eugenio and Sabuncu, Mert R},
	Date-Added = {2018-12-06 20:22:39 -0800},
	Date-Modified = {2018-12-06 20:22:39 -0800},
	Doi = {10.1016/j.media.2015.06.012},
	Journal = {Med Image Anal},
	Journal-Full = {Medical image analysis},
	Keywords = {Label fusion; Multi-atlas segmentation; Survey},
	Mesh = {Algorithms; Humans; Image Interpretation, Computer-Assisted; Pattern Recognition, Automated; Reproducibility of Results; Sensitivity and Specificity; Subtraction Technique},
	Month = {Aug},
	Number = {1},
	Pages = {205-219},
	Pmc = {PMC4532640},
	Pmid = {26201875},
	Pst = {ppublish},
	Title = {Multi-atlas segmentation of biomedical images: A survey},
	Volume = {24},
	Year = {2015},
	Bdsk-Url-1 = {https://doi.org/10.1016/j.media.2015.06.012}}

@article{Singh:2013aa,
	Abstract = {This paper presents a novel approach for diffeomorphic image regression and atlas estimation that results in improved convergence and numerical stability. We use a vector momenta representation of a diffeomorphism's initial conditions instead of the standard scalar momentum that is typically used. The corresponding variational problem results in a closed-form update for template estimation in both the geodesic regression and atlas estimation problems. While we show that the theoretical optimal solution is equivalent to the scalar momenta case, the simplification of the optimization problem leads to more stable and efficient estimation in practice. We demonstrate the effectiveness of our method for atlas estimation and geodesic regression using synthetically generated shapes and 3D MRI brain scans.},
	Author = {Singh, Nikhil and Hinkle, Jacob and Joshi, Sarang and Fletcher, P Thomas},
	Date-Added = {2018-11-26 20:18:45 -0800},
	Date-Modified = {2018-11-26 20:19:50 -0800},
	Doi = {10.1109/ISBI.2013.6556700},
	Journal = {Proc IEEE Int Symp Biomed Imaging},
	Journal-Full = {Proceedings. IEEE International Symposium on Biomedical Imaging},
	Keywords = {Atlas; Geodesic regression; LDDMM; Vector Momentum},
	Month = {Apr},
	Pages = {1219-1222},
	Pmc = {PMC4232950},
	Pmid = {25404997},
	Pst = {ppublish},
	Title = {A Vector Momenta Formulation of Diffeomorphisms for Improved Geodesic Regression And Atlas Construction},
	Volume = {2013},
	Year = {2013},
	Bdsk-Url-1 = {https://doi.org/10.1109/ISBI.2013.6556700}}

@article{Miller:2006aa,
	Abstract = {Studying large deformations with a Riemannian approach has been an efficient point of view to generate metrics between deformable objects, and to provide accurate, non ambiguous and smooth matchings between images. In this paper, we study the geodesics of such large deformation diffeomorphisms, and more precisely, introduce a fundamental property that they satisfy, namely the conservation of momentum. This property allows us to generate and store complex deformations with the help of one initial "momentum" which serves as the initial state of a differential equation in the group of diffeomorphisms. Moreover, it is shown that this momentum can be also used for describing a deformation of given visual structures, like points, contours or images, and that, it has the same dimension as the described object, as a consequence of the normal momentum constraint we introduce.},
	Author = {Miller, Michael I and Trouv{\'e}, Alain and Younes, Laurent},
	Date-Added = {2018-11-26 18:55:31 -0800},
	Date-Modified = {2018-11-26 18:55:31 -0800},
	Doi = {10.1007/s10851-005-3624-0},
	Journal = {J Math Imaging Vis},
	Journal-Full = {Journal of mathematical imaging and vision},
	Month = {Jan},
	Number = {2},
	Pages = {209-228},
	Pmc = {PMC2897162},
	Pmid = {20613972},
	Pst = {ppublish},
	Title = {Geodesic Shooting for Computational Anatomy},
	Volume = {24},
	Year = {2006},
	Bdsk-Url-1 = {https://doi.org/10.1007/s10851-005-3624-0}}

@article{Vercauteren:2009aa,
	Abstract = {We propose an efficient non-parametric diffeomorphic image registration algorithm based on Thirion's demons algorithm. In the first part of this paper, we show that Thirion's demons algorithm can be seen as an optimization procedure on the entire space of displacement fields. We provide strong theoretical roots to the different variants of Thirion's demons algorithm. This analysis predicts a theoretical advantage for the symmetric forces variant of the demons algorithm. We show on controlled experiments that this advantage is confirmed in practice and yields a faster convergence. In the second part of this paper, we adapt the optimization procedure underlying the demons algorithm to a space of diffeomorphic transformations. In contrast to many diffeomorphic registration algorithms, our solution is computationally efficient since in practice it only replaces an addition of displacement fields by a few compositions. Our experiments show that in addition to being diffeomorphic, our algorithm provides results that are similar to the ones from the demons algorithm but with transformations that are much smoother and closer to the gold standard, available in controlled experiments, in terms of Jacobians.},
	Author = {Vercauteren, Tom and Pennec, Xavier and Perchant, Aymeric and Ayache, Nicholas},
	Date-Added = {2018-11-26 18:53:33 -0800},
	Date-Modified = {2018-11-26 18:53:33 -0800},
	Doi = {10.1016/j.neuroimage.2008.10.040},
	Journal = {Neuroimage},
	Journal-Full = {NeuroImage},
	Mesh = {Algorithms; Humans; Image Processing, Computer-Assisted},
	Month = {Mar},
	Number = {1 Suppl},
	Pages = {S61-72},
	Pmid = {19041946},
	Pst = {ppublish},
	Title = {Diffeomorphic demons: efficient non-parametric image registration},
	Volume = {45},
	Year = {2009},
	Bdsk-Url-1 = {https://doi.org/10.1016/j.neuroimage.2008.10.040}}

@article{Ashburner:2007aa,
	Abstract = {This paper describes DARTEL, which is an algorithm for diffeomorphic image registration. It is implemented for both 2D and 3D image registration and has been formulated to include an option for estimating inverse consistent deformations. Nonlinear registration is considered as a local optimisation problem, which is solved using a Levenberg-Marquardt strategy. The necessary matrix solutions are obtained in reasonable time using a multigrid method. A constant Eulerian velocity framework is used, which allows a rapid scaling and squaring method to be used in the computations. DARTEL has been applied to intersubject registration of 471 whole brain images, and the resulting deformations were evaluated in terms of how well they encode the shape information necessary to separate male and female subjects and to predict the ages of the subjects.},
	Author = {Ashburner, John},
	Date-Added = {2018-11-26 18:50:44 -0800},
	Date-Modified = {2018-11-26 18:50:44 -0800},
	Doi = {10.1016/j.neuroimage.2007.07.007},
	Journal = {Neuroimage},
	Journal-Full = {NeuroImage},
	Mesh = {Algorithms; Artificial Intelligence; Brain; Humans; Image Enhancement; Image Interpretation, Computer-Assisted; Imaging, Three-Dimensional; Magnetic Resonance Imaging; Pattern Recognition, Automated; Reproducibility of Results; Sensitivity and Specificity; Subtraction Technique},
	Month = {Oct},
	Number = {1},
	Pages = {95-113},
	Pmid = {17761438},
	Pst = {ppublish},
	Title = {A fast diffeomorphic image registration algorithm},
	Volume = {38},
	Year = {2007},
	Bdsk-Url-1 = {https://doi.org/10.1016/j.neuroimage.2007.07.007}}

@article{Zhang:2017aa,
	Abstract = {This paper presents an efficient algorithm for large deformation diffeomorphic metric mapping (LDDMM) with geodesic shooting for image registration. We introduce a novel finite dimensional Fourier representation of diffeomorphic deformations based on the key fact that the high frequency components of a diffeomorphism remain stationary throughout the integration process when computing the deformation associated with smooth velocity fields. We show that manipulating high dimensional diffeomorphisms can be carried out entirely in the bandlimited space by integrating the nonstationary low frequency components of the displacement field. This insight substantially reduces the computational cost of the registration problem. Experimental results show that our method is significantly faster than the state-of-the-art diffeomorphic image registration methods while producing equally accurate alignment. We demonstrate our algorithm in two different applications of image registration: neuroimaging and in-utero imaging.},
	Author = {Zhang, Miaomiao and Liao, Ruizhi and Dalca, Adrian V and Turk, Esra A and Luo, Jie and Grant, P Ellen and Golland, Polina},
	Date-Added = {2018-11-26 18:48:45 -0800},
	Date-Modified = {2018-11-26 18:48:45 -0800},
	Doi = {10.1007/978-3-319-59050-9_44},
	Journal = {Inf Process Med Imaging},
	Journal-Full = {Information processing in medical imaging : proceedings of the ... conference},
	Mesh = {Algorithms; Brain; Fetus; Humans; Image Enhancement; Image Interpretation, Computer-Assisted; Neuroimaging; Pattern Recognition, Automated; Reproducibility of Results; Sensitivity and Specificity},
	Month = {Jun},
	Pages = {559-570},
	Pmc = {PMC5788203},
	Pmid = {29391767},
	Pst = {ppublish},
	Title = {Frequency Diffeomorphisms for Efficient Image Registration},
	Volume = {10265},
	Year = {2017},
	Bdsk-Url-1 = {https://doi.org/10.1007/978-3-319-59050-9_44}}

@article{Avants:2008aa,
	Abstract = {One of the most challenging problems in modern neuroimaging is detailed characterization of neurodegeneration. Quantifying spatial and longitudinal atrophy patterns is an important component of this process. These spatiotemporal signals will aid in discriminating between related diseases, such as frontotemporal dementia (FTD) and Alzheimer's disease (AD), which manifest themselves in the same at-risk population. Here, we develop a novel symmetric image normalization method (SyN) for maximizing the cross-correlation within the space of diffeomorphic maps and provide the Euler-Lagrange equations necessary for this optimization. We then turn to a careful evaluation of our method. Our evaluation uses gold standard, human cortical segmentation to contrast SyN's performance with a related elastic method and with the standard ITK implementation of Thirion's Demons algorithm. The new method compares favorably with both approaches, in particular when the distance between the template brain and the target brain is large. We then report the correlation of volumes gained by algorithmic cortical labelings of FTD and control subjects with those gained by the manual rater. This comparison shows that, of the three methods tested, SyN's volume measurements are the most strongly correlated with volume measurements gained by expert labeling. This study indicates that SyN, with cross-correlation, is a reliable method for normalizing and making anatomical measurements in volumetric MRI of patients and at-risk elderly individuals.},
	Author = {Avants, B B and Epstein, C L and Grossman, M and Gee, J C},
	Date-Added = {2018-11-26 18:45:42 -0800},
	Date-Modified = {2018-11-26 18:45:42 -0800},
	Doi = {10.1016/j.media.2007.06.004},
	Journal = {Med Image Anal},
	Journal-Full = {Medical image analysis},
	Mesh = {Algorithms; Atrophy; Cerebral Cortex; Dementia; Humans; Image Enhancement; Image Interpretation, Computer-Assisted; Magnetic Resonance Imaging},
	Month = {Feb},
	Number = {1},
	Pages = {26-41},
	Pmc = {PMC2276735},
	Pmid = {17659998},
	Pst = {ppublish},
	Title = {Symmetric diffeomorphic image registration with cross-correlation: evaluating automated labeling of elderly and neurodegenerative brain},
	Volume = {12},
	Year = {2008},
	Bdsk-Url-1 = {https://doi.org/10.1016/j.media.2007.06.004}}

@article{Christensen:1996aa,
	Abstract = {A general automatic approach is presented for accommodating local shape variation when mapping a two-dimensional (2-D) or three-dimensional (3-D) template image into alignment with a topologically similar target image. Local shape variability is accommodated by applying a vector-field transformation to the underlying material coordinate system of the template while constraining the transformation to be smooth (globally positive definite Jacobian). Smoothness is guaranteed without specifically penalizing large-magnitude deformations of small subvolumes by constraining the transformation on the basis of a Stokesian limit of the fluid-dynamical Navier-Stokes equations. This differs fundamentally from quadratic penalty methods, such as those based on linearized elasticity or thin-plate splines, in that stress restraining the motion relaxes over time allowing large-magnitude deformations. Kinematic nonlinearities are inherently necessary to maintain continuity of structures during large-magnitude deformations, and are included in all results. After initial global registration, final mappings are obtained by numerically solving a set of nonlinear partial differential equations associated with the constrained optimization problem. Automatic regridding is performed by propagating templates as the nonlinear transformations evaluated on a finite lattice become singular. Application of the method to intersubject registration of neuroanatomical structures illustrates the ability to account for local anatomical variability.},
	Author = {Christensen, G E and Rabbitt, R D and Miller, M I},
	Date-Added = {2018-11-26 18:37:25 -0800},
	Date-Modified = {2018-11-26 18:37:25 -0800},
	Doi = {10.1109/83.536892},
	Journal = {IEEE Trans Image Process},
	Journal-Full = {IEEE transactions on image processing : a publication of the IEEE Signal Processing Society},
	Number = {10},
	Pages = {1435-47},
	Pmid = {18290061},
	Pst = {ppublish},
	Title = {Deformable templates using large deformation kinematics},
	Volume = {5},
	Year = {1996},
	Bdsk-Url-1 = {https://doi.org/10.1109/83.536892}}

@article{Beg:2005aa,
	Author = {M. Faisal Beg and Michael I. Miller and Alain Trouv{\'e} and Laurent Younes},
	Date-Added = {2018-11-26 13:05:53 -0800},
	Date-Modified = {2018-11-26 13:06:53 -0800},
	Journal = {International Journal of Computer Vision},
	Month = {February},
	Number = {2},
	Pages = {139--157},
	Title = {Computing Large Deformation Metric Mappings via Geodesic Flows of Diffeomorphisms},
	Volume = {61},
	Year = {2004}}

@article{Shams:2010aa,
	Author = {R. Shams and P. Sadeghi and R. A. Kennedy and R. I. Hartley},
	Date-Added = {2018-11-26 12:58:03 -0800},
	Date-Modified = {2018-11-26 13:00:41 -0800},
	Journal = {IEEE Signal Process Mag},
	Number = {2},
	Pages = {50--60},
	Title = {A survey of medical image registration on multicore and the GPU},
	Volume = {27},
	Year = {2010}}

@article{Vialard:2012aa,
	Author = {Fran{\c c}ois-Xavier Vialard and Laurent Risser and Daniel Rueckert and Colin J. Cotter},
	Date-Added = {2018-11-26 12:55:50 -0800},
	Date-Modified = {2018-11-26 12:57:08 -0800},
	Journal = {Int J Comput Vis},
	Pages = {229--241},
	Title = {Diffeomorphic 3D Image Registration via Geodesic Shooting Using an Efficient Adjoint Calculation},
	Volume = {97},
	Year = {2012}}

@inproceedings{Rohe:2017aa,
	Abstract = {In this paper, we propose an innovative approach for registration based on the deterministic prediction of the parameters from both images instead of the optimization of a energy criteria. The method relies on a fully convolutional network whose architecture consists of contracting layers to detect relevant features and a symmetric expanding path that matches them together and outputs the transformation parametrization. Whereas convolutional networks have seen a widespread expansion and have been already applied to many medical imaging problems such as segmentation and classification, its application to registration has so far faced the challenge of defining ground truth data on which to train the algorithm. Here, we present a novel training strategy to build reference deformations which relies on the registration of segmented regions of interest. We apply this methodology to the problem of inter-patient heart registration and show an important improvement over a state of the art optimization based algorithm. Not only our method is more accurate but it is also faster - registration of two 3D-images taking less than 30 ms second on a GPU - and more robust to outliers.},
	Address = {Cham},
	Author = {Roh{\'e}, Marc-Michel and Datar, Manasi and Heimann, Tobias and Sermesant, Maxime and Pennec, Xavier},
	Booktitle = {Medical Image Computing and Computer Assisted Intervention − MICCAI 2017},
	Date-Added = {2018-11-08 14:30:54 -0800},
	Date-Modified = {2018-11-08 14:31:01 -0800},
	Editor = {Descoteaux, Maxime and Maier-Hein, Lena and Franz, Alfred and Jannin, Pierre and Collins, D. Louis and Duchesne, Simon},
	Isbn = {978-3-319-66182-7},
	Pages = {266--274},
	Publisher = {Springer International Publishing},
	Title = {SVF-Net: Learning Deformable Image Registration Using Shape Matching},
	Year = {2017}}

@inproceedings{Sokooti:2017aa,
	Abstract = {In this paper we propose a method to solve nonrigid image registration through a learning approach, instead of via iterative optimization of a predefined dissimilarity metric. We design a Convolutional Neural Network (CNN) architecture that, in contrast to all other work, directly estimates the displacement vector field (DVF) from a pair of input images. The proposed RegNet is trained using a large set of artificially generated DVFs, does not explicitly define a dissimilarity metric, and integrates image content at multiple scales to equip the network with contextual information. At testing time nonrigid registration is performed in a single shot, in contrast to current iterative methods. We tested RegNet on 3D chest CT follow-up data. The results show that the accuracy of RegNet is on par with a conventional B-spline registration, for anatomy within the capture range. Training RegNet with artificially generated DVFs is therefore a promising approach for obtaining good results on real clinical data, thereby greatly simplifying the training problem. Deformable image registration can therefore be successfully casted as a learning problem.},
	Address = {Cham},
	Author = {Sokooti, Hessam and de Vos, Bob and Berendsen, Floris and Lelieveldt, Boudewijn P. F. and I{\v{s}}gum, Ivana and Staring, Marius},
	Booktitle = {Medical Image Computing and Computer Assisted Intervention − MICCAI 2017},
	Date-Added = {2018-11-08 14:26:19 -0800},
	Date-Modified = {2018-11-08 14:26:29 -0800},
	Editor = {Descoteaux, Maxime and Maier-Hein, Lena and Franz, Alfred and Jannin, Pierre and Collins, D. Louis and Duchesne, Simon},
	Isbn = {978-3-319-66182-7},
	Pages = {232--239},
	Publisher = {Springer International Publishing},
	Title = {Nonrigid Image Registration Using Multi-scale 3D Convolutional Neural Networks},
	Year = {2017}}

@article{Yang:2017aa,
	Abstract = {This paper introduces Quicksilver, a fast deformable image registration method. Quicksilver registration for image-pairs works by patch-wise prediction of a deformation model based directly on image appearance. A deep encoder-decoder network is used as the prediction model. While the prediction strategy is general, we focus on predictions for the Large Deformation Diffeomorphic Metric Mapping (LDDMM) model. Specifically, we predict the momentum-parameterization of LDDMM, which facilitates a patch-wise prediction strategy while maintaining the theoretical properties of LDDMM, such as guaranteed diffeomorphic mappings for sufficiently strong regularization. We also provide a probabilistic version of our prediction network which can be sampled during the testing time to calculate uncertainties in the predicted deformations. Finally, we introduce a new correction network which greatly increases the prediction accuracy of an already existing prediction network. We show experimental results for uni-modal atlas-to-image as well as uni-/multi-modal image-to-image registrations. These experiments demonstrate that our method accurately predicts registrations obtained by numerical optimization, is very fast, achieves state-of-the-art registration results on four standard validation datasets, and can jointly learn an image similarity measure. Quicksilver is freely available as an open-source software.},
	Author = {Yang, Xiao and Kwitt, Roland and Styner, Martin and Niethammer, Marc},
	Date-Added = {2018-11-08 14:16:53 -0800},
	Date-Modified = {2018-11-08 14:16:53 -0800},
	Doi = {10.1016/j.neuroimage.2017.07.008},
	Journal = {Neuroimage},
	Journal-Full = {NeuroImage},
	Keywords = {Brain imaging; Deep learning; Image registration},
	Mesh = {Algorithms; Brain; Brain Mapping; Humans; Image Processing, Computer-Assisted; Imaging, Three-Dimensional; Machine Learning; Pattern Recognition, Automated},
	Month = {09},
	Pages = {378-396},
	Pmc = {PMC6036629},
	Pmid = {28705497},
	Pst = {ppublish},
	Title = {Quicksilver: Fast predictive image registration - A deep learning approach},
	Volume = {158},
	Year = {2017},
	Bdsk-Url-1 = {https://doi.org/10.1016/j.neuroimage.2017.07.008}}

@article{Wu:2016aa,
	Abstract = {Feature selection is a critical step in deformable image registration. In particular, selecting the most discriminative features that accurately and concisely describe complex morphological patterns in image patches improves correspondence detection, which in turn improves image registration accuracy. Furthermore, since more and more imaging modalities are being invented to better identify morphological changes in medical imaging data, the development of deformable image registration method that scales well to new image modalities or new image applications with little to no human intervention would have a significant impact on the medical image analysis community. To address these concerns, a learning-based image registration framework is proposed that uses deep learning to discover compact and highly discriminative features upon observed imaging data. Specifically, the proposed feature selection method uses a convolutional stacked autoencoder to identify intrinsic deep feature representations in image patches. Since deep learning is an unsupervised learning method, no ground truth label knowledge is required. This makes the proposed feature selection method more flexible to new imaging modalities since feature representations can be directly learned from the observed imaging data in a very short amount of time. Using the LONI and ADNI imaging datasets, image registration performance was compared to two existing state-of-the-art deformable image registration methods that use handcrafted features. To demonstrate the scalability of the proposed image registration framework, image registration experiments were conducted on 7.0-T brain MR images. In all experiments, the results showed that the new image registration framework consistently demonstrated more accurate registration results when compared to state of the art.},
	Author = {Wu, Guorong and Kim, Minjeong and Wang, Qian and Munsell, Brent C and Shen, Dinggang},
	Date-Added = {2018-11-08 14:16:01 -0800},
	Date-Modified = {2018-11-08 14:16:01 -0800},
	Doi = {10.1109/TBME.2015.2496253},
	Journal = {IEEE Trans Biomed Eng},
	Journal-Full = {IEEE transactions on bio-medical engineering},
	Mesh = {Algorithms; Brain; Humans; Image Processing, Computer-Assisted; Magnetic Resonance Imaging; Unsupervised Machine Learning},
	Month = {07},
	Number = {7},
	Pages = {1505-16},
	Pmc = {PMC4853306},
	Pmid = {26552069},
	Pst = {ppublish},
	Title = {Scalable High-Performance Image Registration Framework by Unsupervised Deep Feature Representations Learning},
	Volume = {63},
	Year = {2016},
	Bdsk-Url-1 = {https://doi.org/10.1109/TBME.2015.2496253}}

@inproceedings{Wohlhart:2015aa,
	Author = {Paul Wohlhart and Vincent Lepetit},
	Bibsource = {dblp computer science bibliography, https://dblp.org},
	Biburl = {https://dblp.org/rec/bib/conf/cvpr/WohlhartL15},
	Booktitle = {{IEEE} Conference on Computer Vision and Pattern Recognition, {CVPR} 2015, Boston, MA, USA, June 7-12, 2015},
	Crossref = {DBLP:conf/cvpr/2015},
	Date-Added = {2018-11-08 14:14:57 -0800},
	Date-Modified = {2018-11-08 14:15:16 -0800},
	Doi = {10.1109/CVPR.2015.7298930},
	Pages = {3109--3118},
	Timestamp = {Thu, 25 May 2017 00:41:23 +0200},
	Title = {Learning descriptors for object recognition and 3D pose estimation},
	Url = {https://doi.org/10.1109/CVPR.2015.7298930},
	Year = {2015},
	Bdsk-Url-1 = {https://doi.org/10.1109/CVPR.2015.7298930}}

@inproceedings{Weinzaepfel:2013aa,
	Author = {P. Weinzaepfel and J. Revaud and Z. Harchaoui and C. Schmid},
	Booktitle = {2013 IEEE International Conference on Computer Vision},
	Date-Added = {2018-11-08 14:12:17 -0800},
	Date-Modified = {2018-11-08 14:12:29 -0800},
	Doi = {10.1109/ICCV.2013.175},
	Issn = {1550-5499},
	Keywords = {computer vision;convolution;image matching;image motion analysis;image retrieval;image sampling;image sequences;minimisation;smoothing methods;variational techniques;large displacement optical flow;deep matching;optical flow computation;computer vision systems;large displacement handling;DeepFlow algorithm;variational approach;descriptor matching algorithm;multistage architecture;interleaving convolutions;max-pooling;deep convolutional nets;dense sampling;quasidense correspondence retrieval;smoothing effect;energy minimization framework;optical flow estimation;MPI-Sintel dataset;Optical imaging;Integrated optics;Nonlinear optics;Optical filters;Adaptive optics;Estimation;Equations;optical flow;large displacements;dense matching;non-rigid matching;deep convolutional networks},
	Month = {Dec},
	Pages = {1385-1392},
	Title = {DeepFlow: Large Displacement Optical Flow with Deep Matching},
	Year = {2013},
	Bdsk-Url-1 = {https://doi.org/10.1109/ICCV.2013.175}}

@inproceedings{Uzunova:2017aa,
	Abstract = {Convolutional neural networks (CNNs) have been successfully used for fast and accurate estimation of dense correspondences between images in computer vision applications. However, much of their success is based on the availability of large training datasets with dense ground truth correspondences, which are only rarely available in medical applications. In this paper, we, therefore, address the problem of CNNs learning from few training data for medical image registration. Our contributions are threefold: (1) We present a novel approach for learning highly expressive appearance models from few training samples, (2) we show that this approach can be used to synthesize huge amounts of realistic ground truth training data for CNN-based medical image registration, and (3) we adapt the FlowNet architecture for CNN-based optical flow estimation to the medical image registration problem. This pipeline is applied to two medical data sets with less than 40 training images. We show that CNNs learned from the proposed generative model outperform those trained on random deformations or displacement fields estimated via classical image registration.},
	Address = {Cham},
	Author = {Uzunova, Hristina and Wilms, Matthias and Handels, Heinz and Ehrhardt, Jan},
	Booktitle = {Medical Image Computing and Computer Assisted Intervention − MICCAI 2017},
	Date-Added = {2018-11-08 14:09:20 -0800},
	Date-Modified = {2018-11-08 14:09:41 -0800},
	Editor = {Descoteaux, Maxime and Maier-Hein, Lena and Franz, Alfred and Jannin, Pierre and Collins, D. Louis and Duchesne, Simon},
	Isbn = {978-3-319-66182-7},
	Pages = {223--231},
	Publisher = {Springer International Publishing},
	Title = {Training CNNs for Image Registration from Few Samples with Model-based Data Augmentation},
	Year = {2017}}

@inproceedings{deVos:2017aa,
	Abstract = {In this work we propose a deep learning network for deformable image registration (DIRNet). The DIRNet consists of a convolutional neural network (ConvNet) regressor, a spatial transformer, and a resampler. The ConvNet analyzes a pair of fixed and moving images and outputs parameters for the spatial transformer, which generates the displacement vector field that enables the resampler to warp the moving image to the fixed image. The DIRNet is trained end-to-end by unsupervised optimization of a similarity metric between input image pairs. A trained DIRNet can be applied to perform registration on unseen image pairs in one pass, thus non-iteratively. Evaluation was performed with registration of images of handwritten digits (MNIST) and cardiac cine MR scans (Sunnybrook Cardiac Data). The results demonstrate that registration with DIRNet is as accurate as a conventional deformable image registration method with short execution times.},
	Address = {Cham},
	Author = {de Vos, Bob D. and Berendsen, Floris F. and Viergever, Max A. and Staring, Marius and I{\v{s}}gum, Ivana},
	Booktitle = {Deep Learning in Medical Image Analysis and Multimodal Learning for Clinical Decision Support},
	Date-Added = {2018-11-08 14:08:22 -0800},
	Date-Modified = {2018-11-08 14:08:33 -0800},
	Editor = {Cardoso, M. Jorge and Arbel, Tal and Carneiro, Gustavo and Syeda-Mahmood, Tanveer and Tavares, Jo{\~a}o Manuel R.S. and Moradi, Mehdi and Bradley, Andrew and Greenspan, Hayit and Papa, Jo{\~a}o Paulo and Madabhushi, Anant and Nascimento, Jacinto C. and Cardoso, Jaime S. and Belagiannis, Vasileios and Lu, Zhi},
	Isbn = {978-3-319-67558-9},
	Pages = {204--212},
	Publisher = {Springer International Publishing},
	Title = {End-to-End Unsupervised Deformable Image Registration with a Convolutional Neural Network},
	Year = {2017}}

@inproceedings{Sloan:2018aa,
	Author = {J. M. Sloan and K. A. Goatman and J. P. Siebert},
	Booktitle = {Proceedings of the 11th International Joint Conference on Biomedical Engineering Systems and Technologies (BIOSTEC 2018) - Volume 2: BIOIMAGING},
	Date-Added = {2018-11-08 14:01:48 -0800},
	Date-Modified = {2018-11-08 14:12:52 -0800},
	Pages = {89--99},
	Title = {Learning Rigid Image Registration - Utilizing Convolutional Neural Networks for Medical Image Registration},
	Year = {2018}}

@inproceedings{Sheikhjafari:2018aa,
	Author = {Ameneh Sheikhjafari and Michelle Noga and Kumaradevan Punithakumar and Nilanjan Ray},
	Booktitle = {Proceeings of Medical Imaging with Deep Learning},
	Date-Added = {2018-11-08 13:59:52 -0800},
	Date-Modified = {2018-11-08 14:13:01 -0800},
	Title = {Unsupervised Deformable Image Registration with Fully Connected Generative Neural Network},
	Year = {2018}}

@inproceedings{Sergeev:2012aa,
	Author = {Sergey Sergeev and Yang Zhao and Marius George Linguraru and Kazunori Okada,},
	Booktitle = {Proceeings of the SPIE},
	Date-Added = {2018-11-08 13:57:02 -0800},
	Date-Modified = {2018-11-08 14:13:07 -0800},
	Title = {Medical image registration using machine learning-based interest point detector},
	Year = {2012}}

@article{Miao:2016aa,
	Abstract = {In this paper, we present a Convolutional Neural Network (CNN) regression approach to address the two major limitations of existing intensity-based 2-D/3-D registration technology: 1) slow computation and 2) small capture range. Different from optimization-based methods, which iteratively optimize the transformation parameters over a scalar-valued metric function representing the quality of the registration, the proposed method exploits the information embedded in the appearances of the digitally reconstructed radiograph and X-ray images, and employs CNN regressors to directly estimate the transformation parameters. An automatic feature extraction step is introduced to calculate 3-D pose-indexed features that are sensitive to the variables to be regressed while robust to other factors. The CNN regressors are then trained for local zones and applied in a hierarchical manner to break down the complex regression task into multiple simpler sub-tasks that can be learned separately. Weight sharing is furthermore employed in the CNN regression model to reduce the memory footprint. The proposed approach has been quantitatively evaluated on 3 potential clinical applications, demonstrating its significant advantage in providing highly accurate real-time 2-D/3-D registration with a significantly enlarged capture range when compared to intensity-based methods.},
	Author = {Shun Miao and Wang, Z Jane and Rui Liao},
	Date-Added = {2018-11-08 13:53:54 -0800},
	Date-Modified = {2018-11-08 13:53:54 -0800},
	Doi = {10.1109/TMI.2016.2521800},
	Journal = {IEEE Trans Med Imaging},
	Journal-Full = {IEEE transactions on medical imaging},
	Mesh = {Arthroplasty, Replacement, Knee; Echocardiography, Transesophageal; Humans; Imaging, Three-Dimensional; Knee Joint; Machine Learning; Neural Networks (Computer); Radiography; Regression Analysis},
	Month = {05},
	Number = {5},
	Pages = {1352-1363},
	Pmid = {26829785},
	Pst = {ppublish},
	Title = {A CNN Regression Approach for Real-Time 2D/3D Registration},
	Volume = {35},
	Year = {2016},
	Bdsk-Url-1 = {https://doi.org/10.1109/TMI.2016.2521800}}

@conference{Liao:2017aa,
	Author = {Rui Liao and Shun Miao and Pierre de Tournemire and Sasa Grbic and Ali Kamen and Tommaso Mansi and Dorin Comaniciu},
	Booktitle = {Proceedings of the Thirty-First AAAI Conference on Artificial Intelligence},
	Date-Added = {2018-11-08 13:52:24 -0800},
	Date-Modified = {2018-11-08 13:53:26 -0800},
	Title = {An Artificial Agent for Robust Image Registration},
	Year = {2017}}

@conference{Eppenhof:2018aa,
	Author = {Koen A. J. Eppenhof and Maxime W. Lafarge and Pim Moeskops and Mitko Veta and Josien P. W. Pluim},
	Booktitle = {Proc. SPIE 10574, Medical Imaging 2018: Image Processing},
	Date-Added = {2018-11-08 13:49:08 -0800},
	Date-Modified = {2018-12-14 16:03:57 -0800},
	Title = {Deformable image registration using convolutional neural networks},
	Year = {2018}}

@article{Cao:2017aa,
	Abstract = {Existing deformable registration methods require exhaustively iterative optimization, along with careful parameter tuning, to estimate the deformation field between images. Although some learning-based methods have been proposed for initiating deformation estimation, they are often template-specific and not flexible in practical use. In this paper, we propose a convolutional neural network (CNN) based regression model to directly learn the complex mapping from the input image pair (i.e., a pair of template and subject) to their corresponding deformation field. Specifically, our CNN architecture is designed in a patch-based manner to learn the complex mapping from the input patch pairs to their respective deformation field. First, the equalized active-points guided sampling strategy is introduced to facilitate accurate CNN model learning upon a limited image dataset. Then, the similarity-steered CNN architecture is designed, where we propose to add the auxiliary contextual cue, i.e., the similarity between input patches, to more directly guide the learning process. Experiments on different brain image datasets demonstrate promising registration performance based on our CNN model. Furthermore, it is found that the trained CNN model from one dataset can be successfully transferred to another dataset, although brain appearances across datasets are quite variable.},
	Author = {Cao, Xiaohuan and Yang, Jianhua and Zhang, Jun and Nie, Dong and Kim, Min-Jeong and Wang, Qian and Shen, Dinggang},
	Date-Added = {2018-11-08 13:47:53 -0800},
	Date-Modified = {2018-11-08 13:47:53 -0800},
	Doi = {10.1007/978-3-319-66182-7_35},
	Journal = {Med Image Comput Comput Assist Interv},
	Journal-Full = {Medical image computing and computer-assisted intervention : MICCAI ... International Conference on Medical Image Computing and Computer-Assisted Intervention},
	Mesh = {Algorithms; Brain; Humans; Machine Learning; Neural Networks (Computer); Neuroimaging; Reproducibility of Results; Sensitivity and Specificity; Young Adult},
	Month = {Sep},
	Pages = {300-308},
	Pmc = {PMC5731783},
	Pmid = {29250613},
	Pst = {ppublish},
	Title = {Deformable Image Registration based on Similarity-Steered CNN Regression},
	Volume = {10433},
	Year = {2017},
	Bdsk-Url-1 = {https://doi.org/10.1007/978-3-319-66182-7_35}}

@conference{Jaderberg:2015aa,
	Author = {Max Jaderberg and Karen Simonyan and Andrew Zisserman and Koray Kavukcuoglu},
	Booktitle = {Neural Information Processing Systems 2015},
	Date-Added = {2018-11-08 13:45:45 -0800},
	Date-Modified = {2018-11-08 13:47:17 -0800},
	Title = {Spatial Transformer Networks},
	Year = {2015}}

@article{Hu:2018aa,
	Abstract = {One of the fundamental challenges in supervised learning for multimodal image registration is the lack of ground-truth for voxel-level spatial correspondence. This work describes a method to infer voxel-level transformation from higher-level correspondence information contained in anatomical labels. We argue that such labels are more reliable and practical to obtain for reference sets of image pairs than voxel-level correspondence. Typical anatomical labels of interest may include solid organs, vessels, ducts, structure boundaries and other subject-specific ad hoc landmarks. The proposed end-to-end convolutional neural network approach aims to predict displacement fields to align multiple labelled corresponding structures for individual image pairs during the training, while only unlabelled image pairs are used as the network input for inference. We highlight the versatility of the proposed strategy, for training, utilising diverse types of anatomical labels, which need not to be identifiable over all training image pairs. At inference, the resulting 3D deformable image registration algorithm runs in real-time and is fully-automated without requiring any anatomical labels or initialisation. Several network architecture variants are compared for registering T2-weighted magnetic resonance images and 3D transrectal ultrasound images from prostate cancer patients. A median target registration error of 3.6 mm on landmark centroids and a median Dice of 0.87 on prostate glands are achieved from cross-validation experiments, in which 108 pairs of multimodal images from 76 patients were tested with high-quality anatomical labels.},
	Author = {Hu, Yipeng and Modat, Marc and Gibson, Eli and Li, Wenqi and Ghavami, Nooshin and Bonmati, Ester and Wang, Guotai and Bandula, Steven and Moore, Caroline M and Emberton, Mark and Ourselin, S{\'e}bastien and Noble, J Alison and Barratt, Dean C and Vercauteren, Tom},
	Date-Added = {2018-11-08 13:44:50 -0800},
	Date-Modified = {2018-11-08 13:44:50 -0800},
	Doi = {10.1016/j.media.2018.07.002},
	Journal = {Med Image Anal},
	Journal-Full = {Medical image analysis},
	Keywords = {Convolutional neural network; Image-guided intervention; Medical image registration; Prostate cancer; Weakly-supervised learning},
	Month = {Oct},
	Pages = {1-13},
	Pmid = {30007253},
	Pst = {ppublish},
	Title = {Weakly-supervised convolutional neural networks for multimodal image registration},
	Volume = {49},
	Year = {2018},
	Bdsk-Url-1 = {https://doi.org/10.1016/j.media.2018.07.002}}

@inproceedings{Dosovitskiy:2015aa,
	Acmid = {2919957},
	Address = {Washington, DC, USA},
	Author = {Dosovitskiy, Alexey and Fischery, Philipp and Ilg, Eddy and Hausser, Philip and Hazirbas, Caner and Golkov, Vladimir and Smagt, Patrick van der and Cremers, Daniel and Brox, Thomas},
	Booktitle = {Proceedings of the 2015 IEEE International Conference on Computer Vision (ICCV)},
	Date-Added = {2018-11-08 13:44:01 -0800},
	Date-Modified = {2018-11-08 13:44:08 -0800},
	Doi = {10.1109/ICCV.2015.316},
	Isbn = {978-1-4673-8391-2},
	Numpages = {9},
	Pages = {2758--2766},
	Publisher = {IEEE Computer Society},
	Series = {ICCV '15},
	Title = {FlowNet: Learning Optical Flow with Convolutional Networks},
	Url = {http://dx.doi.org/10.1109/ICCV.2015.316},
	Year = {2015},
	Bdsk-Url-1 = {http://dx.doi.org/10.1109/ICCV.2015.316}}

@inproceedings{Dalca:2018aa,
	Abstract = {Traditional deformable registration techniques achieve impressive results and offer a rigorous theoretical treatment, but are computationally intensive since they solve an optimization problem for each image pair. Recently, learning-based methods have facilitated fast registration by learning spatial deformation functions. However, these approaches use restricted deformation models, require supervised labels, or do not guarantee a diffeomorphic (topology-preserving) registration. Furthermore, learning-based registration tools have not been derived from a probabilistic framework that can offer uncertainty estimates. In this paper, we present a probabilistic generative model and derive an unsupervised learning-based inference algorithm that makes use of recent developments in convolutional neural networks (CNNs). We demonstrate our method on a 3D brain registration task, and provide an empirical analysis of the algorithm. Our approach results in state of the art accuracy and very fast runtimes, while providing diffeomorphic guarantees and uncertainty estimates. Our implementation is available online at http://voxelmorph.csail.mit.edu.},
	Address = {Cham},
	Author = {Dalca, Adrian V. and Balakrishnan, Guha and Guttag, John and Sabuncu, Mert R.},
	Booktitle = {Medical Image Computing and Computer Assisted Intervention -- MICCAI 2018},
	Date-Added = {2018-11-08 13:39:10 -0800},
	Date-Modified = {2018-11-08 13:39:29 -0800},
	Editor = {Frangi, Alejandro F. and Schnabel, Julia A. and Davatzikos, Christos and Alberola-L{\'o}pez, Carlos and Fichtinger, Gabor},
	Isbn = {978-3-030-00928-1},
	Pages = {729--738},
	Publisher = {Springer International Publishing},
	Title = {Unsupervised Learning for Fast Probabilistic Diffeomorphic Registration},
	Year = {2018}}

@article{Bermudez:2018aa,
	Abstract = {An important task in image processing and neuroimaging is to extract quantitative information from the acquired images in order to make observations about the presence of disease or markers of development in populations. Having a low-dimensional manifold of an image allows for easier statistical comparisons between groups and the synthesis of group representatives. Previous studies have sought to identify the best mapping of brain MRI to a low-dimensional manifold, but have been limited by assumptions of explicit similarity measures. In this work, we use deep learning techniques to investigate implicit manifolds of normal brains and generate new, high-quality images. We explore implicit manifolds by addressing the problems of image synthesis and image denoising as important tools in manifold learning. First, we propose the unsupervised synthesis of T1-weighted brain MRI using a Generative Adversarial Network (GAN) by learning from 528 examples of 2D axial slices of brain MRI. Synthesized images were first shown to be unique by performing a cross-correlation with the training set. Real and synthesized images were then assessed in a blinded manner by two imaging experts providing an image quality score of 1-5. The quality score of the synthetic image showed substantial overlap with that of the real images. Moreover, we use an autoencoder with skip connections for image denoising, showing that the proposed method results in higher PSNR than FSL SUSAN after denoising. This work shows the power of artificial networks to synthesize realistic imaging data, which can be used to improve image processing techniques and provide a quantitative framework to structural changes in the brain.},
	Author = {Bermudez, Camilo and Plassard, Andrew J and Davis, Taylor L and Newton, Allen T and Resnick, Susan M and Landman, Bennett A},
	Date-Added = {2018-11-08 13:36:22 -0800},
	Date-Modified = {2018-11-08 13:36:22 -0800},
	Doi = {10.1117/12.2293515},
	Journal = {Proc SPIE Int Soc Opt Eng},
	Journal-Full = {Proceedings of SPIE--the International Society for Optical Engineering},
	Keywords = {Manifold learning; brain MRI; deep neural networks; generative adversarial networks; image synthesis},
	Month = {Mar},
	Pmc = {PMC5990281},
	Pmid = {29887659},
	Pst = {ppublish},
	Title = {Learning Implicit Brain MRI Manifolds with Deep Learning},
	Volume = {10574},
	Year = {2018},
	Bdsk-Url-1 = {https://doi.org/10.1117/12.2293515}}

@conference{Balakrishnan:2018aa,
	Author = {Guha Balakrishnan and Amy Zhao and Mert R. Sabuncu and John Guttag and Adrian V. Dalca},
	Booktitle = {IEEE CVPR: Conf. on Computer Vision and Pattern Recognition},
	Date-Added = {2018-11-08 13:28:08 -0800},
	Date-Modified = {2018-11-08 13:36:34 -0800},
	Title = {An Unsupervised Learning Model for Deformable Medical Image Registration},
	Year = {2018}}
