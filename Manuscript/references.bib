%% This BibTeX bibliography file was created using BibDesk.
%% http://bibdesk.sourceforge.net/

%% Created for Nicholas Tustison at 2018-12-10 15:48:37 -0800 


%% Saved with string encoding Unicode (UTF-8) 



@webpage{imageNetKaggle,
	Date-Added = {2018-12-10 15:48:35 -0800},
	Date-Modified = {2018-12-10 15:48:35 -0800},
	Lastchecked = {Dec. 10, 2018},
	Url = {https://www.kaggle.com/c/imagenet-object-localization-challenge},
	Bdsk-Url-1 = {https://www.kaggle.com/c/imagenet-object-localization-challenge}}

@article{He:2015,
	Archiveprefix = {arXiv},
	Author = {Kaiming He and Xiangyu Zhang and Shaoqing Ren and Jian Sun},
	Bibsource = {dblp computer science bibliography, https://dblp.org},
	Biburl = {https://dblp.org/rec/bib/journals/corr/HeZRS15},
	Date-Added = {2018-12-10 14:19:21 -0800},
	Date-Modified = {2018-12-10 14:19:21 -0800},
	Eprint = {1512.03385},
	Journal = {CoRR},
	Timestamp = {Wed, 07 Jun 2017 14:41:17 +0200},
	Title = {Deep Residual Learning for Image Recognition},
	Url = {http://arxiv.org/abs/1512.03385},
	Volume = {abs/1512.03385},
	Year = {2015},
	Bdsk-Url-1 = {http://arxiv.org/abs/1512.03385}}

@article{Szegedy:2015,
	Archiveprefix = {arXiv},
	Author = {Christian Szegedy and Vincent Vanhoucke and Sergey Ioffe and Jonathon Shlens and Zbigniew Wojna},
	Bibsource = {dblp computer science bibliography, https://dblp.org},
	Biburl = {https://dblp.org/rec/bib/journals/corr/SzegedyVISW15},
	Date-Added = {2018-12-08 20:37:54 -0800},
	Date-Modified = {2018-12-08 20:37:54 -0800},
	Eprint = {1512.00567},
	Journal = {CoRR},
	Timestamp = {Wed, 07 Jun 2017 14:40:22 +0200},
	Title = {Rethinking the Inception Architecture for Computer Vision},
	Url = {http://arxiv.org/abs/1512.00567},
	Volume = {abs/1512.00567},
	Year = {2015},
	Bdsk-Url-1 = {http://arxiv.org/abs/1512.00567}}

@article{Simonyan:2014,
	Archiveprefix = {arXiv},
	Author = {Karen Simonyan and Andrew Zisserman},
	Bibsource = {dblp computer science bibliography, https://dblp.org},
	Biburl = {https://dblp.org/rec/bib/journals/corr/SimonyanZ14a},
	Date-Added = {2018-12-08 20:37:09 -0800},
	Date-Modified = {2018-12-08 20:37:09 -0800},
	Eprint = {1409.1556},
	Journal = {CoRR},
	Timestamp = {Wed, 07 Jun 2017 14:41:51 +0200},
	Title = {Very Deep Convolutional Networks for Large-Scale Image Recognition},
	Url = {http://arxiv.org/abs/1409.1556},
	Volume = {abs/1409.1556},
	Year = {2014},
	Bdsk-Url-1 = {http://arxiv.org/abs/1409.1556}}

@article{Russakovsky:2015aa,
	Author = {Olga Russakovsky and Jia Deng and Hao Su and Jonathan Krause and Sanjeev Satheesh and Sean Ma and Zhiheng Huang and Andrej Karpathy and Aditya Khosla and Michael Bernstein and Alexander C. Berg and Li Fei-Fei},
	Date-Added = {2018-12-08 20:34:23 -0800},
	Date-Modified = {2018-12-08 20:34:23 -0800},
	Journal = {International Journal of Computer Vision},
	Month = {December},
	Number = {3},
	Pages = {211-252},
	Title = {{ImageNet} Large Scale Visual Recognition Challenge},
	Volume = {115},
	Year = {2015}}

@inproceedings{Ronneberger:2015aa,
	Author = {Olaf Ronneberger and Philipp Fischer and Thomas Brox},
	Booktitle = {Proceedings of the International Conference on Medical Image Computing and Computer-Assisted Intervention},
	Date-Added = {2018-12-08 20:34:19 -0800},
	Date-Modified = {2018-12-08 20:34:19 -0800},
	Pages = {234-241},
	Publisher = {Springer},
	Series = {LNCS},
	Title = {U-Net: Convolutional Networks for Biomedical Image Segmentation},
	Volume = {9351},
	Year = {2015}}

@inproceedings{Krizhevsky:2012,
	Acmid = {2999257},
	Address = {USA},
	Author = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E.},
	Booktitle = {Proceedings of the 25th International Conference on Neural Information Processing Systems - Volume 1},
	Date-Added = {2018-12-08 20:33:50 -0800},
	Date-Modified = {2018-12-08 20:33:50 -0800},
	Location = {Lake Tahoe, Nevada},
	Numpages = {9},
	Pages = {1097--1105},
	Publisher = {Curran Associates Inc.},
	Series = {NIPS'12},
	Title = {ImageNet Classification with Deep Convolutional Neural Networks},
	Url = {http://dl.acm.org/citation.cfm?id=2999134.2999257},
	Year = {2012},
	Bdsk-Url-1 = {http://dl.acm.org/citation.cfm?id=2999134.2999257}}

@inproceedings{Waibel:1987aa,
	Author = {Alex Waibel},
	Booktitle = {Meeting of the Institute of Electrical, Information and Communication Engineers (IEICE).},
	Date-Added = {2018-12-08 19:05:03 -0800},
	Date-Modified = {2018-12-08 19:05:52 -0800},
	Title = {Phoneme Recognition Using Time-Delay Neural Networks},
	Year = {1987}}

@article{Hubel:1962aa,
	Author = {D. H. Hubel and T. N. Wiesel},
	Date-Added = {2018-12-08 18:42:46 -0800},
	Date-Modified = {2018-12-08 18:43:37 -0800},
	Journal = {J Physiol},
	Journal-Full = {The Journal of physiology},
	Keywords = {CEREBRAL CORTEX/physiology},
	Mesh = {Animals; Cats; Cerebral Cortex; Visual Cortex},
	Month = {Jan},
	Pages = {106-54},
	Pmc = {PMC1359523},
	Pmid = {14449617},
	Pst = {ppublish},
	Title = {Receptive fields, binocular interaction and functional architecture in the cat's visual cortex},
	Volume = {160},
	Year = {1962}}

@article{LeCun:1989aa,
	Author = {Y. LeCun and B. Boser and J. S. Denker and D. Henderson and R. E. Howard and W. Hubbard and L. D. Jacke},
	Date-Added = {2018-12-08 18:38:39 -0800},
	Date-Modified = {2018-12-08 18:40:03 -0800},
	Journal = {Neural Computation},
	Number = {4},
	Pages = {541--551},
	Title = {Backpropagation Applied to Handwritten Zip Code Recognition},
	Volume = {1},
	Year = {1989}}

@article{LeCun:2015aa,
	Abstract = {Deep learning allows computational models that are composed of multiple processing layers to learn representations of data with multiple levels of abstraction. These methods have dramatically improved the state-of-the-art in speech recognition, visual object recognition, object detection and many other domains such as drug discovery and genomics. Deep learning discovers intricate structure in large data sets by using the backpropagation algorithm to indicate how a machine should change its internal parameters that are used to compute the representation in each layer from the representation in the previous layer. Deep convolutional nets have brought about breakthroughs in processing images, video, speech and audio, whereas recurrent nets have shone light on sequential data such as text and speech. },
	Author = {LeCun, Yann and Bengio, Yoshua and Hinton, Geoffrey},
	Date-Added = {2018-12-08 18:32:49 -0800},
	Date-Modified = {2018-12-08 18:33:14 -0800},
	Doi = {10.1038/nature14539},
	Journal = {Nature},
	Journal-Full = {Nature},
	Mesh = {Algorithms; Artificial Intelligence; Computers; Language; Neural Networks (Computer)},
	Month = {May},
	Number = {7553},
	Pages = {436-44},
	Pmid = {26017442},
	Pst = {ppublish},
	Title = {Deep learning},
	Volume = {521},
	Year = {2015},
	Bdsk-Url-1 = {https://doi.org/10.1038/nature14539}}

@article{Fukushima:1980aa,
	Abstract = {A neural network model for a mechanism of visual pattern recognition is proposed in this paper. The network is self-organized by "learning without a teacher", and acquires an ability to recognize stimulus patterns based on the geometrical similarity (Gestalt) of their shapes without affected by their positions. This network is given a nickname "neocognitron". After completion of self-organization, the network has a structure similar to the hierarchy model of the visual nervous system proposed by Hubel and Wiesel. The network consists of an input layer (photoreceptor array) followed by a cascade connection of a number of modular structures, each of which is composed of two layers of cells connected in a cascade. The first layer of each module consists of "S-cells", which show characteristics similar to simple cells or lower order hypercomplex cells, and the second layer consists of "C-cells" similar to complex cells or higher order hypercomplex cells. The afferent synapses to each S-cell have plasticity and are modifiable. The network has an ability of unsupervised learning: We do not need any "teacher" during the process of self-organization, and it is only needed to present a set of stimulus patterns repeatedly to the input layer of the network. The network has been simulated on a digital computer. After repetitive presentation of a set of stimulus patterns, each stimulus pattern has become to elicit an output only from one of the C-cells of the last layer, and conversely, this C-cell has become selectively responsive only to that stimulus pattern. That is, none of the C-cells of the last layer responds to more than one stimulus pattern. The response of the C-cells of the last layer is not affected by the pattern's position at all. Neither is it affected by a small change in shape nor in size of the stimulus pattern.},
	Author = {Fukushima, K},
	Date-Added = {2018-12-08 18:19:32 -0800},
	Date-Modified = {2018-12-08 18:19:32 -0800},
	Journal = {Biol Cybern},
	Journal-Full = {Biological cybernetics},
	Mesh = {Cognition; Computers; Form Perception; Learning; Models, Neurological; Nerve Net; Nervous System Physiological Phenomena; Pattern Recognition, Visual},
	Number = {4},
	Pages = {193-202},
	Pmid = {7370364},
	Pst = {ppublish},
	Title = {Neocognitron: a self organizing neural network model for a mechanism of pattern recognition unaffected by shift in position},
	Volume = {36},
	Year = {1980}}

@article{Ivakhnenko:1971aa,
	Author = {A. G. Ivakhnenko},
	Date-Added = {2018-12-08 18:05:08 -0800},
	Date-Modified = {2018-12-08 18:08:03 -0800},
	Journal = {IEEE Transactions on Systems, Man, and Cybernetics},
	Month = {Oct},
	Number = {4},
	Pages = {364--378},
	Title = {Polynomial Theory of Complex Systems},
	Volume = {SMC-1},
	Year = {1971}}

@article{Pluim:2003aa,
	Abstract = {An overview is presented of the medical image processing literature on mutual-information-based registration. The aim of the survey is threefold: an introduction for those new to the field, an overview for those working in the field, and a reference for those searching for literature on a specific application. Methods are classified according to the different aspects of mutual-information-based registration. The main division is in aspects of the methodology and of the application. The part on methodology describes choices made on facets such as preprocessing of images, gray value interpolation, optimization, adaptations to the mutual information measure, and different types of geometrical transformations. The part on applications is a reference of the literature available on different modalities, on interpatient registration and on different anatomical objects. Comparison studies including mutual information are also considered. The paper starts with a description of entropy and mutual information and it closes with a discussion on past achievements and some future challenges.},
	Author = {Pluim, Josien P W and Maintz, J B Antoine and Viergever, Max A},
	Date-Added = {2018-12-06 21:14:24 -0800},
	Date-Modified = {2018-12-06 21:14:24 -0800},
	Doi = {10.1109/TMI.2003.815867},
	Journal = {IEEE Trans Med Imaging},
	Journal-Full = {IEEE transactions on medical imaging},
	Mesh = {Algorithms; Anatomy, Cross-Sectional; Humans; Image Enhancement; Image Interpretation, Computer-Assisted; Imaging, Three-Dimensional; Pattern Recognition, Automated; Subtraction Technique},
	Month = {Aug},
	Number = {8},
	Pages = {986-1004},
	Pmid = {12906253},
	Pst = {ppublish},
	Title = {Mutual-information-based registration of medical images: a survey},
	Volume = {22},
	Year = {2003},
	Bdsk-Url-1 = {https://doi.org/10.1109/TMI.2003.815867}}

@article{Gholipour:2007aa,
	Abstract = {Functional localization is a concept which involves the application of a sequence of geometrical and statistical image processing operations in order to define the location of brain activity or to produce functional/parametric maps with respect to the brain structure or anatomy. Considering that functional brain images do not normally convey detailed structural information and, thus, do not present an anatomically specific localization of functional activity, various image registration techniques are introduced in the literature for the purpose of mapping functional activity into an anatomical image or a brain atlas. The problems addressed by these techniques differ depending on the application and the type of analysis, i.e., single-subject versus group analysis. Functional to anatomical brain image registration is the core part of functional localization in most applications and is accompanied by intersubject and subject-to-atlas registration for group analysis studies. Cortical surface registration and automatic brain labeling are some of the other tools towards establishing a fully automatic functional localization procedure. While several previous survey papers have reviewed and classified general-purpose medical image registration techniques, this paper provides an overview of brain functional localization along with a survey and classification of the image registration techniques related to this problem.},
	Author = {Gholipour, Ali and Kehtarnavaz, Nasser and Briggs, Richard and Devous, Michael and Gopinath, Kaundinya},
	Date-Added = {2018-12-06 21:12:34 -0800},
	Date-Modified = {2018-12-06 21:12:34 -0800},
	Doi = {10.1109/TMI.2007.892508},
	Journal = {IEEE Trans Med Imaging},
	Journal-Full = {IEEE transactions on medical imaging},
	Mesh = {Algorithms; Artificial Intelligence; Brain; Brain Mapping; Cluster Analysis; Evoked Potentials; Humans; Image Enhancement; Image Interpretation, Computer-Assisted; Imaging, Three-Dimensional; Magnetic Resonance Imaging; Pattern Recognition, Automated; Reproducibility of Results; Sensitivity and Specificity; Subtraction Technique},
	Month = {Apr},
	Number = {4},
	Pages = {427-51},
	Pmid = {17427731},
	Pst = {ppublish},
	Title = {Brain functional localization: a survey of image registration techniques},
	Volume = {26},
	Year = {2007},
	Bdsk-Url-1 = {https://doi.org/10.1109/TMI.2007.892508}}

@article{Maintz:1998aa,
	Abstract = {The purpose of this paper is to present a survey of recent (published in 1993 or later) publications concerning medical image registration techniques. These publications will be classified according to a model based on nine salient criteria, the main dichotomy of which is extrinsic versus intrinsic methods. The statistics of the classification show definite trends in the evolving registration techniques, which will be discussed. At this moment, the bulk of interesting intrinsic methods is based on either segmented points or surfaces, or on techniques endeavouring to use the full information content of the images involved.},
	Author = {Maintz, J B and Viergever, M A},
	Date-Added = {2018-12-06 21:11:12 -0800},
	Date-Modified = {2018-12-06 21:11:12 -0800},
	Journal = {Med Image Anal},
	Journal-Full = {Medical image analysis},
	Mesh = {Abdomen; Diagnostic Imaging; Extremities; Head; Humans; Pelvis; Reproducibility of Results; Spine; Thorax},
	Month = {Mar},
	Number = {1},
	Pages = {1-36},
	Pmid = {10638851},
	Pst = {ppublish},
	Title = {A survey of medical image registration},
	Volume = {2},
	Year = {1998}}

@article{Brown:1992,
	Acmid = {146374},
	Address = {New York, NY, USA},
	Author = {Brown, Lisa Gottesfeld},
	Date-Added = {2018-12-06 21:08:51 -0800},
	Date-Modified = {2018-12-06 21:09:04 -0800},
	Doi = {10.1145/146370.146374},
	Issn = {0360-0300},
	Issue_Date = {Dec. 1992},
	Journal = {ACM Comput. Surv.},
	Keywords = {image registration, image warping, rectification, template matching},
	Month = dec,
	Number = {4},
	Numpages = {52},
	Pages = {325--376},
	Publisher = {ACM},
	Title = {A Survey of Image Registration Techniques},
	Url = {http://doi.acm.org/10.1145/146370.146374},
	Volume = {24},
	Year = {1992},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/146370.146374},
	Bdsk-Url-2 = {https://doi.org/10.1145/146370.146374}}

@article{Keszei:2017aa,
	Abstract = {We catalogue available software solutions for non-rigid image registration to support scientists in selecting suitable tools for specific medical registration purposes. Registration tools were identified using non-systematic search in Pubmed, Web of Science, IEEE Xplore{\textregistered} Digital Library, Google Scholar, and through references in identified sources (n = 22). Exclusions are due to unavailability or inappropriateness. The remaining (n = 18) tools were classified by (i) access and technology, (ii) interfaces and application, (iii) living community, (iv) supported file formats, and (v) types of registration methodologies emphasizing the similarity measures implemented. Out of the 18 tools, (i) 12 are open source, 8 are released under a permissive free license, which imposes the least restrictions on the use and further development of the tool, 8 provide graphical processing unit (GPU) support; (ii) 7 are built on software platforms, 5 were developed for brain image registration; (iii) 6 are under active development but only 3 have had their last update in 2015 or 2016; (iv) 16 support the Analyze format, while 7 file formats can be read with only one of the tools; and (v) 6 provide multiple registration methods and 6 provide landmark-based registration methods. Based on open source, licensing, GPU support, active community, several file formats, algorithms, and similarity measures, the tools Elastics and Plastimatch are chosen for the platform ITK and without platform requirements, respectively. Researchers in medical image analysis already have a large choice of registration tools freely available. However, the most recently published algorithms may not be included in the tools, yet.},
	Author = {Keszei, Andr{\'a}s P and Berkels, Benjamin and Deserno, Thomas M},
	Date-Added = {2018-12-06 21:07:25 -0800},
	Date-Modified = {2018-12-06 21:07:25 -0800},
	Doi = {10.1007/s10278-016-9915-8},
	Journal = {J Digit Imaging},
	Journal-Full = {Journal of digital imaging},
	Keywords = {Image alignment; Image analysis; Image registration; Open-source software; Public domain software; Software tool},
	Mesh = {Algorithms; Brain; Humans; Radiology Information Systems; Software; Surveys and Questionnaires; User-Computer Interface},
	Month = {02},
	Number = {1},
	Pages = {102-116},
	Pmc = {PMC5267604},
	Pmid = {27730414},
	Pst = {ppublish},
	Title = {Survey of Non-Rigid Registration Tools in Medicine},
	Volume = {30},
	Year = {2017},
	Bdsk-Url-1 = {https://doi.org/10.1007/s10278-016-9915-8}}

@article{Viergever:2016aa,
	Abstract = {A retrospective view on the past two decades of the field of medical image registration is presented, guided by the article "A survey of medical image registration" (Maintz and Viergever, 1998). It shows that the classification of the field introduced in that article is still usable, although some modifications to do justice to advances in the field would be due. The main changes over the last twenty years are the shift from extrinsic to intrinsic registration, the primacy of intensity-based registration, the breakthrough of nonlinear registration, the progress of inter-subject registration, and the availability of generic image registration software packages. Two problems that were called urgent already 20 years ago, are even more urgent nowadays: Validation of registration methods, and translation of results of image registration research to clinical practice. It may be concluded that the field of medical image registration has evolved, but still is in need of further development in various aspects.},
	Author = {Viergever, Max A and Maintz, J B Antoine and Klein, Stefan and Murphy, Keelin and Staring, Marius and Pluim, Josien P W},
	Date-Added = {2018-12-06 21:05:51 -0800},
	Date-Modified = {2018-12-06 21:05:51 -0800},
	Doi = {10.1016/j.media.2016.06.030},
	Journal = {Med Image Anal},
	Journal-Full = {Medical image analysis},
	Keywords = {Medical image registration},
	Mesh = {Algorithms; Humans; Image Processing, Computer-Assisted; Retrospective Studies},
	Month = {10},
	Pages = {140-144},
	Pmid = {27427472},
	Pst = {ppublish},
	Title = {A survey of medical image registration - under review},
	Volume = {33},
	Year = {2016},
	Bdsk-Url-1 = {https://doi.org/10.1016/j.media.2016.06.030}}

@article{Avants:2010aa,
	Abstract = {We use a new, unsupervised multivariate imaging and analysis strategy to identify related patterns of reduced white matter integrity, measured with the fractional anisotropy (FA) derived from diffusion tensor imaging (DTI), and decreases in cortical thickness, measured by high resolution T1-weighted imaging, in Alzheimer's disease (AD) and frontotemporal dementia (FTD). This process is based on a novel computational model derived from sparse canonical correlation analysis (SCCA) that allows us to automatically identify mutually predictive, distributed neuroanatomical regions from different imaging modalities. We apply the SCCA model to a dataset that includes 23 control subjects that are demographically matched to 49 subjects with autopsy or CSF-biomarker-diagnosed AD (n=24) and FTD (n=25) with both DTI and T1-weighted structural imaging. SCCA shows that the FTD-related frontal and temporal degeneration pattern is correlated across modalities with permutation corrected p<0.0005. In AD, we find significant association between cortical thinning and reduction in white matter integrity within a distributed parietal and temporal network (p<0.0005). Furthermore, we show that-within SCCA identified regions-significant differences exist between FTD and AD cortical-connective degeneration patterns. We validate these distinct, multimodal imaging patterns by showing unique relationships with cognitive measures in AD and FTD. We conclude that SCCA is a potentially valuable approach in image analysis that can be applied productively to distinguishing between neurodegenerative conditions.},
	Author = {Avants, Brian B and Cook, Philip A and Ungar, Lyle and Gee, James C and Grossman, Murray},
	Date-Added = {2018-12-06 20:45:59 -0800},
	Date-Modified = {2018-12-06 20:45:59 -0800},
	Doi = {10.1016/j.neuroimage.2010.01.041},
	Journal = {Neuroimage},
	Journal-Full = {NeuroImage},
	Mesh = {Alzheimer Disease; Anisotropy; Biomarkers; Brain; Cerebral Cortex; Computer Simulation; Databases, Factual; Dementia; Diffusion Tensor Imaging; Female; Frontotemporal Dementia; Humans; Image Processing, Computer-Assisted; Magnetic Resonance Imaging; Male; Middle Aged; Models, Neurological; Multivariate Analysis; Nerve Fibers, Myelinated; Organ Size},
	Month = {Apr},
	Number = {3},
	Pages = {1004-16},
	Pmc = {PMC2953719},
	Pmid = {20083207},
	Pst = {ppublish},
	Title = {Dementia induces correlated reductions in white matter integrity and cortical thickness: a multivariate neuroimaging study with sparse canonical correlation analysis},
	Volume = {50},
	Year = {2010},
	Bdsk-Url-1 = {https://doi.org/10.1016/j.neuroimage.2010.01.041}}

@article{Iglesias:2015aa,
	Abstract = {Multi-atlas segmentation (MAS), first introduced and popularized by the pioneering work of Rohlfing, et al. (2004), Klein, et al. (2005), and Heckemann, et al. (2006), is becoming one of the most widely-used and successful image segmentation techniques in biomedical applications. By manipulating and utilizing the entire dataset of "atlases" (training images that have been previously labeled, e.g., manually by an expert), rather than some model-based average representation, MAS has the flexibility to better capture anatomical variation, thus offering superior segmentation accuracy. This benefit, however, typically comes at a high computational cost. Recent advancements in computer hardware and image processing software have been instrumental in addressing this challenge and facilitated the wide adoption of MAS. Today, MAS has come a long way and the approach includes a wide array of sophisticated algorithms that employ ideas from machine learning, probabilistic modeling, optimization, and computer vision, among other fields. This paper presents a survey of published MAS algorithms and studies that have applied these methods to various biomedical problems. In writing this survey, we have three distinct aims. Our primary goal is to document how MAS was originally conceived, later evolved, and now relates to alternative methods. Second, this paper is intended to be a detailed reference of past research activity in MAS, which now spans over a decade (2003-2014) and entails novel methodological developments and application-specific solutions. Finally, our goal is to also present a perspective on the future of MAS, which, we believe, will be one of the dominant approaches in biomedical image segmentation.},
	Author = {Iglesias, Juan Eugenio and Sabuncu, Mert R},
	Date-Added = {2018-12-06 20:22:39 -0800},
	Date-Modified = {2018-12-06 20:22:39 -0800},
	Doi = {10.1016/j.media.2015.06.012},
	Journal = {Med Image Anal},
	Journal-Full = {Medical image analysis},
	Keywords = {Label fusion; Multi-atlas segmentation; Survey},
	Mesh = {Algorithms; Humans; Image Interpretation, Computer-Assisted; Pattern Recognition, Automated; Reproducibility of Results; Sensitivity and Specificity; Subtraction Technique},
	Month = {Aug},
	Number = {1},
	Pages = {205-219},
	Pmc = {PMC4532640},
	Pmid = {26201875},
	Pst = {ppublish},
	Title = {Multi-atlas segmentation of biomedical images: A survey},
	Volume = {24},
	Year = {2015},
	Bdsk-Url-1 = {https://doi.org/10.1016/j.media.2015.06.012}}

@article{Singh:2013aa,
	Abstract = {This paper presents a novel approach for diffeomorphic image regression and atlas estimation that results in improved convergence and numerical stability. We use a vector momenta representation of a diffeomorphism's initial conditions instead of the standard scalar momentum that is typically used. The corresponding variational problem results in a closed-form update for template estimation in both the geodesic regression and atlas estimation problems. While we show that the theoretical optimal solution is equivalent to the scalar momenta case, the simplification of the optimization problem leads to more stable and efficient estimation in practice. We demonstrate the effectiveness of our method for atlas estimation and geodesic regression using synthetically generated shapes and 3D MRI brain scans.},
	Author = {Singh, Nikhil and Hinkle, Jacob and Joshi, Sarang and Fletcher, P Thomas},
	Date-Added = {2018-11-26 20:18:45 -0800},
	Date-Modified = {2018-11-26 20:19:50 -0800},
	Doi = {10.1109/ISBI.2013.6556700},
	Journal = {Proc IEEE Int Symp Biomed Imaging},
	Journal-Full = {Proceedings. IEEE International Symposium on Biomedical Imaging},
	Keywords = {Atlas; Geodesic regression; LDDMM; Vector Momentum},
	Month = {Apr},
	Pages = {1219-1222},
	Pmc = {PMC4232950},
	Pmid = {25404997},
	Pst = {ppublish},
	Title = {A Vector Momenta Formulation of Diffeomorphisms for Improved Geodesic Regression And Atlas Construction},
	Volume = {2013},
	Year = {2013},
	Bdsk-Url-1 = {https://doi.org/10.1109/ISBI.2013.6556700}}

@article{Miller:2006aa,
	Abstract = {Studying large deformations with a Riemannian approach has been an efficient point of view to generate metrics between deformable objects, and to provide accurate, non ambiguous and smooth matchings between images. In this paper, we study the geodesics of such large deformation diffeomorphisms, and more precisely, introduce a fundamental property that they satisfy, namely the conservation of momentum. This property allows us to generate and store complex deformations with the help of one initial "momentum" which serves as the initial state of a differential equation in the group of diffeomorphisms. Moreover, it is shown that this momentum can be also used for describing a deformation of given visual structures, like points, contours or images, and that, it has the same dimension as the described object, as a consequence of the normal momentum constraint we introduce.},
	Author = {Miller, Michael I and Trouv{\'e}, Alain and Younes, Laurent},
	Date-Added = {2018-11-26 18:55:31 -0800},
	Date-Modified = {2018-11-26 18:55:31 -0800},
	Doi = {10.1007/s10851-005-3624-0},
	Journal = {J Math Imaging Vis},
	Journal-Full = {Journal of mathematical imaging and vision},
	Month = {Jan},
	Number = {2},
	Pages = {209-228},
	Pmc = {PMC2897162},
	Pmid = {20613972},
	Pst = {ppublish},
	Title = {Geodesic Shooting for Computational Anatomy},
	Volume = {24},
	Year = {2006},
	Bdsk-Url-1 = {https://doi.org/10.1007/s10851-005-3624-0}}

@article{Vercauteren:2009aa,
	Abstract = {We propose an efficient non-parametric diffeomorphic image registration algorithm based on Thirion's demons algorithm. In the first part of this paper, we show that Thirion's demons algorithm can be seen as an optimization procedure on the entire space of displacement fields. We provide strong theoretical roots to the different variants of Thirion's demons algorithm. This analysis predicts a theoretical advantage for the symmetric forces variant of the demons algorithm. We show on controlled experiments that this advantage is confirmed in practice and yields a faster convergence. In the second part of this paper, we adapt the optimization procedure underlying the demons algorithm to a space of diffeomorphic transformations. In contrast to many diffeomorphic registration algorithms, our solution is computationally efficient since in practice it only replaces an addition of displacement fields by a few compositions. Our experiments show that in addition to being diffeomorphic, our algorithm provides results that are similar to the ones from the demons algorithm but with transformations that are much smoother and closer to the gold standard, available in controlled experiments, in terms of Jacobians.},
	Author = {Vercauteren, Tom and Pennec, Xavier and Perchant, Aymeric and Ayache, Nicholas},
	Date-Added = {2018-11-26 18:53:33 -0800},
	Date-Modified = {2018-11-26 18:53:33 -0800},
	Doi = {10.1016/j.neuroimage.2008.10.040},
	Journal = {Neuroimage},
	Journal-Full = {NeuroImage},
	Mesh = {Algorithms; Humans; Image Processing, Computer-Assisted},
	Month = {Mar},
	Number = {1 Suppl},
	Pages = {S61-72},
	Pmid = {19041946},
	Pst = {ppublish},
	Title = {Diffeomorphic demons: efficient non-parametric image registration},
	Volume = {45},
	Year = {2009},
	Bdsk-Url-1 = {https://doi.org/10.1016/j.neuroimage.2008.10.040}}

@article{Ashburner:2007aa,
	Abstract = {This paper describes DARTEL, which is an algorithm for diffeomorphic image registration. It is implemented for both 2D and 3D image registration and has been formulated to include an option for estimating inverse consistent deformations. Nonlinear registration is considered as a local optimisation problem, which is solved using a Levenberg-Marquardt strategy. The necessary matrix solutions are obtained in reasonable time using a multigrid method. A constant Eulerian velocity framework is used, which allows a rapid scaling and squaring method to be used in the computations. DARTEL has been applied to intersubject registration of 471 whole brain images, and the resulting deformations were evaluated in terms of how well they encode the shape information necessary to separate male and female subjects and to predict the ages of the subjects.},
	Author = {Ashburner, John},
	Date-Added = {2018-11-26 18:50:44 -0800},
	Date-Modified = {2018-11-26 18:50:44 -0800},
	Doi = {10.1016/j.neuroimage.2007.07.007},
	Journal = {Neuroimage},
	Journal-Full = {NeuroImage},
	Mesh = {Algorithms; Artificial Intelligence; Brain; Humans; Image Enhancement; Image Interpretation, Computer-Assisted; Imaging, Three-Dimensional; Magnetic Resonance Imaging; Pattern Recognition, Automated; Reproducibility of Results; Sensitivity and Specificity; Subtraction Technique},
	Month = {Oct},
	Number = {1},
	Pages = {95-113},
	Pmid = {17761438},
	Pst = {ppublish},
	Title = {A fast diffeomorphic image registration algorithm},
	Volume = {38},
	Year = {2007},
	Bdsk-Url-1 = {https://doi.org/10.1016/j.neuroimage.2007.07.007}}

@article{Zhang:2017aa,
	Abstract = {This paper presents an efficient algorithm for large deformation diffeomorphic metric mapping (LDDMM) with geodesic shooting for image registration. We introduce a novel finite dimensional Fourier representation of diffeomorphic deformations based on the key fact that the high frequency components of a diffeomorphism remain stationary throughout the integration process when computing the deformation associated with smooth velocity fields. We show that manipulating high dimensional diffeomorphisms can be carried out entirely in the bandlimited space by integrating the nonstationary low frequency components of the displacement field. This insight substantially reduces the computational cost of the registration problem. Experimental results show that our method is significantly faster than the state-of-the-art diffeomorphic image registration methods while producing equally accurate alignment. We demonstrate our algorithm in two different applications of image registration: neuroimaging and in-utero imaging.},
	Author = {Zhang, Miaomiao and Liao, Ruizhi and Dalca, Adrian V and Turk, Esra A and Luo, Jie and Grant, P Ellen and Golland, Polina},
	Date-Added = {2018-11-26 18:48:45 -0800},
	Date-Modified = {2018-11-26 18:48:45 -0800},
	Doi = {10.1007/978-3-319-59050-9_44},
	Journal = {Inf Process Med Imaging},
	Journal-Full = {Information processing in medical imaging : proceedings of the ... conference},
	Mesh = {Algorithms; Brain; Fetus; Humans; Image Enhancement; Image Interpretation, Computer-Assisted; Neuroimaging; Pattern Recognition, Automated; Reproducibility of Results; Sensitivity and Specificity},
	Month = {Jun},
	Pages = {559-570},
	Pmc = {PMC5788203},
	Pmid = {29391767},
	Pst = {ppublish},
	Title = {Frequency Diffeomorphisms for Efficient Image Registration},
	Volume = {10265},
	Year = {2017},
	Bdsk-Url-1 = {https://doi.org/10.1007/978-3-319-59050-9_44}}

@article{Avants:2008aa,
	Abstract = {One of the most challenging problems in modern neuroimaging is detailed characterization of neurodegeneration. Quantifying spatial and longitudinal atrophy patterns is an important component of this process. These spatiotemporal signals will aid in discriminating between related diseases, such as frontotemporal dementia (FTD) and Alzheimer's disease (AD), which manifest themselves in the same at-risk population. Here, we develop a novel symmetric image normalization method (SyN) for maximizing the cross-correlation within the space of diffeomorphic maps and provide the Euler-Lagrange equations necessary for this optimization. We then turn to a careful evaluation of our method. Our evaluation uses gold standard, human cortical segmentation to contrast SyN's performance with a related elastic method and with the standard ITK implementation of Thirion's Demons algorithm. The new method compares favorably with both approaches, in particular when the distance between the template brain and the target brain is large. We then report the correlation of volumes gained by algorithmic cortical labelings of FTD and control subjects with those gained by the manual rater. This comparison shows that, of the three methods tested, SyN's volume measurements are the most strongly correlated with volume measurements gained by expert labeling. This study indicates that SyN, with cross-correlation, is a reliable method for normalizing and making anatomical measurements in volumetric MRI of patients and at-risk elderly individuals.},
	Author = {Avants, B B and Epstein, C L and Grossman, M and Gee, J C},
	Date-Added = {2018-11-26 18:45:42 -0800},
	Date-Modified = {2018-11-26 18:45:42 -0800},
	Doi = {10.1016/j.media.2007.06.004},
	Journal = {Med Image Anal},
	Journal-Full = {Medical image analysis},
	Mesh = {Algorithms; Atrophy; Cerebral Cortex; Dementia; Humans; Image Enhancement; Image Interpretation, Computer-Assisted; Magnetic Resonance Imaging},
	Month = {Feb},
	Number = {1},
	Pages = {26-41},
	Pmc = {PMC2276735},
	Pmid = {17659998},
	Pst = {ppublish},
	Title = {Symmetric diffeomorphic image registration with cross-correlation: evaluating automated labeling of elderly and neurodegenerative brain},
	Volume = {12},
	Year = {2008},
	Bdsk-Url-1 = {https://doi.org/10.1016/j.media.2007.06.004}}

@article{Christensen:1996aa,
	Abstract = {A general automatic approach is presented for accommodating local shape variation when mapping a two-dimensional (2-D) or three-dimensional (3-D) template image into alignment with a topologically similar target image. Local shape variability is accommodated by applying a vector-field transformation to the underlying material coordinate system of the template while constraining the transformation to be smooth (globally positive definite Jacobian). Smoothness is guaranteed without specifically penalizing large-magnitude deformations of small subvolumes by constraining the transformation on the basis of a Stokesian limit of the fluid-dynamical Navier-Stokes equations. This differs fundamentally from quadratic penalty methods, such as those based on linearized elasticity or thin-plate splines, in that stress restraining the motion relaxes over time allowing large-magnitude deformations. Kinematic nonlinearities are inherently necessary to maintain continuity of structures during large-magnitude deformations, and are included in all results. After initial global registration, final mappings are obtained by numerically solving a set of nonlinear partial differential equations associated with the constrained optimization problem. Automatic regridding is performed by propagating templates as the nonlinear transformations evaluated on a finite lattice become singular. Application of the method to intersubject registration of neuroanatomical structures illustrates the ability to account for local anatomical variability.},
	Author = {Christensen, G E and Rabbitt, R D and Miller, M I},
	Date-Added = {2018-11-26 18:37:25 -0800},
	Date-Modified = {2018-11-26 18:37:25 -0800},
	Doi = {10.1109/83.536892},
	Journal = {IEEE Trans Image Process},
	Journal-Full = {IEEE transactions on image processing : a publication of the IEEE Signal Processing Society},
	Number = {10},
	Pages = {1435-47},
	Pmid = {18290061},
	Pst = {ppublish},
	Title = {Deformable templates using large deformation kinematics},
	Volume = {5},
	Year = {1996},
	Bdsk-Url-1 = {https://doi.org/10.1109/83.536892}}

@article{Beg:2005aa,
	Author = {M. Faisal Beg and Michael I. Miller and Alain Trouv{\'e} and Laurent Younes},
	Date-Added = {2018-11-26 13:05:53 -0800},
	Date-Modified = {2018-11-26 13:06:53 -0800},
	Journal = {International Journal of Computer Vision},
	Month = {February},
	Number = {2},
	Pages = {139--157},
	Title = {Computing Large Deformation Metric Mappings via Geodesic Flows of Diffeomorphisms},
	Volume = {61},
	Year = {2004}}

@article{Shams:2010aa,
	Author = {R. Shams and P. Sadeghi and R. A. Kennedy and R. I. Hartley},
	Date-Added = {2018-11-26 12:58:03 -0800},
	Date-Modified = {2018-11-26 13:00:41 -0800},
	Journal = {IEEE Signal Process Mag},
	Number = {2},
	Pages = {50--60},
	Title = {A survey of medical image registration on multicore and the GPU},
	Volume = {27},
	Year = {2010}}

@article{Vialard:2012aa,
	Author = {Fran{\c c}ois-Xavier Vialard and Laurent Risser and Daniel Rueckert and Colin J. Cotter},
	Date-Added = {2018-11-26 12:55:50 -0800},
	Date-Modified = {2018-11-26 12:57:08 -0800},
	Journal = {Int J Comput Vis},
	Pages = {229--241},
	Title = {Diffeomorphic 3D Image Registration via Geodesic Shooting Using an Efficient Adjoint Calculation},
	Volume = {97},
	Year = {2012}}

@inproceedings{Rohe:2017aa,
	Abstract = {In this paper, we propose an innovative approach for registration based on the deterministic prediction of the parameters from both images instead of the optimization of a energy criteria. The method relies on a fully convolutional network whose architecture consists of contracting layers to detect relevant features and a symmetric expanding path that matches them together and outputs the transformation parametrization. Whereas convolutional networks have seen a widespread expansion and have been already applied to many medical imaging problems such as segmentation and classification, its application to registration has so far faced the challenge of defining ground truth data on which to train the algorithm. Here, we present a novel training strategy to build reference deformations which relies on the registration of segmented regions of interest. We apply this methodology to the problem of inter-patient heart registration and show an important improvement over a state of the art optimization based algorithm. Not only our method is more accurate but it is also faster - registration of two 3D-images taking less than 30 ms second on a GPU - and more robust to outliers.},
	Address = {Cham},
	Author = {Roh{\'e}, Marc-Michel and Datar, Manasi and Heimann, Tobias and Sermesant, Maxime and Pennec, Xavier},
	Booktitle = {Medical Image Computing and Computer Assisted Intervention − MICCAI 2017},
	Date-Added = {2018-11-08 14:30:54 -0800},
	Date-Modified = {2018-11-08 14:31:01 -0800},
	Editor = {Descoteaux, Maxime and Maier-Hein, Lena and Franz, Alfred and Jannin, Pierre and Collins, D. Louis and Duchesne, Simon},
	Isbn = {978-3-319-66182-7},
	Pages = {266--274},
	Publisher = {Springer International Publishing},
	Title = {SVF-Net: Learning Deformable Image Registration Using Shape Matching},
	Year = {2017}}

@inproceedings{Sokooti:2017aa,
	Abstract = {In this paper we propose a method to solve nonrigid image registration through a learning approach, instead of via iterative optimization of a predefined dissimilarity metric. We design a Convolutional Neural Network (CNN) architecture that, in contrast to all other work, directly estimates the displacement vector field (DVF) from a pair of input images. The proposed RegNet is trained using a large set of artificially generated DVFs, does not explicitly define a dissimilarity metric, and integrates image content at multiple scales to equip the network with contextual information. At testing time nonrigid registration is performed in a single shot, in contrast to current iterative methods. We tested RegNet on 3D chest CT follow-up data. The results show that the accuracy of RegNet is on par with a conventional B-spline registration, for anatomy within the capture range. Training RegNet with artificially generated DVFs is therefore a promising approach for obtaining good results on real clinical data, thereby greatly simplifying the training problem. Deformable image registration can therefore be successfully casted as a learning problem.},
	Address = {Cham},
	Author = {Sokooti, Hessam and de Vos, Bob and Berendsen, Floris and Lelieveldt, Boudewijn P. F. and I{\v{s}}gum, Ivana and Staring, Marius},
	Booktitle = {Medical Image Computing and Computer Assisted Intervention − MICCAI 2017},
	Date-Added = {2018-11-08 14:26:19 -0800},
	Date-Modified = {2018-11-08 14:26:29 -0800},
	Editor = {Descoteaux, Maxime and Maier-Hein, Lena and Franz, Alfred and Jannin, Pierre and Collins, D. Louis and Duchesne, Simon},
	Isbn = {978-3-319-66182-7},
	Pages = {232--239},
	Publisher = {Springer International Publishing},
	Title = {Nonrigid Image Registration Using Multi-scale 3D Convolutional Neural Networks},
	Year = {2017}}

@article{Yang:2017aa,
	Abstract = {This paper introduces Quicksilver, a fast deformable image registration method. Quicksilver registration for image-pairs works by patch-wise prediction of a deformation model based directly on image appearance. A deep encoder-decoder network is used as the prediction model. While the prediction strategy is general, we focus on predictions for the Large Deformation Diffeomorphic Metric Mapping (LDDMM) model. Specifically, we predict the momentum-parameterization of LDDMM, which facilitates a patch-wise prediction strategy while maintaining the theoretical properties of LDDMM, such as guaranteed diffeomorphic mappings for sufficiently strong regularization. We also provide a probabilistic version of our prediction network which can be sampled during the testing time to calculate uncertainties in the predicted deformations. Finally, we introduce a new correction network which greatly increases the prediction accuracy of an already existing prediction network. We show experimental results for uni-modal atlas-to-image as well as uni-/multi-modal image-to-image registrations. These experiments demonstrate that our method accurately predicts registrations obtained by numerical optimization, is very fast, achieves state-of-the-art registration results on four standard validation datasets, and can jointly learn an image similarity measure. Quicksilver is freely available as an open-source software.},
	Author = {Yang, Xiao and Kwitt, Roland and Styner, Martin and Niethammer, Marc},
	Date-Added = {2018-11-08 14:16:53 -0800},
	Date-Modified = {2018-11-08 14:16:53 -0800},
	Doi = {10.1016/j.neuroimage.2017.07.008},
	Journal = {Neuroimage},
	Journal-Full = {NeuroImage},
	Keywords = {Brain imaging; Deep learning; Image registration},
	Mesh = {Algorithms; Brain; Brain Mapping; Humans; Image Processing, Computer-Assisted; Imaging, Three-Dimensional; Machine Learning; Pattern Recognition, Automated},
	Month = {09},
	Pages = {378-396},
	Pmc = {PMC6036629},
	Pmid = {28705497},
	Pst = {ppublish},
	Title = {Quicksilver: Fast predictive image registration - A deep learning approach},
	Volume = {158},
	Year = {2017},
	Bdsk-Url-1 = {https://doi.org/10.1016/j.neuroimage.2017.07.008}}

@article{Wu:2016aa,
	Abstract = {Feature selection is a critical step in deformable image registration. In particular, selecting the most discriminative features that accurately and concisely describe complex morphological patterns in image patches improves correspondence detection, which in turn improves image registration accuracy. Furthermore, since more and more imaging modalities are being invented to better identify morphological changes in medical imaging data, the development of deformable image registration method that scales well to new image modalities or new image applications with little to no human intervention would have a significant impact on the medical image analysis community. To address these concerns, a learning-based image registration framework is proposed that uses deep learning to discover compact and highly discriminative features upon observed imaging data. Specifically, the proposed feature selection method uses a convolutional stacked autoencoder to identify intrinsic deep feature representations in image patches. Since deep learning is an unsupervised learning method, no ground truth label knowledge is required. This makes the proposed feature selection method more flexible to new imaging modalities since feature representations can be directly learned from the observed imaging data in a very short amount of time. Using the LONI and ADNI imaging datasets, image registration performance was compared to two existing state-of-the-art deformable image registration methods that use handcrafted features. To demonstrate the scalability of the proposed image registration framework, image registration experiments were conducted on 7.0-T brain MR images. In all experiments, the results showed that the new image registration framework consistently demonstrated more accurate registration results when compared to state of the art.},
	Author = {Wu, Guorong and Kim, Minjeong and Wang, Qian and Munsell, Brent C and Shen, Dinggang},
	Date-Added = {2018-11-08 14:16:01 -0800},
	Date-Modified = {2018-11-08 14:16:01 -0800},
	Doi = {10.1109/TBME.2015.2496253},
	Journal = {IEEE Trans Biomed Eng},
	Journal-Full = {IEEE transactions on bio-medical engineering},
	Mesh = {Algorithms; Brain; Humans; Image Processing, Computer-Assisted; Magnetic Resonance Imaging; Unsupervised Machine Learning},
	Month = {07},
	Number = {7},
	Pages = {1505-16},
	Pmc = {PMC4853306},
	Pmid = {26552069},
	Pst = {ppublish},
	Title = {Scalable High-Performance Image Registration Framework by Unsupervised Deep Feature Representations Learning},
	Volume = {63},
	Year = {2016},
	Bdsk-Url-1 = {https://doi.org/10.1109/TBME.2015.2496253}}

@inproceedings{Wohlhart:2015aa,
	Author = {Paul Wohlhart and Vincent Lepetit},
	Bibsource = {dblp computer science bibliography, https://dblp.org},
	Biburl = {https://dblp.org/rec/bib/conf/cvpr/WohlhartL15},
	Booktitle = {{IEEE} Conference on Computer Vision and Pattern Recognition, {CVPR} 2015, Boston, MA, USA, June 7-12, 2015},
	Crossref = {DBLP:conf/cvpr/2015},
	Date-Added = {2018-11-08 14:14:57 -0800},
	Date-Modified = {2018-11-08 14:15:16 -0800},
	Doi = {10.1109/CVPR.2015.7298930},
	Pages = {3109--3118},
	Timestamp = {Thu, 25 May 2017 00:41:23 +0200},
	Title = {Learning descriptors for object recognition and 3D pose estimation},
	Url = {https://doi.org/10.1109/CVPR.2015.7298930},
	Year = {2015},
	Bdsk-Url-1 = {https://doi.org/10.1109/CVPR.2015.7298930}}

@inproceedings{Weinzaepfel:2013aa,
	Author = {P. Weinzaepfel and J. Revaud and Z. Harchaoui and C. Schmid},
	Booktitle = {2013 IEEE International Conference on Computer Vision},
	Date-Added = {2018-11-08 14:12:17 -0800},
	Date-Modified = {2018-11-08 14:12:29 -0800},
	Doi = {10.1109/ICCV.2013.175},
	Issn = {1550-5499},
	Keywords = {computer vision;convolution;image matching;image motion analysis;image retrieval;image sampling;image sequences;minimisation;smoothing methods;variational techniques;large displacement optical flow;deep matching;optical flow computation;computer vision systems;large displacement handling;DeepFlow algorithm;variational approach;descriptor matching algorithm;multistage architecture;interleaving convolutions;max-pooling;deep convolutional nets;dense sampling;quasidense correspondence retrieval;smoothing effect;energy minimization framework;optical flow estimation;MPI-Sintel dataset;Optical imaging;Integrated optics;Nonlinear optics;Optical filters;Adaptive optics;Estimation;Equations;optical flow;large displacements;dense matching;non-rigid matching;deep convolutional networks},
	Month = {Dec},
	Pages = {1385-1392},
	Title = {DeepFlow: Large Displacement Optical Flow with Deep Matching},
	Year = {2013},
	Bdsk-Url-1 = {https://doi.org/10.1109/ICCV.2013.175}}

@inproceedings{Uzunova:2017aa,
	Abstract = {Convolutional neural networks (CNNs) have been successfully used for fast and accurate estimation of dense correspondences between images in computer vision applications. However, much of their success is based on the availability of large training datasets with dense ground truth correspondences, which are only rarely available in medical applications. In this paper, we, therefore, address the problem of CNNs learning from few training data for medical image registration. Our contributions are threefold: (1) We present a novel approach for learning highly expressive appearance models from few training samples, (2) we show that this approach can be used to synthesize huge amounts of realistic ground truth training data for CNN-based medical image registration, and (3) we adapt the FlowNet architecture for CNN-based optical flow estimation to the medical image registration problem. This pipeline is applied to two medical data sets with less than 40 training images. We show that CNNs learned from the proposed generative model outperform those trained on random deformations or displacement fields estimated via classical image registration.},
	Address = {Cham},
	Author = {Uzunova, Hristina and Wilms, Matthias and Handels, Heinz and Ehrhardt, Jan},
	Booktitle = {Medical Image Computing and Computer Assisted Intervention − MICCAI 2017},
	Date-Added = {2018-11-08 14:09:20 -0800},
	Date-Modified = {2018-11-08 14:09:41 -0800},
	Editor = {Descoteaux, Maxime and Maier-Hein, Lena and Franz, Alfred and Jannin, Pierre and Collins, D. Louis and Duchesne, Simon},
	Isbn = {978-3-319-66182-7},
	Pages = {223--231},
	Publisher = {Springer International Publishing},
	Title = {Training CNNs for Image Registration from Few Samples with Model-based Data Augmentation},
	Year = {2017}}

@inproceedings{deVos:2017aa,
	Abstract = {In this work we propose a deep learning network for deformable image registration (DIRNet). The DIRNet consists of a convolutional neural network (ConvNet) regressor, a spatial transformer, and a resampler. The ConvNet analyzes a pair of fixed and moving images and outputs parameters for the spatial transformer, which generates the displacement vector field that enables the resampler to warp the moving image to the fixed image. The DIRNet is trained end-to-end by unsupervised optimization of a similarity metric between input image pairs. A trained DIRNet can be applied to perform registration on unseen image pairs in one pass, thus non-iteratively. Evaluation was performed with registration of images of handwritten digits (MNIST) and cardiac cine MR scans (Sunnybrook Cardiac Data). The results demonstrate that registration with DIRNet is as accurate as a conventional deformable image registration method with short execution times.},
	Address = {Cham},
	Author = {de Vos, Bob D. and Berendsen, Floris F. and Viergever, Max A. and Staring, Marius and I{\v{s}}gum, Ivana},
	Booktitle = {Deep Learning in Medical Image Analysis and Multimodal Learning for Clinical Decision Support},
	Date-Added = {2018-11-08 14:08:22 -0800},
	Date-Modified = {2018-11-08 14:08:33 -0800},
	Editor = {Cardoso, M. Jorge and Arbel, Tal and Carneiro, Gustavo and Syeda-Mahmood, Tanveer and Tavares, Jo{\~a}o Manuel R.S. and Moradi, Mehdi and Bradley, Andrew and Greenspan, Hayit and Papa, Jo{\~a}o Paulo and Madabhushi, Anant and Nascimento, Jacinto C. and Cardoso, Jaime S. and Belagiannis, Vasileios and Lu, Zhi},
	Isbn = {978-3-319-67558-9},
	Pages = {204--212},
	Publisher = {Springer International Publishing},
	Title = {End-to-End Unsupervised Deformable Image Registration with a Convolutional Neural Network},
	Year = {2017}}

@inproceedings{Sloan:2018aa,
	Author = {J. M. Sloan and K. A. Goatman and J. P. Siebert},
	Booktitle = {Proceedings of the 11th International Joint Conference on Biomedical Engineering Systems and Technologies (BIOSTEC 2018) - Volume 2: BIOIMAGING},
	Date-Added = {2018-11-08 14:01:48 -0800},
	Date-Modified = {2018-11-08 14:12:52 -0800},
	Pages = {89--99},
	Title = {Learning Rigid Image Registration - Utilizing Convolutional Neural Networks for Medical Image Registration},
	Year = {2018}}

@inproceedings{Sheikhjafari:2018aa,
	Author = {Ameneh Sheikhjafari and Michelle Noga and Kumaradevan Punithakumar and Nilanjan Ray},
	Booktitle = {Proceeings of Medical Imaging with Deep Learning},
	Date-Added = {2018-11-08 13:59:52 -0800},
	Date-Modified = {2018-11-08 14:13:01 -0800},
	Title = {Unsupervised Deformable Image Registration with Fully Connected Generative Neural Network},
	Year = {2018}}

@inproceedings{Sergeev:2012aa,
	Author = {Sergey Sergeev and Yang Zhao and Marius George Linguraru and Kazunori Okada,},
	Booktitle = {Proceeings of the SPIE},
	Date-Added = {2018-11-08 13:57:02 -0800},
	Date-Modified = {2018-11-08 14:13:07 -0800},
	Title = {Medical image registration using machine learning-based interest point detector},
	Year = {2012}}

@article{Miao:2016aa,
	Abstract = {In this paper, we present a Convolutional Neural Network (CNN) regression approach to address the two major limitations of existing intensity-based 2-D/3-D registration technology: 1) slow computation and 2) small capture range. Different from optimization-based methods, which iteratively optimize the transformation parameters over a scalar-valued metric function representing the quality of the registration, the proposed method exploits the information embedded in the appearances of the digitally reconstructed radiograph and X-ray images, and employs CNN regressors to directly estimate the transformation parameters. An automatic feature extraction step is introduced to calculate 3-D pose-indexed features that are sensitive to the variables to be regressed while robust to other factors. The CNN regressors are then trained for local zones and applied in a hierarchical manner to break down the complex regression task into multiple simpler sub-tasks that can be learned separately. Weight sharing is furthermore employed in the CNN regression model to reduce the memory footprint. The proposed approach has been quantitatively evaluated on 3 potential clinical applications, demonstrating its significant advantage in providing highly accurate real-time 2-D/3-D registration with a significantly enlarged capture range when compared to intensity-based methods.},
	Author = {Shun Miao and Wang, Z Jane and Rui Liao},
	Date-Added = {2018-11-08 13:53:54 -0800},
	Date-Modified = {2018-11-08 13:53:54 -0800},
	Doi = {10.1109/TMI.2016.2521800},
	Journal = {IEEE Trans Med Imaging},
	Journal-Full = {IEEE transactions on medical imaging},
	Mesh = {Arthroplasty, Replacement, Knee; Echocardiography, Transesophageal; Humans; Imaging, Three-Dimensional; Knee Joint; Machine Learning; Neural Networks (Computer); Radiography; Regression Analysis},
	Month = {05},
	Number = {5},
	Pages = {1352-1363},
	Pmid = {26829785},
	Pst = {ppublish},
	Title = {A CNN Regression Approach for Real-Time 2D/3D Registration},
	Volume = {35},
	Year = {2016},
	Bdsk-Url-1 = {https://doi.org/10.1109/TMI.2016.2521800}}

@conference{Liao:2017aa,
	Author = {Rui Liao and Shun Miao and Pierre de Tournemire and Sasa Grbic and Ali Kamen and Tommaso Mansi and Dorin Comaniciu},
	Booktitle = {Proceedings of the Thirty-First AAAI Conference on Artificial Intelligence},
	Date-Added = {2018-11-08 13:52:24 -0800},
	Date-Modified = {2018-11-08 13:53:26 -0800},
	Title = {An Artificial Agent for Robust Image Registration},
	Year = {2017}}

@conference{Eppenhof:2018,
	Author = {Koen A. J. Eppenhof and Maxime W. Lafarge and Pim Moeskops and Mitko Veta and Josien P. W. Pluim},
	Booktitle = {Proc. SPIE 10574, Medical Imaging 2018: Image Processing},
	Date-Added = {2018-11-08 13:49:08 -0800},
	Date-Modified = {2018-11-08 13:50:21 -0800},
	Title = {Deformable image registration using convolutional neural networks},
	Year = {2018}}

@article{Cao:2017aa,
	Abstract = {Existing deformable registration methods require exhaustively iterative optimization, along with careful parameter tuning, to estimate the deformation field between images. Although some learning-based methods have been proposed for initiating deformation estimation, they are often template-specific and not flexible in practical use. In this paper, we propose a convolutional neural network (CNN) based regression model to directly learn the complex mapping from the input image pair (i.e., a pair of template and subject) to their corresponding deformation field. Specifically, our CNN architecture is designed in a patch-based manner to learn the complex mapping from the input patch pairs to their respective deformation field. First, the equalized active-points guided sampling strategy is introduced to facilitate accurate CNN model learning upon a limited image dataset. Then, the similarity-steered CNN architecture is designed, where we propose to add the auxiliary contextual cue, i.e., the similarity between input patches, to more directly guide the learning process. Experiments on different brain image datasets demonstrate promising registration performance based on our CNN model. Furthermore, it is found that the trained CNN model from one dataset can be successfully transferred to another dataset, although brain appearances across datasets are quite variable.},
	Author = {Cao, Xiaohuan and Yang, Jianhua and Zhang, Jun and Nie, Dong and Kim, Min-Jeong and Wang, Qian and Shen, Dinggang},
	Date-Added = {2018-11-08 13:47:53 -0800},
	Date-Modified = {2018-11-08 13:47:53 -0800},
	Doi = {10.1007/978-3-319-66182-7_35},
	Journal = {Med Image Comput Comput Assist Interv},
	Journal-Full = {Medical image computing and computer-assisted intervention : MICCAI ... International Conference on Medical Image Computing and Computer-Assisted Intervention},
	Mesh = {Algorithms; Brain; Humans; Machine Learning; Neural Networks (Computer); Neuroimaging; Reproducibility of Results; Sensitivity and Specificity; Young Adult},
	Month = {Sep},
	Pages = {300-308},
	Pmc = {PMC5731783},
	Pmid = {29250613},
	Pst = {ppublish},
	Title = {Deformable Image Registration based on Similarity-Steered CNN Regression},
	Volume = {10433},
	Year = {2017},
	Bdsk-Url-1 = {https://doi.org/10.1007/978-3-319-66182-7_35}}

@conference{Jaderberg:2015aa,
	Author = {Max Jaderberg and Karen Simonyan and Andrew Zisserman and Koray Kavukcuoglu},
	Booktitle = {Neural Information Processing Systems 2015},
	Date-Added = {2018-11-08 13:45:45 -0800},
	Date-Modified = {2018-11-08 13:47:17 -0800},
	Title = {Spatial Transformer Networks},
	Year = {2015}}

@article{Hu:2018aa,
	Abstract = {One of the fundamental challenges in supervised learning for multimodal image registration is the lack of ground-truth for voxel-level spatial correspondence. This work describes a method to infer voxel-level transformation from higher-level correspondence information contained in anatomical labels. We argue that such labels are more reliable and practical to obtain for reference sets of image pairs than voxel-level correspondence. Typical anatomical labels of interest may include solid organs, vessels, ducts, structure boundaries and other subject-specific ad hoc landmarks. The proposed end-to-end convolutional neural network approach aims to predict displacement fields to align multiple labelled corresponding structures for individual image pairs during the training, while only unlabelled image pairs are used as the network input for inference. We highlight the versatility of the proposed strategy, for training, utilising diverse types of anatomical labels, which need not to be identifiable over all training image pairs. At inference, the resulting 3D deformable image registration algorithm runs in real-time and is fully-automated without requiring any anatomical labels or initialisation. Several network architecture variants are compared for registering T2-weighted magnetic resonance images and 3D transrectal ultrasound images from prostate cancer patients. A median target registration error of 3.6 mm on landmark centroids and a median Dice of 0.87 on prostate glands are achieved from cross-validation experiments, in which 108 pairs of multimodal images from 76 patients were tested with high-quality anatomical labels.},
	Author = {Hu, Yipeng and Modat, Marc and Gibson, Eli and Li, Wenqi and Ghavami, Nooshin and Bonmati, Ester and Wang, Guotai and Bandula, Steven and Moore, Caroline M and Emberton, Mark and Ourselin, S{\'e}bastien and Noble, J Alison and Barratt, Dean C and Vercauteren, Tom},
	Date-Added = {2018-11-08 13:44:50 -0800},
	Date-Modified = {2018-11-08 13:44:50 -0800},
	Doi = {10.1016/j.media.2018.07.002},
	Journal = {Med Image Anal},
	Journal-Full = {Medical image analysis},
	Keywords = {Convolutional neural network; Image-guided intervention; Medical image registration; Prostate cancer; Weakly-supervised learning},
	Month = {Oct},
	Pages = {1-13},
	Pmid = {30007253},
	Pst = {ppublish},
	Title = {Weakly-supervised convolutional neural networks for multimodal image registration},
	Volume = {49},
	Year = {2018},
	Bdsk-Url-1 = {https://doi.org/10.1016/j.media.2018.07.002}}

@inproceedings{Dosovitskiy:2015aa,
	Acmid = {2919957},
	Address = {Washington, DC, USA},
	Author = {Dosovitskiy, Alexey and Fischery, Philipp and Ilg, Eddy and Hausser, Philip and Hazirbas, Caner and Golkov, Vladimir and Smagt, Patrick van der and Cremers, Daniel and Brox, Thomas},
	Booktitle = {Proceedings of the 2015 IEEE International Conference on Computer Vision (ICCV)},
	Date-Added = {2018-11-08 13:44:01 -0800},
	Date-Modified = {2018-11-08 13:44:08 -0800},
	Doi = {10.1109/ICCV.2015.316},
	Isbn = {978-1-4673-8391-2},
	Numpages = {9},
	Pages = {2758--2766},
	Publisher = {IEEE Computer Society},
	Series = {ICCV '15},
	Title = {FlowNet: Learning Optical Flow with Convolutional Networks},
	Url = {http://dx.doi.org/10.1109/ICCV.2015.316},
	Year = {2015},
	Bdsk-Url-1 = {http://dx.doi.org/10.1109/ICCV.2015.316}}

@inproceedings{Dalca:2018aa,
	Abstract = {Traditional deformable registration techniques achieve impressive results and offer a rigorous theoretical treatment, but are computationally intensive since they solve an optimization problem for each image pair. Recently, learning-based methods have facilitated fast registration by learning spatial deformation functions. However, these approaches use restricted deformation models, require supervised labels, or do not guarantee a diffeomorphic (topology-preserving) registration. Furthermore, learning-based registration tools have not been derived from a probabilistic framework that can offer uncertainty estimates. In this paper, we present a probabilistic generative model and derive an unsupervised learning-based inference algorithm that makes use of recent developments in convolutional neural networks (CNNs). We demonstrate our method on a 3D brain registration task, and provide an empirical analysis of the algorithm. Our approach results in state of the art accuracy and very fast runtimes, while providing diffeomorphic guarantees and uncertainty estimates. Our implementation is available online at http://voxelmorph.csail.mit.edu.},
	Address = {Cham},
	Author = {Dalca, Adrian V. and Balakrishnan, Guha and Guttag, John and Sabuncu, Mert R.},
	Booktitle = {Medical Image Computing and Computer Assisted Intervention -- MICCAI 2018},
	Date-Added = {2018-11-08 13:39:10 -0800},
	Date-Modified = {2018-11-08 13:39:29 -0800},
	Editor = {Frangi, Alejandro F. and Schnabel, Julia A. and Davatzikos, Christos and Alberola-L{\'o}pez, Carlos and Fichtinger, Gabor},
	Isbn = {978-3-030-00928-1},
	Pages = {729--738},
	Publisher = {Springer International Publishing},
	Title = {Unsupervised Learning for Fast Probabilistic Diffeomorphic Registration},
	Year = {2018}}

@article{Bermudez:2018aa,
	Abstract = {An important task in image processing and neuroimaging is to extract quantitative information from the acquired images in order to make observations about the presence of disease or markers of development in populations. Having a low-dimensional manifold of an image allows for easier statistical comparisons between groups and the synthesis of group representatives. Previous studies have sought to identify the best mapping of brain MRI to a low-dimensional manifold, but have been limited by assumptions of explicit similarity measures. In this work, we use deep learning techniques to investigate implicit manifolds of normal brains and generate new, high-quality images. We explore implicit manifolds by addressing the problems of image synthesis and image denoising as important tools in manifold learning. First, we propose the unsupervised synthesis of T1-weighted brain MRI using a Generative Adversarial Network (GAN) by learning from 528 examples of 2D axial slices of brain MRI. Synthesized images were first shown to be unique by performing a cross-correlation with the training set. Real and synthesized images were then assessed in a blinded manner by two imaging experts providing an image quality score of 1-5. The quality score of the synthetic image showed substantial overlap with that of the real images. Moreover, we use an autoencoder with skip connections for image denoising, showing that the proposed method results in higher PSNR than FSL SUSAN after denoising. This work shows the power of artificial networks to synthesize realistic imaging data, which can be used to improve image processing techniques and provide a quantitative framework to structural changes in the brain.},
	Author = {Bermudez, Camilo and Plassard, Andrew J and Davis, Taylor L and Newton, Allen T and Resnick, Susan M and Landman, Bennett A},
	Date-Added = {2018-11-08 13:36:22 -0800},
	Date-Modified = {2018-11-08 13:36:22 -0800},
	Doi = {10.1117/12.2293515},
	Journal = {Proc SPIE Int Soc Opt Eng},
	Journal-Full = {Proceedings of SPIE--the International Society for Optical Engineering},
	Keywords = {Manifold learning; brain MRI; deep neural networks; generative adversarial networks; image synthesis},
	Month = {Mar},
	Pmc = {PMC5990281},
	Pmid = {29887659},
	Pst = {ppublish},
	Title = {Learning Implicit Brain MRI Manifolds with Deep Learning},
	Volume = {10574},
	Year = {2018},
	Bdsk-Url-1 = {https://doi.org/10.1117/12.2293515}}

@conference{Balakrishnan:2018aa,
	Author = {Guha Balakrishnan and Amy Zhao and Mert R. Sabuncu and John Guttag and Adrian V. Dalca},
	Booktitle = {IEEE CVPR: Conf. on Computer Vision and Pattern Recognition},
	Date-Added = {2018-11-08 13:28:08 -0800},
	Date-Modified = {2018-11-08 13:36:34 -0800},
	Title = {An Unsupervised Learning Model for Deformable Medical Image Registration},
	Year = {2018}}
