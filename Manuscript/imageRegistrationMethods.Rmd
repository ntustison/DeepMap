
# Image registration with Deep Learning

\begin{figure}[!htb]
\centering
\includegraphics[width=0.95\textwidth]{Figures/overview.pdf}
\caption{Summary plots for the works reviewed including (a) publications per year, (b)
         choice of neural network API, (c) anatomy (where applicable), and (d) publishing
        venue.
        }
\label{fig:overview}
\end{figure}

\input{methodsTable.tex}

## Image registration via feature localization

Much of the early work incorporating deep learning into solving image
registration problems involved the detection of corresponding features
and then using that information to determine the correspondence relationship
between the fixed and moving image pair.  For example, just at the start of the
current era of deep learning in image-related research, [@Sergeev:2012aa]
proposed point correspondence detection using multiple feed-forward neural
networks each of which is trained to detect a single feature.  These
neural networks are relatively simple consisting of two hidden layers each
with 60 neurons where the output is a probability of it containing a specific
feature at the center of a small image neighborhood.  These detected point correspondences
are then used to estimate the total affine transformation using the RANSAC
algorithm [@Fischler:1981aa].

Similarly, DeepFlow [@Weinzaepfel:2013aa] uses CNNs to detect
matching features (i.e., _deep matching_) which are then used as
additional information in the large displacement optical flow framework
[@Brox:2011aa].  A relatively small architecture is employed consisting
of six layers and used to detect features at different convolution sizes
and then matched across scales.

A similarity measure for multimodal registration is formulated in terms
of CNNs in the work of [@Simonovsky:2016aa].  A two channel network is
developed for input image patches (T1- and T2-weighted brain images).
A B-spline image registration algorithm developed from the Insight Toolkit
is used to leverage the output CNN-based similarity measure for comparison
with an identical registration set-up employing mutual information.

Finally, in the category of feature learning, Wu et al. use stacked auto-encoders
(SAE) to map patchwise image content to learned feature vectors [@Wu:2016aa].  These
patches are then subsampled based on the importance criteria outlined in
[@Wang:2010aa] which tends towards regions of high informational content
such as edges. The SAE-based feature vectors at these image patches are then
used to drive a HAMMER-based registration [@Shen:2002aa] which is inherently
a feature-based approach.

## GANs for image registration

In order to constrain the mapping between moving and fixed images,
the adverserial approach outlined in [@Mahapatra:2018aa] combines
a content loss term (which includes subterms for normalized mutual
information, structural similarity [@Wang:2004aa], and a VGG-based
filter feature L2-norm between the two images) with a "cyclical" adverserial
loss.  This is constructed in the style
of [@Zhu:2017aa] who proposed this GAN extension, viz., CycleGAN,
to ensure that
the normally underconstrained forward intensity mapping is consistent with
a similarly generated inverse mapping for "image-to-image translation"
(e.g., converting a Monet painting to a realistic photo or rendering a
winter nature scene as its summer analog).  However, in this case, the
cyclical aspect is to ensure a regularized field through forward and
inverse displacement consistency.

The work of [@Hu:2018ac] employs discriminator training between finite-element
modeling and generated displacements for the prostate and surrounding tissues
to regularize the predicted displacement fields.  The generator loss employs
the weakly supervised learning method proposed by the same authors in [@Hu:2018ab]
whereby anatomical labels are used to drive registration during training only.
The generator is constructed from an encoder/decoder architecture based on
ResNet blocks [@He:2015].
The prediction framework includes both localized tissue deformation and the
linear coordinate-system-changes assocated with the ultrasound imaging
acquisition.

In [@Fan:2018aa], the discriminator loss is based on quantification of how
well two images are aligned where the negative case derives from the registration
generator
and the positive cases consist of identical images (plus small perturbations).
Explicit regularization is added to the total loss for the registration network.
The registration network consists of a U-net type architecture which takes two
3-D image patches from the image pair as input and produces a patchwise
displacement field.  The discriminator network takes an image pair as input
and outputs the similarity probability.

## Geodesic shooting with Quicksilver

The large deformation diffeomorphic metric mappings (LDDMM) framework for image matching
derives from the theoretical foundations underlying diffeomorphic *flows*
[@Trouve:1995aa;@Christensen:1996aa;@Dupuis:1998].  Such diffeomorphisms are sufficiently
differentiable bijective mappings, or transformations, which have sufficiently
differentiable inverses. Specifically, the set of possible
diffeomorphic mappings, $\phi(\mathbf{x}, t)$ ($\mathbf{x} \in \Omega$, $t \in [0,1]$),
between two images, $I$ and $J$ can be described as the
collection of *paths* connecting the two images on a manifold determined by
the equation

\begin{equation}
\int_{0}^{1} \|v(t)\|^2_L dt + \int_{\Omega} | I \circ \phi^{-1}(x,1) - J|^2 d\Omega.
\label{eq:lddmm}
\end{equation}

$v$ is a time-dependent smooth field dictated by the functional norm $L$  and determines
the mapping via the ordinary differential equation

\begin{equation}
\frac{d\phi(\mathbf{x},t)}{dt} = v( \phi(\mathbf{x},t), t), \phi( \mathbf{x}, 0) = \mathbf{Id}.
\end{equation}

The optimal diffeomorphic transformation  between $I$ and $J$ can be described
as a geodesic [@Beg:2005aa] connecting the two images.  Traditionally, computational approaches to determining
this geodesic path involve discretization of the velocity field followed by numerical
integration.  This is performed for a given number of iterations where, presumably,
convergence implies arrival at this geodesic (i.e., optimal) path.  Alternatively, based on
the work of [@Miller:2006aa], the Euler-Lagrange equations for Equation (\ref{eq:lddmm})
can be written as a system incorporating a "momentum" term.  It was further demonstrated
that the initial momentum determined the entire geodesic path.  This alternative perspective
engendered a new approach to determining the diffeomorphic solution between two images,
known as _geodesic shooting_ (e.g., [@Beg:2005aa;@Vialard:2012aa]).  Although initially
formulated in terms of scalar momenta [@Vialard:2012aa], a vector formulation was proposed
in [@Singh:2013aa] which tends towards superior numerical behavior.

The supervised deep learning technique of Yang et al. [@Yang:2017aa], known as _Quicksilver_,
leverages this geodesic shooting/vector momentum optimization approach for determining
optimal diffeomorphic transformations.  The network architecture consists of two parallel encoders
for separate fixed/moving image patches ($15 \times 15 \times 15$ voxels)
feature learning.  The output is then concatenated and sent
through three identical decoder branches (one for each dimension) which comprises the
inverse operations as the single encoder branch.  Thus, the output consists of the predicted
vector momentum map which, as described above, determines the total transformation.  In
order to improve accuracy of the predicted momentum maps, a follow-on correction network
is also proposed.  This correction network, trained by inverting the mapping produced
by the predicted momentum and computing the residual error, is meant to account for
large deformations across patch boundaries.  Of note, Quicksilver, written in PyTorch [@paszke:2017aa],
is one of the handful of algorithms surveyed which has been made publicly available[^Q].

[^Q]: https://github.com/rkwitt/quicksilver

